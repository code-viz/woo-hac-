{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exclusive-religious",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "analyzed-entity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('Survival_time_event.csv', index_col=0)\n",
    "df2=pd.read_csv('Treatment.csv', index_col=0)\n",
    "df3=pd.read_csv('Clinical_Variables.csv', index_col=0)\n",
    "df4=pd.read_csv('Genetic_alterations.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aware-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1,df2,df3,df4], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "municipal-percentage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['time' 'event' 'Treatment' 'Var1' 'Var2' 'Var3' 'Var4' 'Var5' 'Var6'\n",
      " 'Var7' 'Var8' 'Var9' 'Var10' 'G1' 'G2' 'G3' 'G4' 'G5' 'G6' 'G7' 'G8' 'G9'\n",
      " 'G10' 'G11' 'G12' 'G13' 'G14' 'G15' 'G16' 'G17' 'G18' 'G19' 'G20' 'G21'\n",
      " 'G22' 'G23' 'G24' 'G25' 'G26' 'G27' 'G28' 'G29' 'G30' 'G31' 'G32' 'G33'\n",
      " 'G34' 'G35' 'G36' 'G37' 'G38' 'G39' 'G40' 'G41' 'G42' 'G43' 'G44' 'G45'\n",
      " 'G46' 'G47' 'G48' 'G49' 'G50' 'G51' 'G52' 'G53' 'G54' 'G55' 'G56' 'G57'\n",
      " 'G58' 'G59' 'G60' 'G61' 'G62' 'G63' 'G64' 'G65' 'G66' 'G67' 'G68' 'G69'\n",
      " 'G70' 'G71' 'G72' 'G73' 'G74' 'G75' 'G76' 'G77' 'G78' 'G79' 'G80' 'G81'\n",
      " 'G82' 'G83' 'G84' 'G85' 'G86' 'G87' 'G88' 'G89' 'G90' 'G91' 'G92' 'G93'\n",
      " 'G94' 'G95' 'G96' 'G97' 'G98' 'G99' 'G100' 'G101' 'G102' 'G103' 'G104'\n",
      " 'G105' 'G106' 'G107' 'G108' 'G109' 'G110' 'G111' 'G112' 'G113' 'G114'\n",
      " 'G115' 'G116' 'G117' 'G118' 'G119' 'G120' 'G121' 'G122' 'G123' 'G124'\n",
      " 'G125' 'G126' 'G127' 'G128' 'G129' 'G130' 'G131' 'G132' 'G133' 'G134'\n",
      " 'G135' 'G136' 'G137' 'G138' 'G139' 'G140' 'G141' 'G142' 'G143' 'G144'\n",
      " 'G145' 'G146' 'G147' 'G148' 'G149' 'G150' 'G151' 'G152' 'G153' 'G154'\n",
      " 'G155' 'G156' 'G157' 'G158' 'G159' 'G160' 'G161' 'G162' 'G163' 'G164'\n",
      " 'G165' 'G166' 'G167' 'G168' 'G169' 'G170' 'G171' 'G172' 'G173' 'G174'\n",
      " 'G175' 'G176' 'G177' 'G178' 'G179' 'G180' 'G181' 'G182' 'G183' 'G184'\n",
      " 'G185' 'G186' 'G187' 'G188' 'G189' 'G190' 'G191' 'G192' 'G193' 'G194'\n",
      " 'G195' 'G196' 'G197' 'G198' 'G199' 'G200' 'G201' 'G202' 'G203' 'G204'\n",
      " 'G205' 'G206' 'G207' 'G208' 'G209' 'G210' 'G211' 'G212' 'G213' 'G214'\n",
      " 'G215' 'G216' 'G217' 'G218' 'G219' 'G220' 'G221' 'G222' 'G223' 'G224'\n",
      " 'G225' 'G226' 'G227' 'G228' 'G229' 'G230' 'G231' 'G232' 'G233' 'G234'\n",
      " 'G235' 'G236' 'G237' 'G238' 'G239' 'G240' 'G241' 'G242' 'G243' 'G244'\n",
      " 'G245' 'G246' 'G247' 'G248' 'G249' 'G250' 'G251' 'G252' 'G253' 'G254'\n",
      " 'G255' 'G256' 'G257' 'G258' 'G259' 'G260' 'G261' 'G262' 'G263' 'G264'\n",
      " 'G265' 'G266' 'G267' 'G268' 'G269' 'G270' 'G271' 'G272' 'G273' 'G274'\n",
      " 'G275' 'G276' 'G277' 'G278' 'G279' 'G280' 'G281' 'G282' 'G283' 'G284'\n",
      " 'G285' 'G286' 'G287' 'G288' 'G289' 'G290' 'G291' 'G292' 'G293' 'G294'\n",
      " 'G295' 'G296' 'G297' 'G298' 'G299' 'G300']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Analyze by describing data\n",
    "'''\n",
    "\n",
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baking-nevada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        time  event  Treatment  Var1  Var2  Var3  Var4  Var5  Var6  Var7  ...  \\\n",
      "0  57.448331      1          0     5     1     1     4     6     5     2  ...   \n",
      "1  27.004439      1          0     3     1     3     9     1     1     2  ...   \n",
      "2  43.770511      1          1     2     5     3     4     3     3     3  ...   \n",
      "3  32.281018      1          1     2     7     2     3     5     0     1  ...   \n",
      "4  44.559284      0          0     1     3     0     0     2     2     6  ...   \n",
      "\n",
      "   G291  G292  G293  G294  G295  G296  G297  G298  G299  G300  \n",
      "0     0     0     0     0     0     0     0     0     0     0  \n",
      "1     0     0     0     0     0     0     0     0     0     0  \n",
      "2     0     0     0     0     0     0     0     0     0     0  \n",
      "3     0     1     0     1     0     0     0     0     0     0  \n",
      "4     0     0     0     0     0     0     0     0     0     1  \n",
      "\n",
      "[5 rows x 313 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "specified-bonus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          time  event  Treatment  Var1  Var2  Var3  Var4  Var5  Var6  Var7  \\\n",
      "995  19.289036      0          0     3     5     3     7     0     2     1   \n",
      "996  66.591235      1          1     4     2     1     2     2     2     2   \n",
      "997  62.986021      0          1     4     3     4     9     3     6     6   \n",
      "998  32.736220      1          0     4     1     4     5     6     3     1   \n",
      "999  36.714493      1          0     3     2     1     2     4     3     1   \n",
      "\n",
      "     ...  G291  G292  G293  G294  G295  G296  G297  G298  G299  G300  \n",
      "995  ...     0     0     0     0     0     0     1     0     0     0  \n",
      "996  ...     0     0     1     0     1     0     0     0     1     0  \n",
      "997  ...     0     0     0     0     1     0     0     0     0     0  \n",
      "998  ...     0     0     0     0     0     0     0     1     1     0  \n",
      "999  ...     0     0     0     0     0     0     0     0     0     0  \n",
      "\n",
      "[5 rows x 313 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "regular-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "vocal-theme",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Train & Test Split\n",
    "'''\n",
    "random_index = np.arange(1000)\n",
    "np.random.shuffle(random_index)\n",
    "np.random.shuffle(random_index)\n",
    "\n",
    "train_df, test_df = df.iloc[random_index[:900],:], df.iloc[random_index[900:1000],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "effective-recall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 313)\n",
      "          time  event  Treatment  Var1  Var2  Var3  Var4  Var5  Var6  Var7  \\\n",
      "963  78.384424      1          1     1     1     3     1     4     0     8   \n",
      "101  54.669402      1          0     6     5     2     1     3     5     1   \n",
      "18   50.220877      1          1     3     5     5     3     3     0     2   \n",
      "788  51.006243      1          1     1     3     1     4     6     2     6   \n",
      "273  42.771480      1          1     2     7     0     2     3     2     3   \n",
      "\n",
      "     ...  G291  G292  G293  G294  G295  G296  G297  G298  G299  G300  \n",
      "963  ...     0     1     0     0     0     0     0     0     0     0  \n",
      "101  ...     0     0     0     0     0     0     0     0     0     1  \n",
      "18   ...     0     0     0     0     0     0     0     0     0     0  \n",
      "788  ...     0     0     0     0     0     0     0     0     0     0  \n",
      "273  ...     0     0     0     0     0     0     0     0     0     1  \n",
      "\n",
      "[5 rows x 313 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "lonely-inquiry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             time       event   Treatment        Var1        Var2        Var3  \\\n",
      "count  900.000000  900.000000  900.000000  900.000000  900.000000  900.000000   \n",
      "mean    51.714706    0.888889    0.480000    2.977778    3.327778    2.984444   \n",
      "std     21.773072    0.314444    0.499878    1.883585    1.952240    1.884242   \n",
      "min     -7.945621    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%     37.385295    1.000000    0.000000    2.000000    2.000000    2.000000   \n",
      "50%     46.911524    1.000000    0.000000    3.000000    3.000000    3.000000   \n",
      "75%     61.291046    1.000000    1.000000    4.000000    4.000000    4.000000   \n",
      "max    186.487089    1.000000    1.000000   10.000000   11.000000   11.000000   \n",
      "\n",
      "             Var4        Var5        Var6        Var7  ...        G291  \\\n",
      "count  900.000000  900.000000  900.000000  900.000000  ...  900.000000   \n",
      "mean     3.206667    3.496667    3.218889    2.360000  ...    0.113333   \n",
      "std      1.965090    1.909228    2.021541    1.824734  ...    0.317176   \n",
      "min      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
      "25%      2.000000    2.000000    2.000000    1.000000  ...    0.000000   \n",
      "50%      3.000000    3.000000    3.000000    2.000000  ...    0.000000   \n",
      "75%      4.000000    5.000000    4.000000    4.000000  ...    0.000000   \n",
      "max     12.000000   11.000000   12.000000   10.000000  ...    1.000000   \n",
      "\n",
      "             G292        G293        G294        G295        G296        G297  \\\n",
      "count  900.000000  900.000000  900.000000  900.000000  900.000000  900.000000   \n",
      "mean     0.088889    0.105556    0.100000    0.125556    0.104444    0.110000   \n",
      "std      0.284742    0.307439    0.300167    0.331532    0.306006    0.313064   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
      "\n",
      "             G298        G299        G300  \n",
      "count  900.000000  900.000000  900.000000  \n",
      "mean     0.090000    0.103333    0.096667  \n",
      "std      0.286341    0.304563    0.295668  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      0.000000    0.000000    0.000000  \n",
      "50%      0.000000    0.000000    0.000000  \n",
      "75%      0.000000    0.000000    0.000000  \n",
      "max      1.000000    1.000000    1.000000  \n",
      "\n",
      "[8 rows x 313 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "naked-ethernet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             time       event   Treatment        Var1        Var2        Var3  \\\n",
      "count  100.000000  100.000000  100.000000  100.000000  100.000000  100.000000   \n",
      "mean    53.169983    0.910000    0.560000    2.800000    3.050000    3.150000   \n",
      "std     25.464551    0.287623    0.498888    1.780932    1.961112    2.171324   \n",
      "min     22.184681    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%     38.316104    1.000000    0.000000    1.000000    2.000000    2.000000   \n",
      "50%     47.715442    1.000000    1.000000    3.000000    3.000000    3.000000   \n",
      "75%     58.406646    1.000000    1.000000    4.000000    4.000000    4.000000   \n",
      "max    217.078908    1.000000    1.000000    9.000000    9.000000   11.000000   \n",
      "\n",
      "            Var4        Var5        Var6        Var7  ...        G291  \\\n",
      "count  100.00000  100.000000  100.000000  100.000000  ...  100.000000   \n",
      "mean     3.26000    3.420000    3.390000    2.360000  ...    0.100000   \n",
      "std      1.94687    1.960107    2.178383    1.778207  ...    0.301511   \n",
      "min      0.00000    0.000000    0.000000    0.000000  ...    0.000000   \n",
      "25%      2.00000    2.000000    2.000000    1.000000  ...    0.000000   \n",
      "50%      3.00000    3.000000    3.000000    2.000000  ...    0.000000   \n",
      "75%      4.00000    5.000000    5.000000    3.000000  ...    0.000000   \n",
      "max     10.00000    9.000000   10.000000    7.000000  ...    1.000000   \n",
      "\n",
      "             G292        G293       G294        G295        G296        G297  \\\n",
      "count  100.000000  100.000000  100.00000  100.000000  100.000000  100.000000   \n",
      "mean     0.090000    0.070000    0.15000    0.110000    0.130000    0.110000   \n",
      "std      0.287623    0.256432    0.35887    0.314466    0.337998    0.314466   \n",
      "min      0.000000    0.000000    0.00000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    0.00000    0.000000    0.000000    0.000000   \n",
      "50%      0.000000    0.000000    0.00000    0.000000    0.000000    0.000000   \n",
      "75%      0.000000    0.000000    0.00000    0.000000    0.000000    0.000000   \n",
      "max      1.000000    1.000000    1.00000    1.000000    1.000000    1.000000   \n",
      "\n",
      "             G298        G299        G300  \n",
      "count  100.000000  100.000000  100.000000  \n",
      "mean     0.090000    0.060000    0.100000  \n",
      "std      0.287623    0.238683    0.301511  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      0.000000    0.000000    0.000000  \n",
      "50%      0.000000    0.000000    0.000000  \n",
      "75%      0.000000    0.000000    0.000000  \n",
      "max      1.000000    1.000000    1.000000  \n",
      "\n",
      "[8 rows x 313 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "proud-bronze",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 311) (900,) (100, 311) (900,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Data & Ground Truth Split\n",
    "'''\n",
    "\n",
    "'''\n",
    "Time data drop\n",
    "'''\n",
    "\n",
    "X_train = train_df.drop(['time', 'event'], axis=1)\n",
    "Y_train = train_df['event']\n",
    "\n",
    "X_test = test_df.drop(['time', 'event'], axis=1)\n",
    "Y_test = test_df['event']\n",
    "\n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "temporal-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Save train & test results\n",
    "\n",
    "When doing train, Shuffle and split the data\n",
    "\n",
    "'''\n",
    "test_method_list = ['LogisticRegression', 'Support Vector Machines', 'KNN or k-Nearest Neighbors',\n",
    "                    'Gaussian Naive Bayes', 'Perceptron', 'Linear SVC', \n",
    "                    'Stochastic Gradient Descent', 'Decision Tree', 'Random Forest']\n",
    "\n",
    "index = ['Basic','Time_outlier','Time_/365','Clinic_outlier','Clinic_0-4(2steps)','Clinic_0-1(resizing)']\n",
    "\n",
    "# result_train_df = pd.DataFrame(index = index, columns=test_method_list)\n",
    "# result_test_df = pd.DataFrame(index = index, columns=test_method_list)\n",
    "result_train_df = pd.DataFrame(columns=test_method_list)\n",
    "result_test_df = pd.DataFrame(columns=test_method_list)\n",
    "# result_df[index] = [train-ulre, , ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "first-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model, predict and solve\n",
    "\n",
    "\n",
    "- Methods\n",
    "Logistic Regression\n",
    "KNN or k-Nearest Neighbors\n",
    "Support Vector Machines\n",
    "Naive Bayes classifier\n",
    "Decision Tree\n",
    "Random Forrest\n",
    "Perceptron\n",
    "Artificial neural network\n",
    "RVM or Relevance Vector Machine\n",
    "'''\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def training():\n",
    "    result_train = []\n",
    "    result_test = []\n",
    "    for input_method in test_method_list:\n",
    "        print('*** Method: ', input_method)\n",
    "\n",
    "        if input_method == 'LogisticRegression':\n",
    "            model = LogisticRegression()\n",
    "\n",
    "        elif input_method == 'Support Vector Machines':\n",
    "            model = SVC()\n",
    "\n",
    "        elif input_method == 'KNN or k-Nearest Neighbors':\n",
    "            model = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "        elif input_method == 'Gaussian Naive Bayes':\n",
    "            model = GaussianNB()\n",
    "\n",
    "        elif input_method == 'Perceptron':\n",
    "            model = Perceptron()\n",
    "\n",
    "        elif input_method == 'Linear SVC':\n",
    "            model = LinearSVC()\n",
    "\n",
    "        elif input_method == 'Stochastic Gradient Descent':\n",
    "            model = SGDClassifier()\n",
    "\n",
    "        elif input_method == 'Decision Tree':\n",
    "            model = DecisionTreeClassifier()\n",
    "\n",
    "        elif input_method == 'Random Forest':\n",
    "            model = RandomForestClassifier(n_estimators=100)\n",
    "    \n",
    "        # Train\n",
    "        model.fit(X_train, Y_train)\n",
    "        acc_log = round(model.score(X_train, Y_train) * 100, 2)\n",
    "        print('trained-acc: ', acc_log)\n",
    "        result_train.append(acc_log)\n",
    "\n",
    "\n",
    "        # Test\n",
    "        acc_log = round(model.score(X_test, Y_test) * 100, 2)\n",
    "        print('test-acc: ', acc_log)\n",
    "        result_test.append(acc_log)\n",
    "        print()\n",
    "        print()\n",
    "\n",
    "    result_train_df.loc[result_train_df.shape[0]] = result_train\n",
    "    result_test_df.loc[result_test_df.shape[0]] = result_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "centered-month",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Method:  LogisticRegression\n",
      "trained-acc:  95.89\n",
      "test-acc:  79.0\n",
      "\n",
      "\n",
      "*** Method:  Support Vector Machines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained-acc:  88.89\n",
      "test-acc:  91.0\n",
      "\n",
      "\n",
      "*** Method:  KNN or k-Nearest Neighbors\n",
      "trained-acc:  90.0\n",
      "test-acc:  89.0\n",
      "\n",
      "\n",
      "*** Method:  Gaussian Naive Bayes\n",
      "trained-acc:  85.22\n",
      "test-acc:  72.0\n",
      "\n",
      "\n",
      "*** Method:  Perceptron\n",
      "trained-acc:  92.33\n",
      "test-acc:  84.0\n",
      "\n",
      "\n",
      "*** Method:  Linear SVC\n",
      "trained-acc:  100.0\n",
      "test-acc:  72.0\n",
      "\n",
      "\n",
      "*** Method:  Stochastic Gradient Descent\n",
      "trained-acc:  95.11\n",
      "test-acc:  77.0\n",
      "\n",
      "\n",
      "*** Method:  Decision Tree\n",
      "trained-acc:  100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-acc:  79.0\n",
      "\n",
      "\n",
      "*** Method:  Random Forest\n",
      "trained-acc:  100.0\n",
      "test-acc:  91.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Basic Training & Test\n",
    "\n",
    "'''\n",
    "\n",
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "strange-norfolk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlier of time: \n",
      "905   -7.945621\n",
      "Name: time, dtype: float64\n",
      "\n",
      "              time        event\n",
      "count  1000.000000  1000.000000\n",
      "mean     51.876125     0.891000\n",
      "std      22.122689     0.311795\n",
      "min       7.070708     0.000000\n",
      "25%      37.401307     1.000000\n",
      "50%      47.064712     1.000000\n",
      "75%      60.966476     1.000000\n",
      "max     217.078908     1.000000\n",
      "\n",
      "*** Method:  LogisticRegression\n",
      "trained-acc:  97.0\n",
      "test-acc:  78.0\n",
      "\n",
      "\n",
      "*** Method:  Support Vector Machines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained-acc:  88.89\n",
      "test-acc:  91.0\n",
      "\n",
      "\n",
      "*** Method:  KNN or k-Nearest Neighbors\n",
      "trained-acc:  91.33\n",
      "test-acc:  89.0\n",
      "\n",
      "\n",
      "*** Method:  Gaussian Naive Bayes\n",
      "trained-acc:  85.56\n",
      "test-acc:  74.0\n",
      "\n",
      "\n",
      "*** Method:  Perceptron\n",
      "trained-acc:  91.67\n",
      "test-acc:  88.0\n",
      "\n",
      "\n",
      "*** Method:  Linear SVC\n",
      "trained-acc:  98.22\n",
      "test-acc:  75.0\n",
      "\n",
      "\n",
      "*** Method:  Stochastic Gradient Descent\n",
      "trained-acc:  93.11\n",
      "test-acc:  87.0\n",
      "\n",
      "\n",
      "*** Method:  Decision Tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained-acc:  100.0\n",
      "test-acc:  70.0\n",
      "\n",
      "\n",
      "*** Method:  Random Forest\n",
      "trained-acc:  100.0\n",
      "test-acc:  91.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Add Time data\n",
    "\n",
    "1) outlier value drop\n",
    "2) clustering from step 0-N days to step 0-N/365 days\n",
    "'''\n",
    "\n",
    "'''\n",
    "1)\n",
    "'''\n",
    "print('outlier of time: ')\n",
    "print(df1.loc[df1['time'] < 0, 'time'], end='\\n\\n')\n",
    "\n",
    "df1_outlier = df1.copy()\n",
    "df1_outlier.loc[df1_outlier['time'] < 0, 'time'] = abs(df1_outlier.loc[df1_outlier['time'] < 0, 'time'])\n",
    "print(df1_outlier.describe(), end='\\n\\n')\n",
    "\n",
    "df = pd.concat([df1_outlier,df2,df3,df4], axis=1)\n",
    "train_df, test_df = df.iloc[random_index[:900],:], df.iloc[random_index[900:1000],:]\n",
    "\n",
    "X_train = train_df.drop(['event'], axis=1)\n",
    "Y_train = train_df['event']\n",
    "\n",
    "X_test = test_df.drop(['event'], axis=1)\n",
    "Y_test = test_df['event']\n",
    "\n",
    "\n",
    "'''\n",
    "Add Time data(1) Training & Test\n",
    "\n",
    "'''\n",
    "\n",
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "technical-might",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              time        event\n",
      "count  1000.000000  1000.000000\n",
      "mean      0.142126     0.891000\n",
      "std       0.060610     0.311795\n",
      "min       0.019372     0.000000\n",
      "25%       0.102469     1.000000\n",
      "50%       0.128944     1.000000\n",
      "75%       0.167031     1.000000\n",
      "max       0.594737     1.000000\n",
      "\n",
      "*** Method:  LogisticRegression\n",
      "trained-acc:  95.89\n",
      "test-acc:  79.0\n",
      "\n",
      "\n",
      "*** Method:  Support Vector Machines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained-acc:  88.89\n",
      "test-acc:  91.0\n",
      "\n",
      "\n",
      "*** Method:  KNN or k-Nearest Neighbors\n",
      "trained-acc:  89.67\n",
      "test-acc:  89.0\n",
      "\n",
      "\n",
      "*** Method:  Gaussian Naive Bayes\n",
      "trained-acc:  85.56\n",
      "test-acc:  74.0\n",
      "\n",
      "\n",
      "*** Method:  Perceptron\n",
      "trained-acc:  94.44\n",
      "test-acc:  76.0\n",
      "\n",
      "\n",
      "*** Method:  Linear SVC\n",
      "trained-acc:  99.89\n",
      "test-acc:  73.0\n",
      "\n",
      "\n",
      "*** Method:  Stochastic Gradient Descent\n",
      "trained-acc:  96.22\n",
      "test-acc:  73.0\n",
      "\n",
      "\n",
      "*** Method:  Decision Tree\n",
      "trained-acc: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100.0\n",
      "test-acc:  72.0\n",
      "\n",
      "\n",
      "*** Method:  Random Forest\n",
      "trained-acc:  100.0\n",
      "test-acc:  91.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2)\n",
    "'''\n",
    "df1_normalize = df1_outlier.copy()\n",
    "df1_normalize['time'] = df1_normalize['time']/365.0\n",
    "print(df1_normalize.describe(), end='\\n\\n')\n",
    "\n",
    "df = pd.concat([df1_normalize,df2,df3,df4], axis=1)\n",
    "train_df, test_df = df.iloc[random_index[:900],:], df.iloc[random_index[900:1000],:]\n",
    "\n",
    "X_train = train_df.drop(['event'], axis=1)\n",
    "Y_train = train_df['event']\n",
    "\n",
    "X_test = test_df.drop(['event'], axis=1)\n",
    "Y_test = test_df['event']\n",
    "\n",
    "\n",
    "'''\n",
    "Add Time data(1) Training & Test\n",
    "\n",
    "'''\n",
    "\n",
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "usual-church",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Var1\n",
      "2    235\n",
      "3    204\n",
      "1    171\n",
      "4    139\n",
      "5     95\n",
      "0     57\n",
      "6     50\n",
      "7     27\n",
      "8     13\n",
      "9      9\n",
      "Name: Var1, dtype: int64\n",
      "--------------------\n",
      "# Var2\n",
      "3    221\n",
      "2    218\n",
      "4    163\n",
      "1    113\n",
      "5    109\n",
      "6     65\n",
      "0     48\n",
      "7     30\n",
      "9     20\n",
      "8     13\n",
      "Name: Var2, dtype: int64\n",
      "--------------------\n",
      "# Var3\n",
      "2    260\n",
      "3    196\n",
      "1    156\n",
      "4    130\n",
      "5     97\n",
      "0     55\n",
      "6     55\n",
      "7     23\n",
      "8     16\n",
      "9     12\n",
      "Name: Var3, dtype: int64\n",
      "--------------------\n",
      "# Var4\n",
      "2    242\n",
      "3    195\n",
      "1    150\n",
      "4    140\n",
      "5    106\n",
      "6     67\n",
      "0     36\n",
      "7     32\n",
      "8     16\n",
      "9     16\n",
      "Name: Var4, dtype: int64\n",
      "--------------------\n",
      "# Var5\n",
      "2    247\n",
      "3    223\n",
      "4    161\n",
      "5    124\n",
      "1     76\n",
      "6     63\n",
      "7     41\n",
      "0     28\n",
      "9     19\n",
      "8     18\n",
      "Name: Var5, dtype: int64\n",
      "--------------------\n",
      "# Var6\n",
      "2    240\n",
      "3    212\n",
      "4    128\n",
      "1    127\n",
      "5     99\n",
      "6     64\n",
      "0     53\n",
      "7     40\n",
      "8     20\n",
      "9     17\n",
      "Name: Var6, dtype: int64\n",
      "--------------------\n",
      "# Var7\n",
      "1    269\n",
      "2    208\n",
      "3    144\n",
      "0    128\n",
      "4    118\n",
      "5     62\n",
      "6     47\n",
      "7     16\n",
      "8      6\n",
      "9      2\n",
      "Name: Var7, dtype: int64\n",
      "--------------------\n",
      "# Var8\n",
      "1    241\n",
      "2    227\n",
      "3    171\n",
      "0    127\n",
      "4    101\n",
      "5     69\n",
      "6     30\n",
      "7     20\n",
      "8     10\n",
      "9      4\n",
      "Name: Var8, dtype: int64\n",
      "--------------------\n",
      "# Var9\n",
      "2    250\n",
      "1    235\n",
      "3    157\n",
      "0    135\n",
      "4    100\n",
      "5     57\n",
      "6     33\n",
      "7     22\n",
      "9      6\n",
      "8      5\n",
      "Name: Var9, dtype: int64\n",
      "--------------------\n",
      "# Var10\n",
      "1    287\n",
      "2    205\n",
      "3    156\n",
      "0    114\n",
      "4    108\n",
      "5     62\n",
      "6     40\n",
      "7     18\n",
      "8      5\n",
      "9      5\n",
      "Name: Var10, dtype: int64\n",
      "--------------------\n",
      "\n",
      "*** Method:  LogisticRegression\n",
      "trained-acc:  97.22\n",
      "test-acc:  78.0\n",
      "\n",
      "\n",
      "*** Method:  Support Vector Machines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained-acc:  88.89\n",
      "test-acc:  91.0\n",
      "\n",
      "\n",
      "*** Method:  KNN or k-Nearest Neighbors\n",
      "trained-acc:  91.33\n",
      "test-acc:  89.0\n",
      "\n",
      "\n",
      "*** Method:  Gaussian Naive Bayes\n",
      "trained-acc:  85.67\n",
      "test-acc:  74.0\n",
      "\n",
      "\n",
      "*** Method:  Perceptron\n",
      "trained-acc:  89.56\n",
      "test-acc:  91.0\n",
      "\n",
      "\n",
      "*** Method:  Linear SVC\n",
      "trained-acc:  98.11\n",
      "test-acc:  77.0\n",
      "\n",
      "\n",
      "*** Method:  Stochastic Gradient Descent\n",
      "trained-acc:  93.67\n",
      "test-acc:  87.0\n",
      "\n",
      "\n",
      "*** Method:  Decision Tree\n",
      "trained-acc: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100.0\n",
      "test-acc:  75.0\n",
      "\n",
      "\n",
      "*** Method:  Random Forest\n",
      "trained-acc:  100.0\n",
      "test-acc:  91.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Correlating numerical features of Clinic data\n",
    "\n",
    "- outlier value drop\n",
    "- clustering from step 0-9 to step 0-4(clustering 2 steps)/0-1(just resizing)\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "1)\n",
    "'''\n",
    "df3_outlier = df3.copy()\n",
    "\n",
    "\n",
    "# drop outlier\n",
    "for col in df3_outlier.columns:\n",
    "    for outlier in range(10,13):\n",
    "        df3_outlier = df3_outlier.replace(outlier, 9)\n",
    "\n",
    "# visualize\n",
    "for col in df3_outlier.columns:\n",
    "    print('#', col)\n",
    "    print(df3_outlier[col].value_counts())\n",
    "    print('-'*20)\n",
    "\n",
    "\n",
    "df = pd.concat([df1_outlier,df2,df3_outlier,df4], axis=1)\n",
    "train_df, test_df = df.iloc[random_index[:900],:], df.iloc[random_index[900:1000],:]\n",
    "\n",
    "X_train = train_df.drop(['event'], axis=1)\n",
    "Y_train = train_df['event']\n",
    "\n",
    "X_test = test_df.drop(['event'], axis=1)\n",
    "Y_test = test_df['event']\n",
    "\n",
    "\n",
    "'''\n",
    "Add Time data(1) +  Correlating Clinic data(1) \n",
    "Training & Test\n",
    "'''\n",
    "\n",
    "print()\n",
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "conscious-large",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Var1         Var2         Var3         Var4         Var5  \\\n",
      "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
      "mean      1.226000     1.400000     1.256000     1.354000     1.500000   \n",
      "std       0.958041     0.975167     0.968195     0.995829     0.942809   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "50%       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "75%       2.000000     2.000000     2.000000     2.000000     2.000000   \n",
      "max       4.000000     4.000000     4.000000     4.000000     4.000000   \n",
      "\n",
      "              Var6         Var7         Var8         Var9        Var10  \n",
      "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  \n",
      "mean      1.366000     0.933000     0.944000     0.930000     0.915000  \n",
      "std       1.011468     0.947316     0.928292     0.917574     0.941627  \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "25%       1.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "50%       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
      "75%       2.000000     2.000000     1.000000     1.000000     1.000000  \n",
      "max       4.000000     4.000000     4.000000     4.000000     4.000000  \n",
      "\n",
      "*** Method:  LogisticRegression\n",
      "trained-acc:  96.56\n",
      "test-acc:  82.0\n",
      "\n",
      "\n",
      "*** Method:  Support Vector Machines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained-acc:  88.89\n",
      "test-acc:  91.0\n",
      "\n",
      "\n",
      "*** Method:  KNN or k-Nearest Neighbors\n",
      "trained-acc:  92.22\n",
      "test-acc:  89.0\n",
      "\n",
      "\n",
      "*** Method:  Gaussian Naive Bayes\n",
      "trained-acc:  85.78\n",
      "test-acc:  74.0\n",
      "\n",
      "\n",
      "*** Method:  Perceptron\n",
      "trained-acc:  89.56\n",
      "test-acc:  91.0\n",
      "\n",
      "\n",
      "*** Method:  Linear SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained-acc:  97.0\n",
      "test-acc:  79.0\n",
      "\n",
      "\n",
      "*** Method:  Stochastic Gradient Descent\n",
      "trained-acc:  94.22\n",
      "test-acc:  83.0\n",
      "\n",
      "\n",
      "*** Method:  Decision Tree\n",
      "trained-acc:  100.0\n",
      "test-acc:  72.0\n",
      "\n",
      "\n",
      "*** Method:  Random Forest\n",
      "trained-acc:  100.0\n",
      "test-acc:  91.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2-1) 2 steps clustering(0-4)\n",
    "'''\n",
    "df3_2c = df3_outlier.copy()\n",
    "\n",
    "for col in df3_2c.columns:\n",
    "    df3_2c.loc[df3_2c[col] <= 1, col] = 0\n",
    "    df3_2c.loc[(df3_2c[col] > 1) & (df3_2c[col] <= 3), col] = 1\n",
    "    df3_2c.loc[(df3_2c[col] > 3) & (df3_2c[col] <= 5), col] = 2\n",
    "    df3_2c.loc[(df3_2c[col] > 5) & (df3_2c[col] <= 7), col] = 3\n",
    "    df3_2c.loc[(df3_2c[col] > 7) & (df3_2c[col] <= 9), col] = 4\n",
    "\n",
    "print(df3_2c.describe(), end='\\n\\n')\n",
    "\n",
    "df = pd.concat([df1_outlier,df2,df3_2c,df4], axis=1)\n",
    "train_df, test_df = df.iloc[random_index[:900],:], df.iloc[random_index[900:1000],:]\n",
    "\n",
    "X_train = train_df.drop(['event'], axis=1)\n",
    "Y_train = train_df['event']\n",
    "\n",
    "X_test = test_df.drop(['event'], axis=1)\n",
    "Y_test = test_df['event']\n",
    "\n",
    "\n",
    "'''\n",
    "Add Time data(1) +  Correlating Clinic data(2-1) \n",
    "Training & Test\n",
    "'''\n",
    "\n",
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "colonial-maryland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Var1         Var2         Var3         Var4         Var5  \\\n",
      "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
      "mean      0.328667     0.365889     0.332889     0.356333     0.387000   \n",
      "std       0.207386     0.214559     0.210689     0.216080     0.210446   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.222222     0.222222     0.222222     0.222222     0.222222   \n",
      "50%       0.333333     0.333333     0.333333     0.333333     0.333333   \n",
      "75%       0.444444     0.444444     0.444444     0.444444     0.555556   \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "              Var6         Var7         Var8         Var9        Var10  \n",
      "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  \n",
      "mean      0.358556     0.262111     0.265889     0.259667     0.262000  \n",
      "std       0.223040     0.201703     0.202755     0.201437     0.201204  \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "25%       0.222222     0.111111     0.111111     0.111111     0.111111  \n",
      "50%       0.333333     0.222222     0.222222     0.222222     0.222222  \n",
      "75%       0.444444     0.444444     0.333333     0.333333     0.333333  \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
      "\n",
      "*** Method:  LogisticRegression\n",
      "trained-acc:  96.56\n",
      "test-acc:  79.0\n",
      "\n",
      "\n",
      "*** Method:  Support Vector Machines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained-acc:  88.89\n",
      "test-acc:  91.0\n",
      "\n",
      "\n",
      "*** Method:  KNN or k-Nearest Neighbors\n",
      "trained-acc:  92.0\n",
      "test-acc:  89.0\n",
      "\n",
      "\n",
      "*** Method:  Gaussian Naive Bayes\n",
      "trained-acc:  85.67\n",
      "test-acc:  74.0\n",
      "\n",
      "\n",
      "*** Method:  Perceptron\n",
      "trained-acc:  89.67\n",
      "test-acc:  91.0\n",
      "\n",
      "\n",
      "*** Method:  Linear SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained-acc:  98.33\n",
      "test-acc:  73.0\n",
      "\n",
      "\n",
      "*** Method:  Stochastic Gradient Descent\n",
      "trained-acc:  90.78\n",
      "test-acc:  91.0\n",
      "\n",
      "\n",
      "*** Method:  Decision Tree\n",
      "trained-acc:  100.0\n",
      "test-acc:  72.0\n",
      "\n",
      "\n",
      "*** Method:  Random Forest\n",
      "trained-acc:  100.0\n",
      "test-acc:  91.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2-2) just resizing(0-1)\n",
    "'''\n",
    "df3_rs = df3_outlier.copy()\n",
    "\n",
    "for col in df3_rs.columns:\n",
    "    df3_rs[col] = df3_rs[col]/9\n",
    "\n",
    "print(df3_rs.describe(), end='\\n\\n')\n",
    "\n",
    "df = pd.concat([df1_outlier,df2,df3_rs,df4], axis=1)\n",
    "train_df, test_df = df.iloc[random_index[:900],:], df.iloc[random_index[900:1000],:]\n",
    "\n",
    "X_train = train_df.drop(['event'], axis=1)\n",
    "Y_train = train_df['event']\n",
    "\n",
    "X_test = test_df.drop(['event'], axis=1)\n",
    "Y_test = test_df['event']\n",
    "\n",
    "\n",
    "'''\n",
    "Add Time data(1) +  Correlating Clinic data(2-2) \n",
    "Training & Test\n",
    "'''\n",
    "\n",
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "delayed-journalist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel parameters\\n\\nresult collection\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model parameters\n",
    "\n",
    "result collection\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0bea627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** train result ***\n",
      "\n",
      "                      LogisticRegression  Support Vector Machines  \\\n",
      "Basic                              95.89                    88.89   \n",
      "Time_outlier                       97.00                    88.89   \n",
      "Time_/365                          95.89                    88.89   \n",
      "Clinic_outlier                     97.22                    88.89   \n",
      "Clinic_0-4(2steps)                 96.56                    88.89   \n",
      "Clinic_0-1(resizing)               96.56                    88.89   \n",
      "\n",
      "                      KNN or k-Nearest Neighbors  Gaussian Naive Bayes  \\\n",
      "Basic                                      90.00                 85.22   \n",
      "Time_outlier                               91.33                 85.56   \n",
      "Time_/365                                  89.67                 85.56   \n",
      "Clinic_outlier                             91.33                 85.67   \n",
      "Clinic_0-4(2steps)                         92.22                 85.78   \n",
      "Clinic_0-1(resizing)                       92.00                 85.67   \n",
      "\n",
      "                      Perceptron  Linear SVC  Stochastic Gradient Descent  \\\n",
      "Basic                      92.33      100.00                        95.11   \n",
      "Time_outlier               91.67       98.22                        93.11   \n",
      "Time_/365                  94.44       99.89                        96.22   \n",
      "Clinic_outlier             89.56       98.11                        93.67   \n",
      "Clinic_0-4(2steps)         89.56       97.00                        94.22   \n",
      "Clinic_0-1(resizing)       89.67       98.33                        90.78   \n",
      "\n",
      "                      Decision Tree  Random Forest  \n",
      "Basic                         100.0          100.0  \n",
      "Time_outlier                  100.0          100.0  \n",
      "Time_/365                     100.0          100.0  \n",
      "Clinic_outlier                100.0          100.0  \n",
      "Clinic_0-4(2steps)            100.0          100.0  \n",
      "Clinic_0-1(resizing)          100.0          100.0  \n",
      "\n",
      "\n",
      "\n",
      "*** test result ***\n",
      "\n",
      "                      LogisticRegression  Support Vector Machines  \\\n",
      "Basic                               79.0                     91.0   \n",
      "Time_outlier                        78.0                     91.0   \n",
      "Time_/365                           79.0                     91.0   \n",
      "Clinic_outlier                      78.0                     91.0   \n",
      "Clinic_0-4(2steps)                  82.0                     91.0   \n",
      "Clinic_0-1(resizing)                79.0                     91.0   \n",
      "\n",
      "                      KNN or k-Nearest Neighbors  Gaussian Naive Bayes  \\\n",
      "Basic                                       89.0                  72.0   \n",
      "Time_outlier                                89.0                  74.0   \n",
      "Time_/365                                   89.0                  74.0   \n",
      "Clinic_outlier                              89.0                  74.0   \n",
      "Clinic_0-4(2steps)                          89.0                  74.0   \n",
      "Clinic_0-1(resizing)                        89.0                  74.0   \n",
      "\n",
      "                      Perceptron  Linear SVC  Stochastic Gradient Descent  \\\n",
      "Basic                       84.0        72.0                         77.0   \n",
      "Time_outlier                88.0        75.0                         87.0   \n",
      "Time_/365                   76.0        73.0                         73.0   \n",
      "Clinic_outlier              91.0        77.0                         87.0   \n",
      "Clinic_0-4(2steps)          91.0        79.0                         83.0   \n",
      "Clinic_0-1(resizing)        91.0        73.0                         91.0   \n",
      "\n",
      "                      Decision Tree  Random Forest  \n",
      "Basic                          79.0           91.0  \n",
      "Time_outlier                   70.0           91.0  \n",
      "Time_/365                      72.0           91.0  \n",
      "Clinic_outlier                 75.0           91.0  \n",
      "Clinic_0-4(2steps)             72.0           91.0  \n",
      "Clinic_0-1(resizing)           72.0           91.0  \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('*** train result ***', end='\\n\\n')\n",
    "result_train_df.index = index\n",
    "print(result_train_df)\n",
    "print(end='\\n\\n\\n')\n",
    "\n",
    "print('*** test result ***', end='\\n\\n')\n",
    "result_test_df.index = index\n",
    "print(result_test_df)\n",
    "print(end='\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99029de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       LogisticRegression  Support Vector Machines  \\\n",
      "count             6.00000                     6.00   \n",
      "mean             96.52000                    88.89   \n",
      "std               0.55089                     0.00   \n",
      "min              95.89000                    88.89   \n",
      "25%              96.05750                    88.89   \n",
      "50%              96.56000                    88.89   \n",
      "75%              96.89000                    88.89   \n",
      "max              97.22000                    88.89   \n",
      "\n",
      "       KNN or k-Nearest Neighbors  Gaussian Naive Bayes  Perceptron  \\\n",
      "count                    6.000000              6.000000    6.000000   \n",
      "mean                    91.091667             85.576667   91.205000   \n",
      "std                      1.041603              0.193149    1.985716   \n",
      "min                     89.670000             85.220000   89.560000   \n",
      "25%                     90.332500             85.560000   89.587500   \n",
      "50%                     91.330000             85.615000   90.670000   \n",
      "75%                     91.832500             85.670000   92.165000   \n",
      "max                     92.220000             85.780000   94.440000   \n",
      "\n",
      "       Linear SVC  Stochastic Gradient Descent  Decision Tree  Random Forest  \n",
      "count    6.000000                     6.000000            6.0            6.0  \n",
      "mean    98.591667                    93.851667          100.0          100.0  \n",
      "std      1.152483                     1.862594            0.0            0.0  \n",
      "min     97.000000                    90.780000          100.0          100.0  \n",
      "25%     98.137500                    93.250000          100.0          100.0  \n",
      "50%     98.275000                    93.945000          100.0          100.0  \n",
      "75%     99.500000                    94.887500          100.0          100.0  \n",
      "max    100.000000                    96.220000          100.0          100.0  \n"
     ]
    }
   ],
   "source": [
    "print(result_train_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce0ea3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       LogisticRegression  Support Vector Machines  \\\n",
      "count            6.000000                      6.0   \n",
      "mean            79.166667                     91.0   \n",
      "std              1.471960                      0.0   \n",
      "min             78.000000                     91.0   \n",
      "25%             78.250000                     91.0   \n",
      "50%             79.000000                     91.0   \n",
      "75%             79.000000                     91.0   \n",
      "max             82.000000                     91.0   \n",
      "\n",
      "       KNN or k-Nearest Neighbors  Gaussian Naive Bayes  Perceptron  \\\n",
      "count                         6.0              6.000000    6.000000   \n",
      "mean                         89.0             73.666667   86.833333   \n",
      "std                           0.0              0.816497    5.980524   \n",
      "min                          89.0             72.000000   76.000000   \n",
      "25%                          89.0             74.000000   85.000000   \n",
      "50%                          89.0             74.000000   89.500000   \n",
      "75%                          89.0             74.000000   91.000000   \n",
      "max                          89.0             74.000000   91.000000   \n",
      "\n",
      "       Linear SVC  Stochastic Gradient Descent  Decision Tree  Random Forest  \n",
      "count    6.000000                     6.000000       6.000000            6.0  \n",
      "mean    74.833333                    83.000000      73.333333           91.0  \n",
      "std      2.714160                     6.811755       3.204164            0.0  \n",
      "min     72.000000                    73.000000      70.000000           91.0  \n",
      "25%     73.000000                    78.500000      72.000000           91.0  \n",
      "50%     74.000000                    85.000000      72.000000           91.0  \n",
      "75%     76.500000                    87.000000      74.250000           91.0  \n",
      "max     79.000000                    91.000000      79.000000           91.0  \n"
     ]
    }
   ],
   "source": [
    "print(result_test_df.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
