{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exclusive-religious",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\anaconda3\\lib\\site-packages (from xgboost) (1.6.2)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\lib\\site-packages (from xgboost) (1.20.1)\n",
      "Requirement already satisfied: lightgbm in c:\\anaconda3\\lib\\site-packages (3.2.1)\n",
      "Requirement already satisfied: wheel in c:\\anaconda3\\lib\\site-packages (from lightgbm) (0.36.2)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\anaconda3\\lib\\site-packages (from lightgbm) (0.24.1)\n",
      "Requirement already satisfied: scipy in c:\\anaconda3\\lib\\site-packages (from lightgbm) (1.6.2)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\lib\\site-packages (from lightgbm) (1.20.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.8.1-py3-none-any.whl (189 kB)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.20.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in c:\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.24.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (2.1.0)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.8.1 imblearn-0.0\n",
      "Collecting borutashap\n",
      "  Downloading BorutaShap-1.0.16-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\anaconda3\\lib\\site-packages (from borutashap) (0.24.1)\n",
      "Requirement already satisfied: seaborn in c:\\anaconda3\\lib\\site-packages (from borutashap) (0.11.1)\n",
      "Requirement already satisfied: pandas in c:\\anaconda3\\lib\\site-packages (from borutashap) (1.2.4)\n",
      "Requirement already satisfied: matplotlib in c:\\anaconda3\\lib\\site-packages (from borutashap) (3.3.4)\n",
      "Collecting shap>=0.34.0\n",
      "  Downloading shap-0.39.0-cp38-cp38-win_amd64.whl (414 kB)\n",
      "Requirement already satisfied: tqdm in c:\\anaconda3\\lib\\site-packages (from borutashap) (4.59.0)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\lib\\site-packages (from borutashap) (1.20.1)\n",
      "Requirement already satisfied: scipy in c:\\anaconda3\\lib\\site-packages (from borutashap) (1.6.2)\n",
      "Requirement already satisfied: statsmodels in c:\\anaconda3\\lib\\site-packages (from borutashap) (0.12.2)\n",
      "Collecting slicer==0.0.7\n",
      "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numba in c:\\anaconda3\\lib\\site-packages (from shap>=0.34.0->borutashap) (0.53.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\anaconda3\\lib\\site-packages (from shap>=0.34.0->borutashap) (1.6.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\anaconda3\\lib\\site-packages (from matplotlib->borutashap) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\anaconda3\\lib\\site-packages (from matplotlib->borutashap) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\anaconda3\\lib\\site-packages (from matplotlib->borutashap) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\anaconda3\\lib\\site-packages (from matplotlib->borutashap) (8.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\anaconda3\\lib\\site-packages (from matplotlib->borutashap) (2.8.1)\n",
      "Requirement already satisfied: six in c:\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->borutashap) (1.15.0)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda3\\lib\\site-packages (from numba->shap>=0.34.0->borutashap) (52.0.0.post20210125)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in c:\\anaconda3\\lib\\site-packages (from numba->shap>=0.34.0->borutashap) (0.36.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\anaconda3\\lib\\site-packages (from pandas->borutashap) (2021.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda3\\lib\\site-packages (from scikit-learn->borutashap) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\anaconda3\\lib\\site-packages (from scikit-learn->borutashap) (1.0.1)\n",
      "Requirement already satisfied: patsy>=0.5 in c:\\anaconda3\\lib\\site-packages (from statsmodels->borutashap) (0.5.1)\n",
      "Installing collected packages: slicer, shap, borutashap\n",
      "Successfully installed borutashap-1.0.16 shap-0.39.0 slicer-0.0.7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "!pip install xgboost\n",
    "!pip install lightgbm\n",
    "!pip install imblearn\n",
    "!pip install borutashap\n",
    "plt.rcParams[\"figure.figsize\"] = (20,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "analyzed-entity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('Survival_time_event.csv', index_col=0)\n",
    "# df2=pd.read_csv('Treatment.csv', index_col=0)\n",
    "df3=pd.read_csv('Clinical_Variables.csv', index_col=0)\n",
    "df4=pd.read_csv('Genetic_alterations.csv', index_col=0)\n",
    "df5=pd.read_csv('newLabel.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "strange-norfolk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlier of time: \n",
      "905   -7.945621\n",
      "Name: time, dtype: float64\n",
      "\n",
      "              time        event\n",
      "count  1000.000000  1000.000000\n",
      "mean     51.876125     0.891000\n",
      "std      22.122689     0.311795\n",
      "min       7.070708     0.000000\n",
      "25%      37.401307     1.000000\n",
      "50%      47.064712     1.000000\n",
      "75%      60.966476     1.000000\n",
      "max     217.078908     1.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Correlating numerical features of Time data\n",
    "\n",
    "- outlier value drop\n",
    "'''\n",
    "\n",
    "print('outlier of time: ')\n",
    "print(df1.loc[df1['time'] < 0, 'time'], end='\\n\\n')\n",
    "\n",
    "df1_outlier = df1.copy()\n",
    "df1_outlier.loc[df1_outlier['time'] < 0, 'time'] = abs(df1_outlier.loc[df1_outlier['time'] < 0, 'time'])\n",
    "print(df1_outlier.describe(), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "usual-church",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Var1\n",
      "2    235\n",
      "3    204\n",
      "1    171\n",
      "4    139\n",
      "5     95\n",
      "0     57\n",
      "6     50\n",
      "7     27\n",
      "8     13\n",
      "9      9\n",
      "Name: Var1, dtype: int64\n",
      "--------------------\n",
      "# Var2\n",
      "3    221\n",
      "2    218\n",
      "4    163\n",
      "1    113\n",
      "5    109\n",
      "6     65\n",
      "0     48\n",
      "7     30\n",
      "9     20\n",
      "8     13\n",
      "Name: Var2, dtype: int64\n",
      "--------------------\n",
      "# Var3\n",
      "2    260\n",
      "3    196\n",
      "1    156\n",
      "4    130\n",
      "5     97\n",
      "0     55\n",
      "6     55\n",
      "7     23\n",
      "8     16\n",
      "9     12\n",
      "Name: Var3, dtype: int64\n",
      "--------------------\n",
      "# Var4\n",
      "2    242\n",
      "3    195\n",
      "1    150\n",
      "4    140\n",
      "5    106\n",
      "6     67\n",
      "0     36\n",
      "7     32\n",
      "8     16\n",
      "9     16\n",
      "Name: Var4, dtype: int64\n",
      "--------------------\n",
      "# Var5\n",
      "2    247\n",
      "3    223\n",
      "4    161\n",
      "5    124\n",
      "1     76\n",
      "6     63\n",
      "7     41\n",
      "0     28\n",
      "9     19\n",
      "8     18\n",
      "Name: Var5, dtype: int64\n",
      "--------------------\n",
      "# Var6\n",
      "2    240\n",
      "3    212\n",
      "4    128\n",
      "1    127\n",
      "5     99\n",
      "6     64\n",
      "0     53\n",
      "7     40\n",
      "8     20\n",
      "9     17\n",
      "Name: Var6, dtype: int64\n",
      "--------------------\n",
      "# Var7\n",
      "1    269\n",
      "2    208\n",
      "3    144\n",
      "0    128\n",
      "4    118\n",
      "5     62\n",
      "6     47\n",
      "7     16\n",
      "8      6\n",
      "9      2\n",
      "Name: Var7, dtype: int64\n",
      "--------------------\n",
      "# Var8\n",
      "1    241\n",
      "2    227\n",
      "3    171\n",
      "0    127\n",
      "4    101\n",
      "5     69\n",
      "6     30\n",
      "7     20\n",
      "8     10\n",
      "9      4\n",
      "Name: Var8, dtype: int64\n",
      "--------------------\n",
      "# Var9\n",
      "2    250\n",
      "1    235\n",
      "3    157\n",
      "0    135\n",
      "4    100\n",
      "5     57\n",
      "6     33\n",
      "7     22\n",
      "9      6\n",
      "8      5\n",
      "Name: Var9, dtype: int64\n",
      "--------------------\n",
      "# Var10\n",
      "1    287\n",
      "2    205\n",
      "3    156\n",
      "0    114\n",
      "4    108\n",
      "5     62\n",
      "6     40\n",
      "7     18\n",
      "8      5\n",
      "9      5\n",
      "Name: Var10, dtype: int64\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Correlating numerical features of Clinic data\n",
    "\n",
    "- outlier value drop\n",
    "'''\n",
    "\n",
    "df3_outlier = df3.copy()\n",
    "\n",
    "\n",
    "# drop outlier\n",
    "for col in df3_outlier.columns:\n",
    "    for outlier in range(10,13):\n",
    "        df3_outlier = df3_outlier.replace(outlier, 9)\n",
    "\n",
    "# visualize\n",
    "for col in df3_outlier.columns:\n",
    "    print('#', col)\n",
    "    print(df3_outlier[col].value_counts())\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "married-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "thick-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dataset of Best Accuracy\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "df = pd.concat([df5, df1_outlier, df3_outlier ,df4], axis=1)\n",
    "df = df.drop(['event'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "signed-interval",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model list\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "ensemble_models = [\n",
    "    ('lrcv', LogisticRegressionCV(max_iter = 10000)),\n",
    "    ('ada', AdaBoostClassifier()),\n",
    "    ('bc', BaggingClassifier()),\n",
    "    ('etc',ExtraTreesClassifier()),\n",
    "    ('gbc', GradientBoostingClassifier()),\n",
    "    ('rfc', RandomForestClassifier(n_estimators=20)),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors = 4)),\n",
    "    ('svc', SVC(probability=True)),\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss')),\n",
    "    ('lgbm', LGBMClassifier()),\n",
    "    ('dtc', DecisionTreeClassifier()),\n",
    "    ('gnb',GaussianNB()),\n",
    "]\n",
    "\n",
    "models = [VotingClassifier(ensemble_models, voting='soft'),\n",
    "          LogisticRegression(max_iter = 10000), SVC(), KNeighborsClassifier(n_neighbors = 4), \n",
    "          GaussianNB(), Perceptron(),\n",
    "          SGDClassifier(), \n",
    "          DecisionTreeClassifier(), RandomForestClassifier(n_estimators=20)]\n",
    "#LinearSVC(max_iter=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "extra-retention",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Select Model of Best Accuracy\n",
    "\n",
    "\n",
    "'''\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def training(model_list):\n",
    "    best_model = []\n",
    "    for model in model_list:\n",
    "        model_name = str(model)[:str(model).find('(')]\n",
    "        print('Model: ', model_name)\n",
    "        print()\n",
    "        features = df.drop(['newlabel'], axis=1)\n",
    "        labels = df['newlabel']\n",
    "        \n",
    "        splits = [5, 10, 7]\n",
    "        \n",
    "        for s in splits:\n",
    "            skfold = StratifiedKFold(n_splits=s)\n",
    "            idx_iter=0\n",
    "            cv_accuracy=[]\n",
    "            cv_precision=[]\n",
    "            cv_recall=[]\n",
    "            cv_f1score=[]\n",
    "\n",
    "            for i in range(20):\n",
    "                features = features.sample(frac=1).reset_index(drop=True)\n",
    "                labels = labels.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "                for train_index, test_index in skfold.split(features,labels):\n",
    "                    np.random.shuffle(train_index)\n",
    "                    np.random.shuffle(test_index)\n",
    "\n",
    "                    # split train and test set\n",
    "                    X_train, X_test = features.iloc[train_index,:], features.iloc[test_index,:]\n",
    "                    y_train, y_test = labels.iloc[train_index], labels.iloc[test_index]\n",
    "\n",
    "                    # train ans prediction\n",
    "                    model.fit(X_train, y_train)\n",
    "                    pred = model.predict(X_test)\n",
    "\n",
    "                    idx_iter += 1\n",
    "\n",
    "                    # \n",
    "                    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "                    cv_accuracy.append(accuracy)\n",
    "\n",
    "                    precision = np.round(precision_score(y_test, pred, average='weighted', zero_division=0), 4)\n",
    "                    cv_precision.append(precision)\n",
    "\n",
    "                    recall = np.round(recall_score(y_test, pred, average='weighted', zero_division=0), 4)\n",
    "                    cv_recall.append(recall)\n",
    "\n",
    "                    f1score = np.round(f1_score(y_test, pred, average='weighted', zero_division=0), 4)\n",
    "                    cv_f1score.append(f1score)\n",
    "\n",
    "                    #train_size = X_train.shape[0]\n",
    "                    #test_size = X_test.shape[0]\n",
    "\n",
    "                    #print('\\n#{0} 교차 검증 정확도: {1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'.format(idx_iter, accuracy, train_size, test_size))\n",
    "                    #print('#{0} 검증 세트 인덱스: MIN{1}, MAX{2}'.format(idx_iter, min(test_index), max(test_index)))\n",
    "\n",
    "                    #print('학습 레이블 데이터 분포: \\n', pd.Series(y_train).value_counts())\n",
    "                    #print('검증 레이블 데이터 분포: \\n', pd.Series(y_test).value_counts())\n",
    "\n",
    "            print('## 교차 검증 총 횟수: ', len(cv_accuracy), '(분할개수:', s, ')')\n",
    "            #print('\\n## 교차 검증별 정확도: ', np.round(cv_accuracy, 4))\n",
    "            print('## 평균 검증 정확도: ', np.round(np.mean(cv_accuracy), 5))\n",
    "            print('## 평균 검증 F1 Score: ', np.round(np.mean(cv_f1score), 5))\n",
    "            print('##')\n",
    "            #save model name, split num, acc, pre, rec, f1\n",
    "            best_model.append([model_name, s, \n",
    "                               np.round(np.mean(cv_accuracy), 5), \n",
    "                               np.round(np.mean(cv_precision), 5),\n",
    "                               np.round(np.mean(cv_recall), 5),\n",
    "                               np.round(np.mean(cv_f1score), 5)])\n",
    "        print()\n",
    "        print('-'*100)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-pulse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  VotingClassifier\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_best_model = np.array(best_model)\n",
    "max_model = np.argmax(np_best_model, axis=0)\n",
    "print(best_model[max_model,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.2, random_state=42)\n",
    "\n",
    "def modeling(model):\n",
    "    skfold = StratifiedKFold(n_splits=10)\n",
    "    cv_accuracy=[]\n",
    "    cv_f1score=[]\n",
    "\n",
    "    for i in range(20):\n",
    "        features = features.sample(frac=1).reset_index(drop=True)\n",
    "        labels = labels.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        for train_index, test_index in skfold.split(features,label):\n",
    "            np.random.shuffle(train_index)\n",
    "            np.random.shuffle(test_index)\n",
    "\n",
    "            # split train and test set\n",
    "            X_train, X_test = features.iloc[train_index,:], features.iloc[test_index,:]\n",
    "            y_train, y_test = labels.iloc[train_index], labels.iloc[test_index]\n",
    "\n",
    "            # train ans prediction\n",
    "            model.fit(X_train, y_train)\n",
    "            model.predict(X_test)\n",
    "            \n",
    "            accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "            cv_accuracy.append(accuracy)\n",
    "\n",
    "            f1score = np.round(f1_score(y_test, pred, average='weighted', zero_division=0), 4)\n",
    "            cv_f1score.append(f1score)\n",
    "\n",
    "    print('## 교차 검증 총 횟수: ', len(cv_accuracy))\n",
    "    print('## 평균 검증 정확도: ', np.round(np.mean(cv_accuracy), 5))\n",
    "    print('## 평균 검증 F1 Score: ', np.round(np.mean(cv_f1score), 5))\n",
    "\n",
    "modeling(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "comprehensive-calculation",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Feature selection\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "from BorutaShap import BorutaShap\n",
    "import shap\n",
    "from eli5.lightgbm import *\n",
    "from eli5.sklearn import *\n",
    "import eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Feature selection Method 1\n",
    "\n",
    "BorutaShap\n",
    "\n",
    "'''\n",
    "\n",
    "Feature_Selector = BorutaShap(model=best_model, importance_measure='shap', classification=True)\n",
    "Feature_Selector.fit(X=X_train, y=Y_train, n_trials=50, random_state=0)\n",
    "Feature_Selector.plot(X_size=12, which_features='all', figsize=(48,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Feature selection Method 2\n",
    "\n",
    "TreeExplainer\n",
    "\n",
    "'''\n",
    "\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "fig = shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Feature selection Method 3\n",
    "\n",
    "PermutationImportance\n",
    "\n",
    "'''\n",
    "\n",
    "perm = PermutationImportance(best_model, random_state=42).fit(X_test, y_test)\n",
    "#print(eli5.format_as_text(explain_weights.explain_permutation_importance(perm, feature_names = X_test.columns.values, top=40)))\n",
    "explain_weights.explain_permutation_importance(perm, feature_names = X_test.columns.values, top=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
