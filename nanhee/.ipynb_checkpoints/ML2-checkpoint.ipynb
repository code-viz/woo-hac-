{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exclusive-religious",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\lib\\site-packages (from xgboost) (1.20.1)\n",
      "Requirement already satisfied: scipy in c:\\anaconda3\\lib\\site-packages (from xgboost) (1.6.2)\n",
      "Requirement already satisfied: lightgbm in c:\\anaconda3\\lib\\site-packages (3.2.1)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\lib\\site-packages (from lightgbm) (1.20.1)\n",
      "Requirement already satisfied: wheel in c:\\anaconda3\\lib\\site-packages (from lightgbm) (0.36.2)\n",
      "Requirement already satisfied: scipy in c:\\anaconda3\\lib\\site-packages (from lightgbm) (1.6.2)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\anaconda3\\lib\\site-packages (from lightgbm) (0.24.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "!pip install xgboost\n",
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "analyzed-entity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('Survival_time_event.csv', index_col=0)\n",
    "df2=pd.read_csv('Treatment.csv', index_col=0)\n",
    "df3=pd.read_csv('Clinical_Variables.csv', index_col=0)\n",
    "df4=pd.read_csv('Genetic_alterations.csv', index_col=0)\n",
    "df5=pd.read_csv('Label.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aware-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df5,df1,df2,df3,df4], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "municipal-percentage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['label' 'time' 'Var1' 'Var2' 'Var3' 'Var4' 'Var5' 'Var6' 'Var7' 'Var8'\n",
      " 'Var9' 'Var10' 'G1' 'G2' 'G3' 'G4' 'G5' 'G6' 'G7' 'G8' 'G9' 'G10' 'G11'\n",
      " 'G12' 'G13' 'G14' 'G15' 'G16' 'G17' 'G18' 'G19' 'G20' 'G21' 'G22' 'G23'\n",
      " 'G24' 'G25' 'G26' 'G27' 'G28' 'G29' 'G30' 'G31' 'G32' 'G33' 'G34' 'G35'\n",
      " 'G36' 'G37' 'G38' 'G39' 'G40' 'G41' 'G42' 'G43' 'G44' 'G45' 'G46' 'G47'\n",
      " 'G48' 'G49' 'G50' 'G51' 'G52' 'G53' 'G54' 'G55' 'G56' 'G57' 'G58' 'G59'\n",
      " 'G60' 'G61' 'G62' 'G63' 'G64' 'G65' 'G66' 'G67' 'G68' 'G69' 'G70' 'G71'\n",
      " 'G72' 'G73' 'G74' 'G75' 'G76' 'G77' 'G78' 'G79' 'G80' 'G81' 'G82' 'G83'\n",
      " 'G84' 'G85' 'G86' 'G87' 'G88' 'G89' 'G90' 'G91' 'G92' 'G93' 'G94' 'G95'\n",
      " 'G96' 'G97' 'G98' 'G99' 'G100' 'G101' 'G102' 'G103' 'G104' 'G105' 'G106'\n",
      " 'G107' 'G108' 'G109' 'G110' 'G111' 'G112' 'G113' 'G114' 'G115' 'G116'\n",
      " 'G117' 'G118' 'G119' 'G120' 'G121' 'G122' 'G123' 'G124' 'G125' 'G126'\n",
      " 'G127' 'G128' 'G129' 'G130' 'G131' 'G132' 'G133' 'G134' 'G135' 'G136'\n",
      " 'G137' 'G138' 'G139' 'G140' 'G141' 'G142' 'G143' 'G144' 'G145' 'G146'\n",
      " 'G147' 'G148' 'G149' 'G150' 'G151' 'G152' 'G153' 'G154' 'G155' 'G156'\n",
      " 'G157' 'G158' 'G159' 'G160' 'G161' 'G162' 'G163' 'G164' 'G165' 'G166'\n",
      " 'G167' 'G168' 'G169' 'G170' 'G171' 'G172' 'G173' 'G174' 'G175' 'G176'\n",
      " 'G177' 'G178' 'G179' 'G180' 'G181' 'G182' 'G183' 'G184' 'G185' 'G186'\n",
      " 'G187' 'G188' 'G189' 'G190' 'G191' 'G192' 'G193' 'G194' 'G195' 'G196'\n",
      " 'G197' 'G198' 'G199' 'G200' 'G201' 'G202' 'G203' 'G204' 'G205' 'G206'\n",
      " 'G207' 'G208' 'G209' 'G210' 'G211' 'G212' 'G213' 'G214' 'G215' 'G216'\n",
      " 'G217' 'G218' 'G219' 'G220' 'G221' 'G222' 'G223' 'G224' 'G225' 'G226'\n",
      " 'G227' 'G228' 'G229' 'G230' 'G231' 'G232' 'G233' 'G234' 'G235' 'G236'\n",
      " 'G237' 'G238' 'G239' 'G240' 'G241' 'G242' 'G243' 'G244' 'G245' 'G246'\n",
      " 'G247' 'G248' 'G249' 'G250' 'G251' 'G252' 'G253' 'G254' 'G255' 'G256'\n",
      " 'G257' 'G258' 'G259' 'G260' 'G261' 'G262' 'G263' 'G264' 'G265' 'G266'\n",
      " 'G267' 'G268' 'G269' 'G270' 'G271' 'G272' 'G273' 'G274' 'G275' 'G276'\n",
      " 'G277' 'G278' 'G279' 'G280' 'G281' 'G282' 'G283' 'G284' 'G285' 'G286'\n",
      " 'G287' 'G288' 'G289' 'G290' 'G291' 'G292' 'G293' 'G294' 'G295' 'G296'\n",
      " 'G297' 'G298' 'G299' 'G300']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Analyze by describing data\n",
    "'''\n",
    "'''\n",
    "label class\n",
    "\n",
    "치료o + 사망x -> class 1\n",
    "나머지 경우 -> class 0\n",
    "\n",
    "'''\n",
    "\n",
    "df = df.drop(['event', 'Treatment'], axis=1)\n",
    "\n",
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baking-nevada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label       time  Var1  Var2  Var3  Var4  Var5  Var6  Var7  Var8  ...  \\\n",
      "0    0.0  57.448331     5     1     1     4     6     5     2     1  ...   \n",
      "1    0.0  27.004439     3     1     3     9     1     1     2     4  ...   \n",
      "2    0.0  43.770511     2     5     3     4     3     3     3     2  ...   \n",
      "3    0.0  32.281018     2     7     2     3     5     0     1     4  ...   \n",
      "4    0.0  44.559284     1     3     0     0     2     2     6     3  ...   \n",
      "\n",
      "   G291  G292  G293  G294  G295  G296  G297  G298  G299  G300  \n",
      "0     0     0     0     0     0     0     0     0     0     0  \n",
      "1     0     0     0     0     0     0     0     0     0     0  \n",
      "2     0     0     0     0     0     0     0     0     0     0  \n",
      "3     0     1     0     1     0     0     0     0     0     0  \n",
      "4     0     0     0     0     0     0     0     0     0     1  \n",
      "\n",
      "[5 rows x 312 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "specified-bonus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     label       time  Var1  Var2  Var3  Var4  Var5  Var6  Var7  Var8  ...  \\\n",
      "995    0.0  19.289036     3     5     3     7     0     2     1     4  ...   \n",
      "996    0.0  66.591235     4     2     1     2     2     2     2     1  ...   \n",
      "997    1.0  62.986021     4     3     4     9     3     6     6     4  ...   \n",
      "998    0.0  32.736220     4     1     4     5     6     3     1     2  ...   \n",
      "999    0.0  36.714493     3     2     1     2     4     3     1     2  ...   \n",
      "\n",
      "     G291  G292  G293  G294  G295  G296  G297  G298  G299  G300  \n",
      "995     0     0     0     0     0     0     1     0     0     0  \n",
      "996     0     0     1     0     1     0     0     0     1     0  \n",
      "997     0     0     0     0     1     0     0     0     0     0  \n",
      "998     0     0     0     0     0     0     0     1     1     0  \n",
      "999     0     0     0     0     0     0     0     0     0     0  \n",
      "\n",
      "[5 rows x 312 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "regular-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "vocal-theme",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Train & Test Split\n",
    "'''\n",
    "random_index = np.arange(1000)\n",
    "# np.random.shuffle(random_index)\n",
    "# np.random.shuffle(random_index)\n",
    "\n",
    "train_df, test_df = df.iloc[random_index[:800],:], df.iloc[random_index[800:1000],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "effective-recall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 312)\n",
      "   label       time  Var1  Var2  Var3  Var4  Var5  Var6  Var7  Var8  ...  \\\n",
      "0    0.0  57.448331     5     1     1     4     6     5     2     1  ...   \n",
      "1    0.0  27.004439     3     1     3     9     1     1     2     4  ...   \n",
      "2    0.0  43.770511     2     5     3     4     3     3     3     2  ...   \n",
      "3    0.0  32.281018     2     7     2     3     5     0     1     4  ...   \n",
      "4    0.0  44.559284     1     3     0     0     2     2     6     3  ...   \n",
      "\n",
      "   G291  G292  G293  G294  G295  G296  G297  G298  G299  G300  \n",
      "0     0     0     0     0     0     0     0     0     0     0  \n",
      "1     0     0     0     0     0     0     0     0     0     0  \n",
      "2     0     0     0     0     0     0     0     0     0     0  \n",
      "3     0     1     0     1     0     0     0     0     0     0  \n",
      "4     0     0     0     0     0     0     0     0     0     1  \n",
      "\n",
      "[5 rows x 312 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "lonely-inquiry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            label        time        Var1        Var2        Var3        Var4  \\\n",
      "count  800.000000  800.000000  800.000000  800.000000  800.000000  800.000000   \n",
      "mean     0.047500   51.286198    2.918750    3.326250    3.022500    3.155000   \n",
      "std      0.212839   20.840875    1.878579    1.947962    1.907627    1.943115   \n",
      "min      0.000000    7.070708    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000   37.385295    2.000000    2.000000    2.000000    2.000000   \n",
      "50%      0.000000   47.141058    3.000000    3.000000    3.000000    3.000000   \n",
      "75%      0.000000   60.610372    4.000000    4.000000    4.000000    4.000000   \n",
      "max      1.000000  171.994623    9.000000   11.000000   11.000000   12.000000   \n",
      "\n",
      "             Var5        Var6        Var7        Var8  ...       G291  \\\n",
      "count  800.000000  800.000000  800.000000  800.000000  ...  800.00000   \n",
      "mean     3.470000    3.265000    2.346250    2.387500  ...    0.10875   \n",
      "std      1.873763    2.028526    1.795938    1.838905  ...    0.31152   \n",
      "min      0.000000    0.000000    0.000000    0.000000  ...    0.00000   \n",
      "25%      2.000000    2.000000    1.000000    1.000000  ...    0.00000   \n",
      "50%      3.000000    3.000000    2.000000    2.000000  ...    0.00000   \n",
      "75%      5.000000    4.000000    3.000000    3.000000  ...    0.00000   \n",
      "max     10.000000   12.000000   10.000000    9.000000  ...    1.00000   \n",
      "\n",
      "             G292        G293        G294        G295        G296        G297  \\\n",
      "count  800.000000  800.000000  800.000000  800.000000  800.000000  800.000000   \n",
      "mean     0.090000    0.097500    0.111250    0.122500    0.110000    0.101250   \n",
      "std      0.286361    0.296823    0.314638    0.328068    0.313085    0.301848   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
      "\n",
      "            G298        G299        G300  \n",
      "count  800.00000  800.000000  800.000000  \n",
      "mean     0.08875    0.102500    0.096250  \n",
      "std      0.28456    0.303494    0.295118  \n",
      "min      0.00000    0.000000    0.000000  \n",
      "25%      0.00000    0.000000    0.000000  \n",
      "50%      0.00000    0.000000    0.000000  \n",
      "75%      0.00000    0.000000    0.000000  \n",
      "max      1.00000    1.000000    1.000000  \n",
      "\n",
      "[8 rows x 312 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "naked-ethernet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            label        time        Var1       Var2        Var3        Var4  \\\n",
      "count  200.000000  200.000000  200.000000  200.00000  200.000000  200.000000   \n",
      "mean     0.050000   54.156377    3.125000    3.19500    2.915000    3.440000   \n",
      "std      0.218492   26.732912    1.848366    1.97903    1.943363    2.026557   \n",
      "min      0.000000   -7.945621    0.000000    0.00000    0.000000    0.000000   \n",
      "25%      0.000000   37.611163    2.000000    2.00000    2.000000    2.000000   \n",
      "50%      0.000000   46.796557    3.000000    3.00000    2.000000    3.000000   \n",
      "75%      0.000000   62.989101    4.000000    4.00000    4.000000    5.000000   \n",
      "max      1.000000  217.078908   10.000000   10.00000    9.000000    9.000000   \n",
      "\n",
      "            Var5        Var6        Var7        Var8  ...        G291  \\\n",
      "count  200.00000  200.000000  200.000000  200.000000  ...  200.000000   \n",
      "mean     3.56500    3.120000    2.415000    2.420000  ...    0.125000   \n",
      "std      2.06813    2.072941    1.913395    1.791549  ...    0.331549   \n",
      "min      0.00000    0.000000    0.000000    0.000000  ...    0.000000   \n",
      "25%      2.00000    2.000000    1.000000    1.000000  ...    0.000000   \n",
      "50%      3.00000    3.000000    2.000000    2.000000  ...    0.000000   \n",
      "75%      5.00000    4.000000    4.000000    3.000000  ...    0.000000   \n",
      "max     11.00000   10.000000    8.000000   10.000000  ...    1.000000   \n",
      "\n",
      "             G292        G293        G294        G295        G296        G297  \\\n",
      "count  200.000000  200.000000  200.000000  200.000000  200.000000  200.000000   \n",
      "mean     0.085000    0.120000    0.080000    0.130000    0.095000    0.145000   \n",
      "std      0.279582    0.325777    0.271974    0.337147    0.293951    0.352984   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
      "\n",
      "             G298        G299        G300  \n",
      "count  200.000000  200.000000  200.000000  \n",
      "mean     0.095000    0.085000    0.100000  \n",
      "std      0.293951    0.279582    0.300753  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      0.000000    0.000000    0.000000  \n",
      "50%      0.000000    0.000000    0.000000  \n",
      "75%      0.000000    0.000000    0.000000  \n",
      "max      1.000000    1.000000    1.000000  \n",
      "\n",
      "[8 rows x 312 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "proud-bronze",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 310) (800,) (200, 310) (200,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Data & Ground Truth Split\n",
    "'''\n",
    "\n",
    "'''\n",
    "Time data drop\n",
    "'''\n",
    "\n",
    "X_train = train_df.drop(['time', 'label'], axis=1)\n",
    "Y_train = train_df['label']\n",
    "\n",
    "X_test = test_df.drop(['time', 'label'], axis=1)\n",
    "Y_test = test_df['label']\n",
    "\n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "temporal-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Save train & test results\n",
    "\n",
    "When doing train, Shuffle and split the data\n",
    "\n",
    "'''\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "test_method_list = ['LogisticRegression', 'Support Vector Machines', 'KNN or k-Nearest Neighbors',\n",
    "                    'Gaussian Naive Bayes', 'Perceptron', 'Linear SVC', \n",
    "                    'Stochastic Gradient Descent', 'Decision Tree', 'Random Forest', 'Ensemble']\n",
    "\n",
    "ensemble_models = [\n",
    "    ('lrcv', LogisticRegressionCV(max_iter = 5000)),\n",
    "    ('ada', AdaBoostClassifier()),\n",
    "    ('bc', BaggingClassifier()),\n",
    "    ('etc',ExtraTreesClassifier()),\n",
    "    ('gbc', GradientBoostingClassifier()),\n",
    "    ('rfc', RandomForestClassifier(n_estimators=20)),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors = 4)),\n",
    "    ('svc', SVC(probability=True)),\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss')),\n",
    "    ('lgbm', LGBMClassifier()),\n",
    "    ('dtc', DecisionTreeClassifier()),\n",
    "    ('gnb',GaussianNB()),\n",
    "]\n",
    "\n",
    "index = ['Basic','Time_outlier','Time_/365','Clinic_outlier','Clinic_0-4(2steps)','Clinic_0-1(resizing)']\n",
    "\n",
    "result_train_df = pd.DataFrame(columns=test_method_list)\n",
    "result_test_df = pd.DataFrame(columns=test_method_list)\n",
    "result_acc_test_df = pd.DataFrame(columns=test_method_list)\n",
    "result_pre_test_df = pd.DataFrame(columns=test_method_list)\n",
    "result_rec_test_df = pd.DataFrame(columns=test_method_list)\n",
    "result_f1score_test_df = pd.DataFrame(columns=test_method_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "first-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model, predict and solve\n",
    "\n",
    "\n",
    "- Methods\n",
    "Logistic Regression\n",
    "KNN or k-Nearest Neighbors\n",
    "Support Vector Machines\n",
    "Naive Bayes classifier\n",
    "Decision Tree\n",
    "Random Forrest\n",
    "Perceptron\n",
    "Artificial neural network\n",
    "RVM or Relevance Vector Machine\n",
    "Ensemble model\n",
    "'''\n",
    "\n",
    "\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    #     print('confusion matrix')\n",
    "    #     print(confusion)\n",
    "    print('accuracy:{}, precision:{}, recall:{}'.format(accuracy, precision, recall))\n",
    "    \n",
    "    return accuracy, precision, recall\n",
    "\n",
    "\n",
    "def training():\n",
    "    result_train = []\n",
    "    result_test = []\n",
    "    result_acc = []\n",
    "    result_pre = []\n",
    "    result_rec = []\n",
    "    result_f1 = []\n",
    "    for input_method in test_method_list:\n",
    "        print('*** Method: ', input_method)\n",
    "\n",
    "        if input_method == 'LogisticRegression':\n",
    "            model = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "        elif input_method == 'Support Vector Machines':\n",
    "            model = SVC()\n",
    "\n",
    "        elif input_method == 'KNN or k-Nearest Neighbors':\n",
    "            model = KNeighborsClassifier(n_neighbors = 4)\n",
    "\n",
    "        elif input_method == 'Gaussian Naive Bayes':\n",
    "            model = GaussianNB()\n",
    "\n",
    "        elif input_method == 'Perceptron':\n",
    "            model = Perceptron()\n",
    "\n",
    "        elif input_method == 'Linear SVC':\n",
    "            model = LinearSVC(max_iter=500000)\n",
    "\n",
    "        elif input_method == 'Stochastic Gradient Descent':\n",
    "            model = SGDClassifier()\n",
    "\n",
    "        elif input_method == 'Decision Tree':\n",
    "            model = DecisionTreeClassifier()\n",
    "\n",
    "        elif input_method == 'Random Forest':\n",
    "            model = RandomForestClassifier(n_estimators=20)\n",
    "            \n",
    "        elif input_method == 'Ensemble':\n",
    "            model  = VotingClassifier(ensemble_models, voting='soft')\n",
    "    \n",
    "        # Train\n",
    "        model.fit(X_train, Y_train)\n",
    "        acc_log = round(model.score(X_train, Y_train) * 100, 2)\n",
    "        print('trained-acc: ', acc_log)\n",
    "        result_train.append(acc_log)\n",
    "\n",
    "\n",
    "        # Test\n",
    "        acc_log = round(model.score(X_test, Y_test) * 100, 2)\n",
    "        print('test-acc: ', acc_log)\n",
    "        result_test.append(acc_log)\n",
    "        \n",
    "        # f1 score\n",
    "        Y_pred = model.predict(X_test)\n",
    "        acc, pre, rec = get_clf_eval(Y_test, Y_pred)\n",
    "        result_acc.append(acc)\n",
    "        result_pre.append(pre)\n",
    "        result_rec.append(rec)\n",
    "        f1 = f1_score(Y_test, Y_pred)\n",
    "        print('f1 score:{}'.format(f1))\n",
    "        result_f1.append(f1)\n",
    "        \n",
    "        print()\n",
    "        print()\n",
    "\n",
    "    result_train_df.loc[result_train_df.shape[0]] = result_train\n",
    "    result_test_df.loc[result_test_df.shape[0]] = result_test\n",
    "    result_acc_test_df.loc[result_acc_test_df.shape[0]] = result_acc\n",
    "    result_pre_test_df.loc[result_pre_test_df.shape[0]] = result_pre\n",
    "    result_rec_test_df.loc[result_rec_test_df.shape[0]] = result_rec\n",
    "    result_f1score_test_df.loc[result_f1score_test_df.shape[0]] = result_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "centered-month",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Method:  LogisticRegression\n",
      "trained-acc:  99.38\n",
      "test-acc:  94.0\n",
      "accuracy:0.94, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  Support Vector Machines\n",
      "trained-acc:  95.25\n",
      "test-acc:  95.0\n",
      "accuracy:0.95, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  KNN or k-Nearest Neighbors\n",
      "trained-acc: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95.25\n",
      "test-acc:  95.0\n",
      "accuracy:0.95, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  Gaussian Naive Bayes\n",
      "trained-acc:  57.88\n",
      "test-acc:  60.5\n",
      "accuracy:0.605, precision:0.08433734939759036, recall:0.7\n",
      "f1 score:0.15053763440860216\n",
      "\n",
      "\n",
      "*** Method:  Perceptron\n",
      "trained-acc:  95.62\n",
      "test-acc:  83.5\n",
      "accuracy:0.835, precision:0.04, recall:0.1\n",
      "f1 score:0.05714285714285714\n",
      "\n",
      "\n",
      "*** Method:  Linear SVC\n",
      "trained-acc:  100.0\n",
      "test-acc:  92.5\n",
      "accuracy:0.925, precision:0.2222222222222222, recall:0.2\n",
      "f1 score:0.2105263157894737\n",
      "\n",
      "\n",
      "*** Method:  Stochastic Gradient Descent\n",
      "trained-acc:  96.38\n",
      "test-acc:  87.0\n",
      "accuracy:0.87, precision:0.1, recall:0.2\n",
      "f1 score:0.13333333333333333\n",
      "\n",
      "\n",
      "*** Method:  Decision Tree\n",
      "trained-acc:  100.0\n",
      "test-acc:  89.5\n",
      "accuracy:0.895, precision:0.07692307692307693, recall:0.1\n",
      "f1 score:0.08695652173913043\n",
      "\n",
      "\n",
      "*** Method:  Random Forest\n",
      "trained-acc:  99.38\n",
      "test-acc:  95.0\n",
      "accuracy:0.95, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  Ensemble\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained-acc:  100.0\n",
      "test-acc:  95.0\n",
      "accuracy:0.95, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Basic Training & Test\n",
    "\n",
    "'''\n",
    "\n",
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "strange-norfolk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlier of time: \n",
      "905   -7.945621\n",
      "Name: time, dtype: float64\n",
      "\n",
      "              time        event\n",
      "count  1000.000000  1000.000000\n",
      "mean     51.876125     0.891000\n",
      "std      22.122689     0.311795\n",
      "min       7.070708     0.000000\n",
      "25%      37.401307     1.000000\n",
      "50%      47.064712     1.000000\n",
      "75%      60.966476     1.000000\n",
      "max     217.078908     1.000000\n",
      "\n",
      "['label' 'time' 'Var1' 'Var2' 'Var3' 'Var4' 'Var5' 'Var6' 'Var7' 'Var8'\n",
      " 'Var9' 'Var10' 'G1' 'G2' 'G3' 'G4' 'G5' 'G6' 'G7' 'G8' 'G9' 'G10' 'G11'\n",
      " 'G12' 'G13' 'G14' 'G15' 'G16' 'G17' 'G18' 'G19' 'G20' 'G21' 'G22' 'G23'\n",
      " 'G24' 'G25' 'G26' 'G27' 'G28' 'G29' 'G30' 'G31' 'G32' 'G33' 'G34' 'G35'\n",
      " 'G36' 'G37' 'G38' 'G39' 'G40' 'G41' 'G42' 'G43' 'G44' 'G45' 'G46' 'G47'\n",
      " 'G48' 'G49' 'G50' 'G51' 'G52' 'G53' 'G54' 'G55' 'G56' 'G57' 'G58' 'G59'\n",
      " 'G60' 'G61' 'G62' 'G63' 'G64' 'G65' 'G66' 'G67' 'G68' 'G69' 'G70' 'G71'\n",
      " 'G72' 'G73' 'G74' 'G75' 'G76' 'G77' 'G78' 'G79' 'G80' 'G81' 'G82' 'G83'\n",
      " 'G84' 'G85' 'G86' 'G87' 'G88' 'G89' 'G90' 'G91' 'G92' 'G93' 'G94' 'G95'\n",
      " 'G96' 'G97' 'G98' 'G99' 'G100' 'G101' 'G102' 'G103' 'G104' 'G105' 'G106'\n",
      " 'G107' 'G108' 'G109' 'G110' 'G111' 'G112' 'G113' 'G114' 'G115' 'G116'\n",
      " 'G117' 'G118' 'G119' 'G120' 'G121' 'G122' 'G123' 'G124' 'G125' 'G126'\n",
      " 'G127' 'G128' 'G129' 'G130' 'G131' 'G132' 'G133' 'G134' 'G135' 'G136'\n",
      " 'G137' 'G138' 'G139' 'G140' 'G141' 'G142' 'G143' 'G144' 'G145' 'G146'\n",
      " 'G147' 'G148' 'G149' 'G150' 'G151' 'G152' 'G153' 'G154' 'G155' 'G156'\n",
      " 'G157' 'G158' 'G159' 'G160' 'G161' 'G162' 'G163' 'G164' 'G165' 'G166'\n",
      " 'G167' 'G168' 'G169' 'G170' 'G171' 'G172' 'G173' 'G174' 'G175' 'G176'\n",
      " 'G177' 'G178' 'G179' 'G180' 'G181' 'G182' 'G183' 'G184' 'G185' 'G186'\n",
      " 'G187' 'G188' 'G189' 'G190' 'G191' 'G192' 'G193' 'G194' 'G195' 'G196'\n",
      " 'G197' 'G198' 'G199' 'G200' 'G201' 'G202' 'G203' 'G204' 'G205' 'G206'\n",
      " 'G207' 'G208' 'G209' 'G210' 'G211' 'G212' 'G213' 'G214' 'G215' 'G216'\n",
      " 'G217' 'G218' 'G219' 'G220' 'G221' 'G222' 'G223' 'G224' 'G225' 'G226'\n",
      " 'G227' 'G228' 'G229' 'G230' 'G231' 'G232' 'G233' 'G234' 'G235' 'G236'\n",
      " 'G237' 'G238' 'G239' 'G240' 'G241' 'G242' 'G243' 'G244' 'G245' 'G246'\n",
      " 'G247' 'G248' 'G249' 'G250' 'G251' 'G252' 'G253' 'G254' 'G255' 'G256'\n",
      " 'G257' 'G258' 'G259' 'G260' 'G261' 'G262' 'G263' 'G264' 'G265' 'G266'\n",
      " 'G267' 'G268' 'G269' 'G270' 'G271' 'G272' 'G273' 'G274' 'G275' 'G276'\n",
      " 'G277' 'G278' 'G279' 'G280' 'G281' 'G282' 'G283' 'G284' 'G285' 'G286'\n",
      " 'G287' 'G288' 'G289' 'G290' 'G291' 'G292' 'G293' 'G294' 'G295' 'G296'\n",
      " 'G297' 'G298' 'G299' 'G300']\n",
      "*** Method:  LogisticRegression\n",
      "trained-acc:  99.38\n",
      "test-acc:  95.0\n",
      "accuracy:0.95, precision:0.5, recall:0.2\n",
      "f1 score:0.28571428571428575\n",
      "\n",
      "\n",
      "*** Method:  Support Vector Machines\n",
      "trained-acc:  95.25\n",
      "test-acc:  95.0\n",
      "accuracy:0.95, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  KNN or k-Nearest Neighbors\n",
      "trained-acc: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96.0\n",
      "test-acc:  94.5\n",
      "accuracy:0.945, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  Gaussian Naive Bayes\n",
      "trained-acc:  66.25\n",
      "test-acc:  64.0\n",
      "accuracy:0.64, precision:0.08108108108108109, recall:0.6\n",
      "f1 score:0.14285714285714288\n",
      "\n",
      "\n",
      "*** Method:  Perceptron\n",
      "trained-acc:  95.5\n",
      "test-acc:  95.0\n",
      "accuracy:0.95, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  Linear SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained-acc:  100.0\n",
      "test-acc:  93.0\n",
      "accuracy:0.93, precision:0.25, recall:0.2\n",
      "f1 score:0.22222222222222224\n",
      "\n",
      "\n",
      "*** Method:  Stochastic Gradient Descent\n",
      "trained-acc:  95.5\n",
      "test-acc:  95.0\n",
      "accuracy:0.95, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  Decision Tree\n",
      "trained-acc:  100.0\n",
      "test-acc:  91.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.915, precision:0.1111111111111111, recall:0.1\n",
      "f1 score:0.10526315789473685\n",
      "\n",
      "\n",
      "*** Method:  Random Forest\n",
      "trained-acc:  99.88\n",
      "test-acc:  95.0\n",
      "accuracy:0.95, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  Ensemble\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained-acc:  100.0\n",
      "test-acc:  95.0\n",
      "accuracy:0.95, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Add Time data\n",
    "\n",
    "1) outlier value drop\n",
    "2) clustering from step 0-N days to step 0-N/365 days\n",
    "'''\n",
    "\n",
    "'''\n",
    "1)\n",
    "'''\n",
    "print('outlier of time: ')\n",
    "print(df1.loc[df1['time'] < 0, 'time'], end='\\n\\n')\n",
    "\n",
    "df1_outlier = df1.copy()\n",
    "df1_outlier.loc[df1_outlier['time'] < 0, 'time'] = abs(df1_outlier.loc[df1_outlier['time'] < 0, 'time'])\n",
    "print(df1_outlier.describe(), end='\\n\\n')\n",
    "\n",
    "df = pd.concat([df5, df1_outlier,df2,df3,df4], axis=1)\n",
    "df = df.drop(['event', 'Treatment'], axis=1)\n",
    "\n",
    "print(df.columns.values)\n",
    "\n",
    "train_df, test_df = df.iloc[random_index[:800],:], df.iloc[random_index[800:1000],:]\n",
    "\n",
    "X_train = train_df.drop(['label'], axis=1)\n",
    "Y_train = train_df['label']\n",
    "\n",
    "X_test = test_df.drop(['label'], axis=1)\n",
    "Y_test = test_df['label']\n",
    "\n",
    "\n",
    "'''\n",
    "Add Time data(1) Training & Test\n",
    "\n",
    "'''\n",
    "\n",
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "technical-might",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              time        event\n",
      "count  1000.000000  1000.000000\n",
      "mean      0.142126     0.891000\n",
      "std       0.060610     0.311795\n",
      "min       0.019372     0.000000\n",
      "25%       0.102469     1.000000\n",
      "50%       0.128944     1.000000\n",
      "75%       0.167031     1.000000\n",
      "max       0.594737     1.000000\n",
      "\n",
      "['label' 'time' 'Var1' 'Var2' 'Var3' 'Var4' 'Var5' 'Var6' 'Var7' 'Var8'\n",
      " 'Var9' 'Var10' 'G1' 'G2' 'G3' 'G4' 'G5' 'G6' 'G7' 'G8' 'G9' 'G10' 'G11'\n",
      " 'G12' 'G13' 'G14' 'G15' 'G16' 'G17' 'G18' 'G19' 'G20' 'G21' 'G22' 'G23'\n",
      " 'G24' 'G25' 'G26' 'G27' 'G28' 'G29' 'G30' 'G31' 'G32' 'G33' 'G34' 'G35'\n",
      " 'G36' 'G37' 'G38' 'G39' 'G40' 'G41' 'G42' 'G43' 'G44' 'G45' 'G46' 'G47'\n",
      " 'G48' 'G49' 'G50' 'G51' 'G52' 'G53' 'G54' 'G55' 'G56' 'G57' 'G58' 'G59'\n",
      " 'G60' 'G61' 'G62' 'G63' 'G64' 'G65' 'G66' 'G67' 'G68' 'G69' 'G70' 'G71'\n",
      " 'G72' 'G73' 'G74' 'G75' 'G76' 'G77' 'G78' 'G79' 'G80' 'G81' 'G82' 'G83'\n",
      " 'G84' 'G85' 'G86' 'G87' 'G88' 'G89' 'G90' 'G91' 'G92' 'G93' 'G94' 'G95'\n",
      " 'G96' 'G97' 'G98' 'G99' 'G100' 'G101' 'G102' 'G103' 'G104' 'G105' 'G106'\n",
      " 'G107' 'G108' 'G109' 'G110' 'G111' 'G112' 'G113' 'G114' 'G115' 'G116'\n",
      " 'G117' 'G118' 'G119' 'G120' 'G121' 'G122' 'G123' 'G124' 'G125' 'G126'\n",
      " 'G127' 'G128' 'G129' 'G130' 'G131' 'G132' 'G133' 'G134' 'G135' 'G136'\n",
      " 'G137' 'G138' 'G139' 'G140' 'G141' 'G142' 'G143' 'G144' 'G145' 'G146'\n",
      " 'G147' 'G148' 'G149' 'G150' 'G151' 'G152' 'G153' 'G154' 'G155' 'G156'\n",
      " 'G157' 'G158' 'G159' 'G160' 'G161' 'G162' 'G163' 'G164' 'G165' 'G166'\n",
      " 'G167' 'G168' 'G169' 'G170' 'G171' 'G172' 'G173' 'G174' 'G175' 'G176'\n",
      " 'G177' 'G178' 'G179' 'G180' 'G181' 'G182' 'G183' 'G184' 'G185' 'G186'\n",
      " 'G187' 'G188' 'G189' 'G190' 'G191' 'G192' 'G193' 'G194' 'G195' 'G196'\n",
      " 'G197' 'G198' 'G199' 'G200' 'G201' 'G202' 'G203' 'G204' 'G205' 'G206'\n",
      " 'G207' 'G208' 'G209' 'G210' 'G211' 'G212' 'G213' 'G214' 'G215' 'G216'\n",
      " 'G217' 'G218' 'G219' 'G220' 'G221' 'G222' 'G223' 'G224' 'G225' 'G226'\n",
      " 'G227' 'G228' 'G229' 'G230' 'G231' 'G232' 'G233' 'G234' 'G235' 'G236'\n",
      " 'G237' 'G238' 'G239' 'G240' 'G241' 'G242' 'G243' 'G244' 'G245' 'G246'\n",
      " 'G247' 'G248' 'G249' 'G250' 'G251' 'G252' 'G253' 'G254' 'G255' 'G256'\n",
      " 'G257' 'G258' 'G259' 'G260' 'G261' 'G262' 'G263' 'G264' 'G265' 'G266'\n",
      " 'G267' 'G268' 'G269' 'G270' 'G271' 'G272' 'G273' 'G274' 'G275' 'G276'\n",
      " 'G277' 'G278' 'G279' 'G280' 'G281' 'G282' 'G283' 'G284' 'G285' 'G286'\n",
      " 'G287' 'G288' 'G289' 'G290' 'G291' 'G292' 'G293' 'G294' 'G295' 'G296'\n",
      " 'G297' 'G298' 'G299' 'G300']\n",
      "*** Method:  LogisticRegression\n",
      "trained-acc:  99.38\n",
      "test-acc:  94.0\n",
      "accuracy:0.94, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  Support Vector Machines\n",
      "trained-acc:  95.25\n",
      "test-acc:  95.0\n",
      "accuracy:0.95, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  KNN or k-Nearest Neighbors\n",
      "trained-acc: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95.25\n",
      "test-acc:  95.0\n",
      "accuracy:0.95, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  Gaussian Naive Bayes\n",
      "trained-acc:  57.88\n",
      "test-acc:  60.5\n",
      "accuracy:0.605, precision:0.08433734939759036, recall:0.7"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "f1 score:0.15053763440860216\n",
      "\n",
      "\n",
      "*** Method:  Perceptron\n",
      "trained-acc:  98.0\n",
      "test-acc:  93.5\n",
      "accuracy:0.935, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  Linear SVC\n",
      "trained-acc:  100.0\n",
      "test-acc:  92.5\n",
      "accuracy:0.925, precision:0.2222222222222222, recall:0.2\n",
      "f1 score:0.2105263157894737\n",
      "\n",
      "\n",
      "*** Method:  Stochastic Gradient Descent\n",
      "trained-acc:  100.0\n",
      "test-acc:  92.5\n",
      "accuracy:0.925, precision:0.2222222222222222, recall:0.2\n",
      "f1 score:0.2105263157894737\n",
      "\n",
      "\n",
      "*** Method:  Decision Tree\n",
      "trained-acc:  100.0\n",
      "test-acc:  90.0\n",
      "accuracy:0.9, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  Random Forest\n",
      "trained-acc:  99.62\n",
      "test-acc:  95.0\n",
      "accuracy:0.95, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  Ensemble\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained-acc:  100.0\n",
      "test-acc:  95.0\n",
      "accuracy:0.95, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2)\n",
    "'''\n",
    "df1_normalize = df1_outlier.copy()\n",
    "df1_normalize['time'] = df1_normalize['time']/365.0\n",
    "print(df1_normalize.describe(), end='\\n\\n')\n",
    "\n",
    "df = pd.concat([df5, df1_normalize,df2,df3,df4], axis=1)\n",
    "df = df.drop(['event', 'Treatment'], axis=1)\n",
    "\n",
    "print(df.columns.values)\n",
    "\n",
    "train_df, test_df = df.iloc[random_index[:800],:], df.iloc[random_index[800:1000],:]\n",
    "\n",
    "X_train = train_df.drop(['label'], axis=1)\n",
    "Y_train = train_df['label']\n",
    "\n",
    "X_test = test_df.drop(['label'], axis=1)\n",
    "Y_test = test_df['label']\n",
    "\n",
    "\n",
    "'''\n",
    "Add Time data(1) Training & Test\n",
    "\n",
    "'''\n",
    "\n",
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "usual-church",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Var1\n",
      "2    235\n",
      "3    204\n",
      "1    171\n",
      "4    139\n",
      "5     95\n",
      "0     57\n",
      "6     50\n",
      "7     27\n",
      "8     13\n",
      "9      9\n",
      "Name: Var1, dtype: int64\n",
      "--------------------\n",
      "# Var2\n",
      "3    221\n",
      "2    218\n",
      "4    163\n",
      "1    113\n",
      "5    109\n",
      "6     65\n",
      "0     48\n",
      "7     30\n",
      "9     20\n",
      "8     13\n",
      "Name: Var2, dtype: int64\n",
      "--------------------\n",
      "# Var3\n",
      "2    260\n",
      "3    196\n",
      "1    156\n",
      "4    130\n",
      "5     97\n",
      "0     55\n",
      "6     55\n",
      "7     23\n",
      "8     16\n",
      "9     12\n",
      "Name: Var3, dtype: int64\n",
      "--------------------\n",
      "# Var4\n",
      "2    242\n",
      "3    195\n",
      "1    150\n",
      "4    140\n",
      "5    106\n",
      "6     67\n",
      "0     36\n",
      "7     32\n",
      "8     16\n",
      "9     16\n",
      "Name: Var4, dtype: int64\n",
      "--------------------\n",
      "# Var5\n",
      "2    247\n",
      "3    223\n",
      "4    161\n",
      "5    124\n",
      "1     76\n",
      "6     63\n",
      "7     41\n",
      "0     28\n",
      "9     19\n",
      "8     18\n",
      "Name: Var5, dtype: int64\n",
      "--------------------\n",
      "# Var6\n",
      "2    240\n",
      "3    212\n",
      "4    128\n",
      "1    127\n",
      "5     99\n",
      "6     64\n",
      "0     53\n",
      "7     40\n",
      "8     20\n",
      "9     17\n",
      "Name: Var6, dtype: int64\n",
      "--------------------\n",
      "# Var7\n",
      "1    269\n",
      "2    208\n",
      "3    144\n",
      "0    128\n",
      "4    118\n",
      "5     62\n",
      "6     47\n",
      "7     16\n",
      "8      6\n",
      "9      2\n",
      "Name: Var7, dtype: int64\n",
      "--------------------\n",
      "# Var8\n",
      "1    241\n",
      "2    227\n",
      "3    171\n",
      "0    127\n",
      "4    101\n",
      "5     69\n",
      "6     30\n",
      "7     20\n",
      "8     10\n",
      "9      4\n",
      "Name: Var8, dtype: int64\n",
      "--------------------\n",
      "# Var9\n",
      "2    250\n",
      "1    235\n",
      "3    157\n",
      "0    135\n",
      "4    100\n",
      "5     57\n",
      "6     33\n",
      "7     22\n",
      "9      6\n",
      "8      5\n",
      "Name: Var9, dtype: int64\n",
      "--------------------\n",
      "# Var10\n",
      "1    287\n",
      "2    205\n",
      "3    156\n",
      "0    114\n",
      "4    108\n",
      "5     62\n",
      "6     40\n",
      "7     18\n",
      "8      5\n",
      "9      5\n",
      "Name: Var10, dtype: int64\n",
      "--------------------\n",
      "['label' 'time' 'Var1' 'Var2' 'Var3' 'Var4' 'Var5' 'Var6' 'Var7' 'Var8'\n",
      " 'Var9' 'Var10' 'G1' 'G2' 'G3' 'G4' 'G5' 'G6' 'G7' 'G8' 'G9' 'G10' 'G11'\n",
      " 'G12' 'G13' 'G14' 'G15' 'G16' 'G17' 'G18' 'G19' 'G20' 'G21' 'G22' 'G23'\n",
      " 'G24' 'G25' 'G26' 'G27' 'G28' 'G29' 'G30' 'G31' 'G32' 'G33' 'G34' 'G35'\n",
      " 'G36' 'G37' 'G38' 'G39' 'G40' 'G41' 'G42' 'G43' 'G44' 'G45' 'G46' 'G47'\n",
      " 'G48' 'G49' 'G50' 'G51' 'G52' 'G53' 'G54' 'G55' 'G56' 'G57' 'G58' 'G59'\n",
      " 'G60' 'G61' 'G62' 'G63' 'G64' 'G65' 'G66' 'G67' 'G68' 'G69' 'G70' 'G71'\n",
      " 'G72' 'G73' 'G74' 'G75' 'G76' 'G77' 'G78' 'G79' 'G80' 'G81' 'G82' 'G83'\n",
      " 'G84' 'G85' 'G86' 'G87' 'G88' 'G89' 'G90' 'G91' 'G92' 'G93' 'G94' 'G95'\n",
      " 'G96' 'G97' 'G98' 'G99' 'G100' 'G101' 'G102' 'G103' 'G104' 'G105' 'G106'\n",
      " 'G107' 'G108' 'G109' 'G110' 'G111' 'G112' 'G113' 'G114' 'G115' 'G116'\n",
      " 'G117' 'G118' 'G119' 'G120' 'G121' 'G122' 'G123' 'G124' 'G125' 'G126'\n",
      " 'G127' 'G128' 'G129' 'G130' 'G131' 'G132' 'G133' 'G134' 'G135' 'G136'\n",
      " 'G137' 'G138' 'G139' 'G140' 'G141' 'G142' 'G143' 'G144' 'G145' 'G146'\n",
      " 'G147' 'G148' 'G149' 'G150' 'G151' 'G152' 'G153' 'G154' 'G155' 'G156'\n",
      " 'G157' 'G158' 'G159' 'G160' 'G161' 'G162' 'G163' 'G164' 'G165' 'G166'\n",
      " 'G167' 'G168' 'G169' 'G170' 'G171' 'G172' 'G173' 'G174' 'G175' 'G176'\n",
      " 'G177' 'G178' 'G179' 'G180' 'G181' 'G182' 'G183' 'G184' 'G185' 'G186'\n",
      " 'G187' 'G188' 'G189' 'G190' 'G191' 'G192' 'G193' 'G194' 'G195' 'G196'\n",
      " 'G197' 'G198' 'G199' 'G200' 'G201' 'G202' 'G203' 'G204' 'G205' 'G206'\n",
      " 'G207' 'G208' 'G209' 'G210' 'G211' 'G212' 'G213' 'G214' 'G215' 'G216'\n",
      " 'G217' 'G218' 'G219' 'G220' 'G221' 'G222' 'G223' 'G224' 'G225' 'G226'\n",
      " 'G227' 'G228' 'G229' 'G230' 'G231' 'G232' 'G233' 'G234' 'G235' 'G236'\n",
      " 'G237' 'G238' 'G239' 'G240' 'G241' 'G242' 'G243' 'G244' 'G245' 'G246'\n",
      " 'G247' 'G248' 'G249' 'G250' 'G251' 'G252' 'G253' 'G254' 'G255' 'G256'\n",
      " 'G257' 'G258' 'G259' 'G260' 'G261' 'G262' 'G263' 'G264' 'G265' 'G266'\n",
      " 'G267' 'G268' 'G269' 'G270' 'G271' 'G272' 'G273' 'G274' 'G275' 'G276'\n",
      " 'G277' 'G278' 'G279' 'G280' 'G281' 'G282' 'G283' 'G284' 'G285' 'G286'\n",
      " 'G287' 'G288' 'G289' 'G290' 'G291' 'G292' 'G293' 'G294' 'G295' 'G296'\n",
      " 'G297' 'G298' 'G299' 'G300']\n",
      "\n",
      "*** Method:  LogisticRegression\n",
      "trained-acc:  99.38\n",
      "test-acc:  95.0\n",
      "accuracy:0.95, precision:0.5, recall:0.2\n",
      "f1 score:0.28571428571428575\n",
      "\n",
      "\n",
      "*** Method:  Support Vector Machines\n",
      "trained-acc:  95.25\n",
      "test-acc:  95.0\n",
      "accuracy:0.95, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  KNN or k-Nearest Neighbors\n",
      "trained-acc:  96.0\n",
      "test-acc:  94.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.945, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  Gaussian Naive Bayes\n",
      "trained-acc:  66.25\n",
      "test-acc:  64.0\n",
      "accuracy:0.64, precision:0.08108108108108109, recall:0.6\n",
      "f1 score:0.14285714285714288\n",
      "\n",
      "\n",
      "*** Method:  Perceptron\n",
      "trained-acc:  96.25\n",
      "test-acc:  94.5\n",
      "accuracy:0.945, precision:0.3333333333333333, recall:0.1\n",
      "f1 score:0.15384615384615383\n",
      "\n",
      "\n",
      "*** Method:  Linear SVC\n",
      "trained-acc:  100.0\n",
      "test-acc:  93.0\n",
      "accuracy:0.93, precision:0.25, recall:0.2\n",
      "f1 score:0.22222222222222224\n",
      "\n",
      "\n",
      "*** Method:  Stochastic Gradient Descent\n",
      "trained-acc:  96.62\n",
      "test-acc:  94.5\n",
      "accuracy:0.945, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  Decision Tree\n",
      "trained-acc:  100.0\n",
      "test-acc:  90.5\n",
      "accuracy:0.905, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  Random Forest\n",
      "trained-acc:  99.12\n",
      "test-acc:  95.0\n",
      "accuracy:0.95, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  Ensemble\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained-acc:  100.0\n",
      "test-acc:  94.5\n",
      "accuracy:0.945, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Correlating numerical features of Clinic data\n",
    "\n",
    "- outlier value drop\n",
    "- clustering from step 0-9 to step 0-4(clustering 2 steps)/0-1(just resizing)\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "1)\n",
    "'''\n",
    "df3_outlier = df3.copy()\n",
    "\n",
    "\n",
    "# drop outlier\n",
    "for col in df3_outlier.columns:\n",
    "    for outlier in range(10,13):\n",
    "        df3_outlier = df3_outlier.replace(outlier, 9)\n",
    "\n",
    "# visualize\n",
    "for col in df3_outlier.columns:\n",
    "    print('#', col)\n",
    "    print(df3_outlier[col].value_counts())\n",
    "    print('-'*20)\n",
    "\n",
    "\n",
    "df = pd.concat([df5, df1_outlier,df2,df3_outlier,df4], axis=1)\n",
    "df = df.drop(['event', 'Treatment'], axis=1)\n",
    "\n",
    "print(df.columns.values)\n",
    "\n",
    "train_df, test_df = df.iloc[random_index[:800],:], df.iloc[random_index[800:1000],:]\n",
    "\n",
    "X_train = train_df.drop(['label'], axis=1)\n",
    "Y_train = train_df['label']\n",
    "\n",
    "X_test = test_df.drop(['label'], axis=1)\n",
    "Y_test = test_df['label']\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Add Time data(1) +  Correlating Clinic data(1) \n",
    "Training & Test\n",
    "'''\n",
    "\n",
    "print()\n",
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "conscious-large",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Var1         Var2         Var3         Var4         Var5  \\\n",
      "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
      "mean      1.226000     1.400000     1.256000     1.354000     1.500000   \n",
      "std       0.958041     0.975167     0.968195     0.995829     0.942809   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "50%       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "75%       2.000000     2.000000     2.000000     2.000000     2.000000   \n",
      "max       4.000000     4.000000     4.000000     4.000000     4.000000   \n",
      "\n",
      "              Var6         Var7         Var8         Var9        Var10  \n",
      "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  \n",
      "mean      1.366000     0.933000     0.944000     0.930000     0.915000  \n",
      "std       1.011468     0.947316     0.928292     0.917574     0.941627  \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "25%       1.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "50%       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
      "75%       2.000000     2.000000     1.000000     1.000000     1.000000  \n",
      "max       4.000000     4.000000     4.000000     4.000000     4.000000  \n",
      "\n",
      "['label' 'time' 'Var1' 'Var2' 'Var3' 'Var4' 'Var5' 'Var6' 'Var7' 'Var8'\n",
      " 'Var9' 'Var10' 'G1' 'G2' 'G3' 'G4' 'G5' 'G6' 'G7' 'G8' 'G9' 'G10' 'G11'\n",
      " 'G12' 'G13' 'G14' 'G15' 'G16' 'G17' 'G18' 'G19' 'G20' 'G21' 'G22' 'G23'\n",
      " 'G24' 'G25' 'G26' 'G27' 'G28' 'G29' 'G30' 'G31' 'G32' 'G33' 'G34' 'G35'\n",
      " 'G36' 'G37' 'G38' 'G39' 'G40' 'G41' 'G42' 'G43' 'G44' 'G45' 'G46' 'G47'\n",
      " 'G48' 'G49' 'G50' 'G51' 'G52' 'G53' 'G54' 'G55' 'G56' 'G57' 'G58' 'G59'\n",
      " 'G60' 'G61' 'G62' 'G63' 'G64' 'G65' 'G66' 'G67' 'G68' 'G69' 'G70' 'G71'\n",
      " 'G72' 'G73' 'G74' 'G75' 'G76' 'G77' 'G78' 'G79' 'G80' 'G81' 'G82' 'G83'\n",
      " 'G84' 'G85' 'G86' 'G87' 'G88' 'G89' 'G90' 'G91' 'G92' 'G93' 'G94' 'G95'\n",
      " 'G96' 'G97' 'G98' 'G99' 'G100' 'G101' 'G102' 'G103' 'G104' 'G105' 'G106'\n",
      " 'G107' 'G108' 'G109' 'G110' 'G111' 'G112' 'G113' 'G114' 'G115' 'G116'\n",
      " 'G117' 'G118' 'G119' 'G120' 'G121' 'G122' 'G123' 'G124' 'G125' 'G126'\n",
      " 'G127' 'G128' 'G129' 'G130' 'G131' 'G132' 'G133' 'G134' 'G135' 'G136'\n",
      " 'G137' 'G138' 'G139' 'G140' 'G141' 'G142' 'G143' 'G144' 'G145' 'G146'\n",
      " 'G147' 'G148' 'G149' 'G150' 'G151' 'G152' 'G153' 'G154' 'G155' 'G156'\n",
      " 'G157' 'G158' 'G159' 'G160' 'G161' 'G162' 'G163' 'G164' 'G165' 'G166'\n",
      " 'G167' 'G168' 'G169' 'G170' 'G171' 'G172' 'G173' 'G174' 'G175' 'G176'\n",
      " 'G177' 'G178' 'G179' 'G180' 'G181' 'G182' 'G183' 'G184' 'G185' 'G186'\n",
      " 'G187' 'G188' 'G189' 'G190' 'G191' 'G192' 'G193' 'G194' 'G195' 'G196'\n",
      " 'G197' 'G198' 'G199' 'G200' 'G201' 'G202' 'G203' 'G204' 'G205' 'G206'\n",
      " 'G207' 'G208' 'G209' 'G210' 'G211' 'G212' 'G213' 'G214' 'G215' 'G216'\n",
      " 'G217' 'G218' 'G219' 'G220' 'G221' 'G222' 'G223' 'G224' 'G225' 'G226'\n",
      " 'G227' 'G228' 'G229' 'G230' 'G231' 'G232' 'G233' 'G234' 'G235' 'G236'\n",
      " 'G237' 'G238' 'G239' 'G240' 'G241' 'G242' 'G243' 'G244' 'G245' 'G246'\n",
      " 'G247' 'G248' 'G249' 'G250' 'G251' 'G252' 'G253' 'G254' 'G255' 'G256'\n",
      " 'G257' 'G258' 'G259' 'G260' 'G261' 'G262' 'G263' 'G264' 'G265' 'G266'\n",
      " 'G267' 'G268' 'G269' 'G270' 'G271' 'G272' 'G273' 'G274' 'G275' 'G276'\n",
      " 'G277' 'G278' 'G279' 'G280' 'G281' 'G282' 'G283' 'G284' 'G285' 'G286'\n",
      " 'G287' 'G288' 'G289' 'G290' 'G291' 'G292' 'G293' 'G294' 'G295' 'G296'\n",
      " 'G297' 'G298' 'G299' 'G300']\n",
      "*** Method:  LogisticRegression\n",
      "trained-acc:  99.38\n",
      "test-acc:  93.5\n",
      "accuracy:0.935, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  Support Vector Machines\n",
      "trained-acc:  95.25\n",
      "test-acc:  95.0\n",
      "accuracy:0.95, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  KNN or k-Nearest Neighbors\n",
      "trained-acc: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96.0\n",
      "test-acc:  94.5\n",
      "accuracy:0.945, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  Gaussian Naive Bayes\n",
      "trained-acc:  66.25\n",
      "test-acc:  63.5\n",
      "accuracy:0.635, precision:0.08, recall:0.6\n",
      "f1 score:0.14117647058823532\n",
      "\n",
      "\n",
      "*** Method:  Perceptron\n",
      "trained-acc:  95.5\n",
      "test-acc:  95.0\n",
      "accuracy:0.95, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  Linear SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained-acc:  100.0\n",
      "test-acc:  92.5\n",
      "accuracy:0.925, precision:0.2222222222222222, recall:0.2\n",
      "f1 score:0.2105263157894737\n",
      "\n",
      "\n",
      "*** Method:  Stochastic Gradient Descent\n",
      "trained-acc:  96.38\n",
      "test-acc:  93.5\n",
      "accuracy:0.935, precision:0.2, recall:0.1\n",
      "f1 score:0.13333333333333333\n",
      "\n",
      "\n",
      "*** Method:  Decision Tree\n",
      "trained-acc:  100.0\n",
      "test-acc:  90.5\n",
      "accuracy:0.905, precision:0.09090909090909091, recall:0.1\n",
      "f1 score:0.09523809523809525\n",
      "\n",
      "\n",
      "*** Method:  Random Forest\n",
      "trained-acc:  99.88\n",
      "test-acc:  95.0\n",
      "accuracy:0.95, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  Ensemble\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained-acc:  100.0\n",
      "test-acc:  94.5\n",
      "accuracy:0.945, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2-1) 2 steps clustering(0-4)\n",
    "'''\n",
    "df3_2c = df3_outlier.copy()\n",
    "\n",
    "for col in df3_2c.columns:\n",
    "    df3_2c.loc[df3_2c[col] <= 1, col] = 0\n",
    "    df3_2c.loc[(df3_2c[col] > 1) & (df3_2c[col] <= 3), col] = 1\n",
    "    df3_2c.loc[(df3_2c[col] > 3) & (df3_2c[col] <= 5), col] = 2\n",
    "    df3_2c.loc[(df3_2c[col] > 5) & (df3_2c[col] <= 7), col] = 3\n",
    "    df3_2c.loc[(df3_2c[col] > 7) & (df3_2c[col] <= 9), col] = 4\n",
    "\n",
    "print(df3_2c.describe(), end='\\n\\n')\n",
    "\n",
    "df = pd.concat([df5, df1_outlier,df2,df3_2c,df4], axis=1)\n",
    "df = df.drop(['event', 'Treatment'], axis=1)\n",
    "\n",
    "print(df.columns.values)\n",
    "\n",
    "train_df, test_df = df.iloc[random_index[:800],:], df.iloc[random_index[800:1000],:]\n",
    "\n",
    "X_train = train_df.drop(['label'], axis=1)\n",
    "Y_train = train_df['label']\n",
    "\n",
    "X_test = test_df.drop(['label'], axis=1)\n",
    "Y_test = test_df['label']\n",
    "\n",
    "\n",
    "'''\n",
    "Add Time data(1) +  Correlating Clinic data(2-1) \n",
    "Training & Test\n",
    "'''\n",
    "\n",
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "colonial-maryland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Var1         Var2         Var3         Var4         Var5  \\\n",
      "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
      "mean      0.328667     0.365889     0.332889     0.356333     0.387000   \n",
      "std       0.207386     0.214559     0.210689     0.216080     0.210446   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.222222     0.222222     0.222222     0.222222     0.222222   \n",
      "50%       0.333333     0.333333     0.333333     0.333333     0.333333   \n",
      "75%       0.444444     0.444444     0.444444     0.444444     0.555556   \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "              Var6         Var7         Var8         Var9        Var10  \n",
      "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  \n",
      "mean      0.358556     0.262111     0.265889     0.259667     0.262000  \n",
      "std       0.223040     0.201703     0.202755     0.201437     0.201204  \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "25%       0.222222     0.111111     0.111111     0.111111     0.111111  \n",
      "50%       0.333333     0.222222     0.222222     0.222222     0.222222  \n",
      "75%       0.444444     0.444444     0.333333     0.333333     0.333333  \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
      "\n",
      "['label' 'time' 'Var1' 'Var2' 'Var3' 'Var4' 'Var5' 'Var6' 'Var7' 'Var8'\n",
      " 'Var9' 'Var10' 'G1' 'G2' 'G3' 'G4' 'G5' 'G6' 'G7' 'G8' 'G9' 'G10' 'G11'\n",
      " 'G12' 'G13' 'G14' 'G15' 'G16' 'G17' 'G18' 'G19' 'G20' 'G21' 'G22' 'G23'\n",
      " 'G24' 'G25' 'G26' 'G27' 'G28' 'G29' 'G30' 'G31' 'G32' 'G33' 'G34' 'G35'\n",
      " 'G36' 'G37' 'G38' 'G39' 'G40' 'G41' 'G42' 'G43' 'G44' 'G45' 'G46' 'G47'\n",
      " 'G48' 'G49' 'G50' 'G51' 'G52' 'G53' 'G54' 'G55' 'G56' 'G57' 'G58' 'G59'\n",
      " 'G60' 'G61' 'G62' 'G63' 'G64' 'G65' 'G66' 'G67' 'G68' 'G69' 'G70' 'G71'\n",
      " 'G72' 'G73' 'G74' 'G75' 'G76' 'G77' 'G78' 'G79' 'G80' 'G81' 'G82' 'G83'\n",
      " 'G84' 'G85' 'G86' 'G87' 'G88' 'G89' 'G90' 'G91' 'G92' 'G93' 'G94' 'G95'\n",
      " 'G96' 'G97' 'G98' 'G99' 'G100' 'G101' 'G102' 'G103' 'G104' 'G105' 'G106'\n",
      " 'G107' 'G108' 'G109' 'G110' 'G111' 'G112' 'G113' 'G114' 'G115' 'G116'\n",
      " 'G117' 'G118' 'G119' 'G120' 'G121' 'G122' 'G123' 'G124' 'G125' 'G126'\n",
      " 'G127' 'G128' 'G129' 'G130' 'G131' 'G132' 'G133' 'G134' 'G135' 'G136'\n",
      " 'G137' 'G138' 'G139' 'G140' 'G141' 'G142' 'G143' 'G144' 'G145' 'G146'\n",
      " 'G147' 'G148' 'G149' 'G150' 'G151' 'G152' 'G153' 'G154' 'G155' 'G156'\n",
      " 'G157' 'G158' 'G159' 'G160' 'G161' 'G162' 'G163' 'G164' 'G165' 'G166'\n",
      " 'G167' 'G168' 'G169' 'G170' 'G171' 'G172' 'G173' 'G174' 'G175' 'G176'\n",
      " 'G177' 'G178' 'G179' 'G180' 'G181' 'G182' 'G183' 'G184' 'G185' 'G186'\n",
      " 'G187' 'G188' 'G189' 'G190' 'G191' 'G192' 'G193' 'G194' 'G195' 'G196'\n",
      " 'G197' 'G198' 'G199' 'G200' 'G201' 'G202' 'G203' 'G204' 'G205' 'G206'\n",
      " 'G207' 'G208' 'G209' 'G210' 'G211' 'G212' 'G213' 'G214' 'G215' 'G216'\n",
      " 'G217' 'G218' 'G219' 'G220' 'G221' 'G222' 'G223' 'G224' 'G225' 'G226'\n",
      " 'G227' 'G228' 'G229' 'G230' 'G231' 'G232' 'G233' 'G234' 'G235' 'G236'\n",
      " 'G237' 'G238' 'G239' 'G240' 'G241' 'G242' 'G243' 'G244' 'G245' 'G246'\n",
      " 'G247' 'G248' 'G249' 'G250' 'G251' 'G252' 'G253' 'G254' 'G255' 'G256'\n",
      " 'G257' 'G258' 'G259' 'G260' 'G261' 'G262' 'G263' 'G264' 'G265' 'G266'\n",
      " 'G267' 'G268' 'G269' 'G270' 'G271' 'G272' 'G273' 'G274' 'G275' 'G276'\n",
      " 'G277' 'G278' 'G279' 'G280' 'G281' 'G282' 'G283' 'G284' 'G285' 'G286'\n",
      " 'G287' 'G288' 'G289' 'G290' 'G291' 'G292' 'G293' 'G294' 'G295' 'G296'\n",
      " 'G297' 'G298' 'G299' 'G300']\n",
      "*** Method:  LogisticRegression\n",
      "trained-acc:  99.25\n",
      "test-acc:  93.5\n",
      "accuracy:0.935, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  Support Vector Machines\n",
      "trained-acc:  95.25\n",
      "test-acc:  95.0\n",
      "accuracy:0.95, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  KNN or k-Nearest Neighbors\n",
      "trained-acc: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96.0\n",
      "test-acc:  94.5\n",
      "accuracy:0.945, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  Gaussian Naive Bayes\n",
      "trained-acc:  66.25\n",
      "test-acc:  64.0\n",
      "accuracy:0.64, precision:0.08108108108108109, recall:0.6\n",
      "f1 score:0.14285714285714288\n",
      "\n",
      "\n",
      "*** Method:  Perceptron\n",
      "trained-acc:  95.38\n",
      "test-acc:  95.0\n",
      "accuracy:0.95, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  Linear SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained-acc:  100.0\n",
      "test-acc:  91.0\n",
      "accuracy:0.91, precision:0.16666666666666666, recall:0.2\n",
      "f1 score:0.1818181818181818\n",
      "\n",
      "\n",
      "*** Method:  Stochastic Gradient Descent\n",
      "trained-acc:  98.0\n",
      "test-acc:  94.5\n",
      "accuracy:0.945, precision:0.3333333333333333, recall:0.1\n",
      "f1 score:0.15384615384615383\n",
      "\n",
      "\n",
      "*** Method:  Decision Tree\n",
      "trained-acc:  100.0\n",
      "test-acc:  90.5\n",
      "accuracy:0.905, precision:0.09090909090909091, recall:0.1\n",
      "f1 score:0.09523809523809525\n",
      "\n",
      "\n",
      "*** Method:  Random Forest\n",
      "trained-acc:  99.62\n",
      "test-acc:  95.0\n",
      "accuracy:0.95, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  Ensemble\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained-acc:  100.0\n",
      "test-acc:  94.5\n",
      "accuracy:0.945, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2-2) just resizing(0-1)\n",
    "'''\n",
    "df3_rs = df3_outlier.copy()\n",
    "\n",
    "for col in df3_rs.columns:\n",
    "    df3_rs[col] = df3_rs[col]/9\n",
    "\n",
    "print(df3_rs.describe(), end='\\n\\n')\n",
    "\n",
    "df = pd.concat([df5, df1_outlier,df2,df3_rs,df4], axis=1)\n",
    "df = df.drop(['event', 'Treatment'], axis=1)\n",
    "\n",
    "print(df.columns.values)\n",
    "\n",
    "train_df, test_df = df.iloc[random_index[:800],:], df.iloc[random_index[800:1000],:]\n",
    "\n",
    "X_train = train_df.drop(['label'], axis=1)\n",
    "Y_train = train_df['label']\n",
    "\n",
    "X_test = test_df.drop(['label'], axis=1)\n",
    "Y_test = test_df['label']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Add Time data(1) +  Correlating Clinic data(2-2) \n",
    "Training & Test\n",
    "'''\n",
    "\n",
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0bea627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** train result ***\n",
      "\n",
      "                      LogisticRegression  Support Vector Machines  \\\n",
      "Basic                              99.38                    95.25   \n",
      "Time_outlier                       99.38                    95.25   \n",
      "Time_/365                          99.38                    95.25   \n",
      "Clinic_outlier                     99.38                    95.25   \n",
      "Clinic_0-4(2steps)                 99.38                    95.25   \n",
      "Clinic_0-1(resizing)               99.25                    95.25   \n",
      "\n",
      "                      KNN or k-Nearest Neighbors  Gaussian Naive Bayes  \\\n",
      "Basic                                      95.25                 57.88   \n",
      "Time_outlier                               96.00                 66.25   \n",
      "Time_/365                                  95.25                 57.88   \n",
      "Clinic_outlier                             96.00                 66.25   \n",
      "Clinic_0-4(2steps)                         96.00                 66.25   \n",
      "Clinic_0-1(resizing)                       96.00                 66.25   \n",
      "\n",
      "                      Perceptron  Linear SVC  Stochastic Gradient Descent  \\\n",
      "Basic                      95.62       100.0                        96.38   \n",
      "Time_outlier               95.50       100.0                        95.50   \n",
      "Time_/365                  98.00       100.0                       100.00   \n",
      "Clinic_outlier             96.25       100.0                        96.62   \n",
      "Clinic_0-4(2steps)         95.50       100.0                        96.38   \n",
      "Clinic_0-1(resizing)       95.38       100.0                        98.00   \n",
      "\n",
      "                      Decision Tree  Random Forest  Ensemble  \n",
      "Basic                         100.0          99.38     100.0  \n",
      "Time_outlier                  100.0          99.88     100.0  \n",
      "Time_/365                     100.0          99.62     100.0  \n",
      "Clinic_outlier                100.0          99.12     100.0  \n",
      "Clinic_0-4(2steps)            100.0          99.88     100.0  \n",
      "Clinic_0-1(resizing)          100.0          99.62     100.0  \n",
      "\n",
      "\n",
      "\n",
      "*** test result ***\n",
      "\n",
      "                      LogisticRegression  Support Vector Machines  \\\n",
      "Basic                               94.0                     95.0   \n",
      "Time_outlier                        95.0                     95.0   \n",
      "Time_/365                           94.0                     95.0   \n",
      "Clinic_outlier                      95.0                     95.0   \n",
      "Clinic_0-4(2steps)                  93.5                     95.0   \n",
      "Clinic_0-1(resizing)                93.5                     95.0   \n",
      "\n",
      "                      KNN or k-Nearest Neighbors  Gaussian Naive Bayes  \\\n",
      "Basic                                       95.0                  60.5   \n",
      "Time_outlier                                94.5                  64.0   \n",
      "Time_/365                                   95.0                  60.5   \n",
      "Clinic_outlier                              94.5                  64.0   \n",
      "Clinic_0-4(2steps)                          94.5                  63.5   \n",
      "Clinic_0-1(resizing)                        94.5                  64.0   \n",
      "\n",
      "                      Perceptron  Linear SVC  Stochastic Gradient Descent  \\\n",
      "Basic                       83.5        92.5                         87.0   \n",
      "Time_outlier                95.0        93.0                         95.0   \n",
      "Time_/365                   93.5        92.5                         92.5   \n",
      "Clinic_outlier              94.5        93.0                         94.5   \n",
      "Clinic_0-4(2steps)          95.0        92.5                         93.5   \n",
      "Clinic_0-1(resizing)        95.0        91.0                         94.5   \n",
      "\n",
      "                      Decision Tree  Random Forest  Ensemble  \n",
      "Basic                          89.5           95.0      95.0  \n",
      "Time_outlier                   91.5           95.0      95.0  \n",
      "Time_/365                      90.0           95.0      95.0  \n",
      "Clinic_outlier                 90.5           95.0      94.5  \n",
      "Clinic_0-4(2steps)             90.5           95.0      94.5  \n",
      "Clinic_0-1(resizing)           90.5           95.0      94.5  \n",
      "\n",
      "\n",
      "\n",
      "*** test acc ***\n",
      "\n",
      "                      LogisticRegression  Support Vector Machines  \\\n",
      "Basic                              0.940                     0.95   \n",
      "Time_outlier                       0.950                     0.95   \n",
      "Time_/365                          0.940                     0.95   \n",
      "Clinic_outlier                     0.950                     0.95   \n",
      "Clinic_0-4(2steps)                 0.935                     0.95   \n",
      "Clinic_0-1(resizing)               0.935                     0.95   \n",
      "\n",
      "                      KNN or k-Nearest Neighbors  Gaussian Naive Bayes  \\\n",
      "Basic                                      0.950                 0.605   \n",
      "Time_outlier                               0.945                 0.640   \n",
      "Time_/365                                  0.950                 0.605   \n",
      "Clinic_outlier                             0.945                 0.640   \n",
      "Clinic_0-4(2steps)                         0.945                 0.635   \n",
      "Clinic_0-1(resizing)                       0.945                 0.640   \n",
      "\n",
      "                      Perceptron  Linear SVC  Stochastic Gradient Descent  \\\n",
      "Basic                      0.835       0.925                        0.870   \n",
      "Time_outlier               0.950       0.930                        0.950   \n",
      "Time_/365                  0.935       0.925                        0.925   \n",
      "Clinic_outlier             0.945       0.930                        0.945   \n",
      "Clinic_0-4(2steps)         0.950       0.925                        0.935   \n",
      "Clinic_0-1(resizing)       0.950       0.910                        0.945   \n",
      "\n",
      "                      Decision Tree  Random Forest  Ensemble  \n",
      "Basic                         0.895           0.95     0.950  \n",
      "Time_outlier                  0.915           0.95     0.950  \n",
      "Time_/365                     0.900           0.95     0.950  \n",
      "Clinic_outlier                0.905           0.95     0.945  \n",
      "Clinic_0-4(2steps)            0.905           0.95     0.945  \n",
      "Clinic_0-1(resizing)          0.905           0.95     0.945  \n",
      "\n",
      "\n",
      "\n",
      "*** test pre ***\n",
      "\n",
      "                      LogisticRegression  Support Vector Machines  \\\n",
      "Basic                                0.0                      0.0   \n",
      "Time_outlier                         0.5                      0.0   \n",
      "Time_/365                            0.0                      0.0   \n",
      "Clinic_outlier                       0.5                      0.0   \n",
      "Clinic_0-4(2steps)                   0.0                      0.0   \n",
      "Clinic_0-1(resizing)                 0.0                      0.0   \n",
      "\n",
      "                      KNN or k-Nearest Neighbors  Gaussian Naive Bayes  \\\n",
      "Basic                                        0.0              0.084337   \n",
      "Time_outlier                                 0.0              0.081081   \n",
      "Time_/365                                    0.0              0.084337   \n",
      "Clinic_outlier                               0.0              0.081081   \n",
      "Clinic_0-4(2steps)                           0.0              0.080000   \n",
      "Clinic_0-1(resizing)                         0.0              0.081081   \n",
      "\n",
      "                      Perceptron  Linear SVC  Stochastic Gradient Descent  \\\n",
      "Basic                   0.040000    0.222222                     0.100000   \n",
      "Time_outlier            0.000000    0.250000                     0.000000   \n",
      "Time_/365               0.000000    0.222222                     0.222222   \n",
      "Clinic_outlier          0.333333    0.250000                     0.000000   \n",
      "Clinic_0-4(2steps)      0.000000    0.222222                     0.200000   \n",
      "Clinic_0-1(resizing)    0.000000    0.166667                     0.333333   \n",
      "\n",
      "                      Decision Tree  Random Forest  Ensemble  \n",
      "Basic                      0.076923            0.0       0.0  \n",
      "Time_outlier               0.111111            0.0       0.0  \n",
      "Time_/365                  0.000000            0.0       0.0  \n",
      "Clinic_outlier             0.000000            0.0       0.0  \n",
      "Clinic_0-4(2steps)         0.090909            0.0       0.0  \n",
      "Clinic_0-1(resizing)       0.090909            0.0       0.0  \n",
      "\n",
      "\n",
      "\n",
      "*** test rec ***\n",
      "\n",
      "                      LogisticRegression  Support Vector Machines  \\\n",
      "Basic                                0.0                      0.0   \n",
      "Time_outlier                         0.2                      0.0   \n",
      "Time_/365                            0.0                      0.0   \n",
      "Clinic_outlier                       0.2                      0.0   \n",
      "Clinic_0-4(2steps)                   0.0                      0.0   \n",
      "Clinic_0-1(resizing)                 0.0                      0.0   \n",
      "\n",
      "                      KNN or k-Nearest Neighbors  Gaussian Naive Bayes  \\\n",
      "Basic                                        0.0                   0.7   \n",
      "Time_outlier                                 0.0                   0.6   \n",
      "Time_/365                                    0.0                   0.7   \n",
      "Clinic_outlier                               0.0                   0.6   \n",
      "Clinic_0-4(2steps)                           0.0                   0.6   \n",
      "Clinic_0-1(resizing)                         0.0                   0.6   \n",
      "\n",
      "                      Perceptron  Linear SVC  Stochastic Gradient Descent  \\\n",
      "Basic                        0.1         0.2                          0.2   \n",
      "Time_outlier                 0.0         0.2                          0.0   \n",
      "Time_/365                    0.0         0.2                          0.2   \n",
      "Clinic_outlier               0.1         0.2                          0.0   \n",
      "Clinic_0-4(2steps)           0.0         0.2                          0.1   \n",
      "Clinic_0-1(resizing)         0.0         0.2                          0.1   \n",
      "\n",
      "                      Decision Tree  Random Forest  Ensemble  \n",
      "Basic                           0.1            0.0       0.0  \n",
      "Time_outlier                    0.1            0.0       0.0  \n",
      "Time_/365                       0.0            0.0       0.0  \n",
      "Clinic_outlier                  0.0            0.0       0.0  \n",
      "Clinic_0-4(2steps)              0.1            0.0       0.0  \n",
      "Clinic_0-1(resizing)            0.1            0.0       0.0  \n",
      "\n",
      "\n",
      "\n",
      "*** test f1 ***\n",
      "\n",
      "                      LogisticRegression  Support Vector Machines  \\\n",
      "Basic                           0.000000                      0.0   \n",
      "Time_outlier                    0.285714                      0.0   \n",
      "Time_/365                       0.000000                      0.0   \n",
      "Clinic_outlier                  0.285714                      0.0   \n",
      "Clinic_0-4(2steps)              0.000000                      0.0   \n",
      "Clinic_0-1(resizing)            0.000000                      0.0   \n",
      "\n",
      "                      KNN or k-Nearest Neighbors  Gaussian Naive Bayes  \\\n",
      "Basic                                        0.0              0.150538   \n",
      "Time_outlier                                 0.0              0.142857   \n",
      "Time_/365                                    0.0              0.150538   \n",
      "Clinic_outlier                               0.0              0.142857   \n",
      "Clinic_0-4(2steps)                           0.0              0.141176   \n",
      "Clinic_0-1(resizing)                         0.0              0.142857   \n",
      "\n",
      "                      Perceptron  Linear SVC  Stochastic Gradient Descent  \\\n",
      "Basic                   0.057143    0.210526                     0.133333   \n",
      "Time_outlier            0.000000    0.222222                     0.000000   \n",
      "Time_/365               0.000000    0.210526                     0.210526   \n",
      "Clinic_outlier          0.153846    0.222222                     0.000000   \n",
      "Clinic_0-4(2steps)      0.000000    0.210526                     0.133333   \n",
      "Clinic_0-1(resizing)    0.000000    0.181818                     0.153846   \n",
      "\n",
      "                      Decision Tree  Random Forest  Ensemble  \n",
      "Basic                      0.086957            0.0       0.0  \n",
      "Time_outlier               0.105263            0.0       0.0  \n",
      "Time_/365                  0.000000            0.0       0.0  \n",
      "Clinic_outlier             0.000000            0.0       0.0  \n",
      "Clinic_0-4(2steps)         0.095238            0.0       0.0  \n",
      "Clinic_0-1(resizing)       0.095238            0.0       0.0  \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('*** train result ***', end='\\n\\n')\n",
    "result_train_df.index = index\n",
    "print(result_train_df)\n",
    "print(end='\\n\\n\\n')\n",
    "\n",
    "print('*** test result ***', end='\\n\\n')\n",
    "result_test_df.index = index\n",
    "print(result_test_df)\n",
    "print(end='\\n\\n\\n')\n",
    "\n",
    "print('*** test acc ***', end='\\n\\n')\n",
    "result_acc_test_df.index = index\n",
    "print(result_acc_test_df)\n",
    "print(end='\\n\\n\\n')\n",
    "\n",
    "print('*** test pre ***', end='\\n\\n')\n",
    "result_pre_test_df.index = index\n",
    "print(result_pre_test_df)\n",
    "print(end='\\n\\n\\n')\n",
    "\n",
    "print('*** test rec ***', end='\\n\\n')\n",
    "result_rec_test_df.index = index\n",
    "print(result_rec_test_df)\n",
    "print(end='\\n\\n\\n')\n",
    "\n",
    "print('*** test f1 ***', end='\\n\\n')\n",
    "result_f1score_test_df.index = index\n",
    "print(result_f1score_test_df)\n",
    "print(end='\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99029de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression              99.38\n",
      "Support Vector Machines         95.25\n",
      "KNN or k-Nearest Neighbors      96.00\n",
      "Gaussian Naive Bayes            66.25\n",
      "Perceptron                      98.00\n",
      "Linear SVC                     100.00\n",
      "Stochastic Gradient Descent    100.00\n",
      "Decision Tree                  100.00\n",
      "Random Forest                   99.88\n",
      "Ensemble                       100.00\n",
      "Name: max, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(result_train_df.describe().loc['max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce0ea3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression             95.0\n",
      "Support Vector Machines        95.0\n",
      "KNN or k-Nearest Neighbors     95.0\n",
      "Gaussian Naive Bayes           64.0\n",
      "Perceptron                     95.0\n",
      "Linear SVC                     93.0\n",
      "Stochastic Gradient Descent    95.0\n",
      "Decision Tree                  91.5\n",
      "Random Forest                  95.0\n",
      "Ensemble                       95.0\n",
      "Name: max, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(result_test_df.describe().loc['max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "tired-routine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression             0.950\n",
      "Support Vector Machines        0.950\n",
      "KNN or k-Nearest Neighbors     0.950\n",
      "Gaussian Naive Bayes           0.640\n",
      "Perceptron                     0.950\n",
      "Linear SVC                     0.930\n",
      "Stochastic Gradient Descent    0.950\n",
      "Decision Tree                  0.915\n",
      "Random Forest                  0.950\n",
      "Ensemble                       0.950\n",
      "Name: max, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(result_acc_test_df.describe().loc['max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "usual-regard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression             0.500000\n",
      "Support Vector Machines        0.000000\n",
      "KNN or k-Nearest Neighbors     0.000000\n",
      "Gaussian Naive Bayes           0.084337\n",
      "Perceptron                     0.333333\n",
      "Linear SVC                     0.250000\n",
      "Stochastic Gradient Descent    0.333333\n",
      "Decision Tree                  0.111111\n",
      "Random Forest                  0.000000\n",
      "Ensemble                       0.000000\n",
      "Name: max, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(result_pre_test_df.describe().loc['max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "golden-level",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression             0.2\n",
      "Support Vector Machines        0.0\n",
      "KNN or k-Nearest Neighbors     0.0\n",
      "Gaussian Naive Bayes           0.7\n",
      "Perceptron                     0.1\n",
      "Linear SVC                     0.2\n",
      "Stochastic Gradient Descent    0.2\n",
      "Decision Tree                  0.1\n",
      "Random Forest                  0.0\n",
      "Ensemble                       0.0\n",
      "Name: max, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(result_rec_test_df.describe().loc['max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "monthly-hungary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression             0.285714\n",
      "Support Vector Machines        0.000000\n",
      "KNN or k-Nearest Neighbors     0.000000\n",
      "Gaussian Naive Bayes           0.150538\n",
      "Perceptron                     0.153846\n",
      "Linear SVC                     0.222222\n",
      "Stochastic Gradient Descent    0.210526\n",
      "Decision Tree                  0.105263\n",
      "Random Forest                  0.000000\n",
      "Ensemble                       0.000000\n",
      "Name: max, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(result_f1score_test_df.describe().loc['max'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
