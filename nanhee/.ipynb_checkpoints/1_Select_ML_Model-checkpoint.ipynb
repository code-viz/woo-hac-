{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "exclusive-religious",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "import lightgbm as lgb\n",
    "# !pip install xgboost\n",
    "# !pip install lightgbm\n",
    "# !pip install imblearn\n",
    "# !pip install borutashap\n",
    "plt.rcParams[\"figure.figsize\"] = (200,10)\n",
    "\n",
    "\n",
    "'''\n",
    "###########################################\n",
    "\n",
    "Load CSV Dataset to DataFrame\n",
    "\n",
    "###########################################\n",
    "'''\n",
    "\n",
    "\n",
    "time_table = pd.read_csv('Survival_time_event.csv', index_col=0)\n",
    "clinic_table = pd.read_csv('Clinical_Variables.csv', index_col=0)\n",
    "genetic_table = pd.read_csv('Genetic_alterations.csv', index_col=0)\n",
    "survival_treatment_table = pd.read_csv('Label.csv', index_col=0)\n",
    "\n",
    "\n",
    "'''\n",
    "###########################################\n",
    "\n",
    "Correlating Numerical Features of Time Data\n",
    "\n",
    "-  Dropped Outlier Value\n",
    "\n",
    "###########################################\n",
    "'''\n",
    "\n",
    "\n",
    "print('outlier of time: ')\n",
    "print(time_table.loc[time_table['time'] < 0, 'time'], end='\\n\\n')\n",
    "\n",
    "time_table_outlier = time_table.copy()\n",
    "time_table_outlier.loc[time_table_outlier['time'] < 0, 'time'] = abs(time_table_outlier.loc[time_table_outlier['time'] < 0, 'time'])\n",
    "print(time_table_outlier.describe(), end='\\n\\n')\n",
    "\n",
    "\n",
    "'''\n",
    "###########################################\n",
    "\n",
    "Correlating Numerical Features of Clinic Data\n",
    "\n",
    "-  Dropped Outlier Value\n",
    "\n",
    "###########################################\n",
    "'''\n",
    "\n",
    "\n",
    "clinic_table_outlier = clinic_table.copy()\n",
    "\n",
    "# drop outlier\n",
    "for col in clinic_table_outlier.columns:\n",
    "    for outlier in range(10,13):\n",
    "        clinic_table_outlier = clinic_table_outlier.replace(outlier, 9)\n",
    "\n",
    "# visualize\n",
    "for col in clinic_table_outlier.columns:\n",
    "    print('#', col)\n",
    "    print(clinic_table_outlier[col].value_counts())\n",
    "    print('-'*20)\n",
    "   \n",
    "\n",
    "'''\n",
    "###########################################\n",
    "\n",
    "Correlating Numerical Features of Clinic Data\n",
    "\n",
    "- Normalization\n",
    "\n",
    "###########################################\n",
    "'''\n",
    "\n",
    "\n",
    "clinic_table_normalization = clinic_table_outlier.copy()\n",
    "\n",
    "# normalization\n",
    "for col in clinic_table_normalization.columns:\n",
    "    clinic_table_normalization[col] = (clinic_table_normalization[col] + 1)/10.0\n",
    "    \n",
    "# visualize\n",
    "for col in clinic_table_normalization.columns:\n",
    "    print('#', col)\n",
    "    print(clinic_table_normalization[col].value_counts())\n",
    "    print('-'*20)    \n",
    "    \n",
    "    \n",
    "'''\n",
    "###########################################\n",
    "\n",
    "Correlating Numerical Features of Genetic Data\n",
    "\n",
    "- Normalization\n",
    "\n",
    "###########################################\n",
    "'''\n",
    "\n",
    "\n",
    "genetic_table_normalization = genetic_table.copy()\n",
    "\n",
    "# normalization\n",
    "for col in genetic_table_normalization.columns:\n",
    "    genetic_table_normalization[col] -= 0.5\n",
    "    \n",
    "    \n",
    "print(genetic_table_normalization.head(10))\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "###########################################\n",
    "\n",
    "Dataset of Best Accuracy\n",
    "\n",
    "###########################################\n",
    "'''\n",
    "\n",
    "input_dataset = pd.concat([survival_treatment_table, time_table_outlier, clinic_table_normalization ,genetic_table_normalization], axis=1)\n",
    "input_dataset = input_dataset.drop(['event'], axis=1)\n",
    "\n",
    "\n",
    "'''\n",
    "###########################################\n",
    "\n",
    "Model list\n",
    "\n",
    "###########################################\n",
    "'''\n",
    "\n",
    "ensemble_models = [\n",
    "    ('lrcv', LogisticRegression(max_iter = 10000)),\n",
    "    ('ada', AdaBoostClassifier()),\n",
    "    ('bc', BaggingClassifier()),\n",
    "    ('etc',ExtraTreesClassifier()),\n",
    "    ('gbc', GradientBoostingClassifier()),\n",
    "    ('rfc', RandomForestClassifier(n_estimators=20)),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors = 4)),\n",
    "    ('svc', SVC(probability=True)),\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss')),\n",
    "    ('lgbm', LGBMClassifier()),\n",
    "    ('dtc', DecisionTreeClassifier()),\n",
    "    ('gnb',GaussianNB()),\n",
    "]\n",
    "\n",
    "models = [VotingClassifier(ensemble_models, voting='soft'),\n",
    "          lgb.LGBMClassifier(n_estimators=30,num_leaves=64,n_jobs=-1,boost_from_average=False),\n",
    "          LogisticRegression(max_iter = 10000), \n",
    "          SVC(), \n",
    "          KNeighborsClassifier(n_neighbors = 4), \n",
    "          GaussianNB(), \n",
    "          Perceptron(),\n",
    "          SGDClassifier(), \n",
    "          DecisionTreeClassifier(), \n",
    "          RandomForestClassifier(n_estimators=60)]\n",
    "\n",
    "\n",
    "'''\n",
    "###########################################\n",
    "\n",
    "Select Model of Best Accuracy\n",
    "\n",
    "###########################################\n",
    "'''\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def training(model_list):\n",
    "    best_model = []\n",
    "    for model in model_list:\n",
    "        model_name = str(model)[:str(model).find('(')]\n",
    "        print('Model: ', model_name)\n",
    "        print()\n",
    "        features = input_dataset.drop(['newlabel'], axis=1)\n",
    "        labels = input_dataset['newlabel']\n",
    "        \n",
    "        splits = [5, 10, 7]\n",
    "        \n",
    "        for s in splits:\n",
    "            skfold = StratifiedKFold(n_splits=s)\n",
    "            idx_iter=0\n",
    "            cv_accuracy=[]\n",
    "            cv_precision=[]\n",
    "            cv_recall=[]\n",
    "            cv_f1score=[]\n",
    "\n",
    "            for i in range(10):\n",
    "                features = features.sample(frac=1).reset_index(drop=True)\n",
    "                labels = labels.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "                for train_index, test_index in skfold.split(features,labels):\n",
    "                    np.random.shuffle(train_index)\n",
    "                    np.random.shuffle(test_index)\n",
    "\n",
    "                    # split train and test set\n",
    "                    X_train, X_test = features.iloc[train_index,:], features.iloc[test_index,:]\n",
    "                    y_train, y_test = labels.iloc[train_index], labels.iloc[test_index]\n",
    "\n",
    "                    # train ans prediction\n",
    "                    model.fit(X_train, y_train)\n",
    "                    pred = model.predict(X_test)\n",
    "\n",
    "                    idx_iter += 1\n",
    "\n",
    "                    # \n",
    "                    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "                    cv_accuracy.append(accuracy)\n",
    "\n",
    "                    precision = np.round(precision_score(y_test, pred, average='weighted', zero_division=0), 4)\n",
    "                    cv_precision.append(precision)\n",
    "\n",
    "                    recall = np.round(recall_score(y_test, pred, average='weighted', zero_division=0), 4)\n",
    "                    cv_recall.append(recall)\n",
    "\n",
    "                    f1score = np.round(f1_score(y_test, pred, average='weighted', zero_division=0), 4)\n",
    "                    cv_f1score.append(f1score)\n",
    "\n",
    "                    #train_size = X_train.shape[0]\n",
    "                    #test_size = X_test.shape[0]\n",
    "\n",
    "                    #print('\\n#{0} 교차 검증 정확도: {1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'.format(idx_iter, accuracy, train_size, test_size))\n",
    "                    #print('#{0} 검증 세트 인덱스: MIN{1}, MAX{2}'.format(idx_iter, min(test_index), max(test_index)))\n",
    "\n",
    "                    #print('학습 레이블 데이터 분포: \\n', pd.Series(y_train).value_counts())\n",
    "                    #print('검증 레이블 데이터 분포: \\n', pd.Series(y_test).value_counts())\n",
    "\n",
    "            print('## 교차 검증 총 횟수: ', len(cv_accuracy), '(분할개수:', s, ')')\n",
    "            # print('## 교차 검증별 정확도: ', np.round(cv_accuracy, 4))\n",
    "            print('## 평균 검증 정확도: ', np.round(np.mean(cv_accuracy), 5))\n",
    "            print('## 평균 검증 F1 Score: ', np.round(np.mean(cv_f1score), 5))\n",
    "            print('##')\n",
    "            \n",
    "            #save model name, split num, acc, pre, rec, f1\n",
    "            best_model.append([model_name, s, \n",
    "                               np.round(np.mean(cv_accuracy), 5), \n",
    "                               np.round(np.mean(cv_precision), 5),\n",
    "                               np.round(np.mean(cv_recall), 5),\n",
    "                               np.round(np.mean(cv_f1score), 5)])\n",
    "        print()\n",
    "        print('-'*100)\n",
    "        print()\n",
    "        \n",
    "training(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "analyzed-entity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  VotingClassifier\n",
      "\n",
      "## 교차 검증 총 횟수:  50 (분할개수: 5 )\n",
      "## 평균 검증 정확도:  0.4411\n",
      "## 평균 검증 F1 Score:  0.41502\n",
      "##\n",
      "## 교차 검증 총 횟수:  100 (분할개수: 10 )\n",
      "## 평균 검증 정확도:  0.4527\n",
      "## 평균 검증 F1 Score:  0.42527\n",
      "##\n",
      "## 교차 검증 총 횟수:  70 (분할개수: 7 )\n",
      "## 평균 검증 정확도:  0.44822\n",
      "## 평균 검증 F1 Score:  0.42134\n",
      "##\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Model:  LGBMClassifier\n",
      "\n",
      "## 교차 검증 총 횟수:  50 (분할개수: 5 )\n",
      "## 평균 검증 정확도:  0.4502\n",
      "## 평균 검증 F1 Score:  0.42367\n",
      "##\n",
      "## 교차 검증 총 횟수:  100 (분할개수: 10 )\n",
      "## 평균 검증 정확도:  0.4534\n",
      "## 평균 검증 F1 Score:  0.42657\n",
      "##\n",
      "## 교차 검증 총 횟수:  70 (분할개수: 7 )\n",
      "## 평균 검증 정확도:  0.45099\n",
      "## 평균 검증 F1 Score:  0.42485\n",
      "##\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Model:  LogisticRegression\n",
      "\n",
      "## 교차 검증 총 횟수:  50 (분할개수: 5 )\n",
      "## 평균 검증 정확도:  0.4362\n",
      "## 평균 검증 F1 Score:  0.42612\n",
      "##\n",
      "## 교차 검증 총 횟수:  100 (분할개수: 10 )\n",
      "## 평균 검증 정확도:  0.4192\n",
      "## 평균 검증 F1 Score:  0.4101\n",
      "##\n",
      "## 교차 검증 총 횟수:  70 (분할개수: 7 )\n",
      "## 평균 검증 정확도:  0.41531\n",
      "## 평균 검증 F1 Score:  0.40688\n",
      "##\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Model:  SVC\n",
      "\n",
      "## 교차 검증 총 횟수:  50 (분할개수: 5 )\n",
      "## 평균 검증 정확도:  0.4569\n",
      "## 평균 검증 F1 Score:  0.38586\n",
      "##\n",
      "## 교차 검증 총 횟수:  100 (분할개수: 10 )\n",
      "## 평균 검증 정확도:  0.4527\n",
      "## 평균 검증 F1 Score:  0.36592\n",
      "##\n",
      "## 교차 검증 총 횟수:  70 (분할개수: 7 )\n",
      "## 평균 검증 정확도:  0.44731\n",
      "## 평균 검증 F1 Score:  0.34796\n",
      "##\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Model:  KNeighborsClassifier\n",
      "\n",
      "## 교차 검증 총 횟수:  50 (분할개수: 5 )\n",
      "## 평균 검증 정확도:  0.4295\n",
      "## 평균 검증 F1 Score:  0.40796\n",
      "##\n",
      "## 교차 검증 총 횟수:  100 (분할개수: 10 )\n",
      "## 평균 검증 정확도:  0.4308\n",
      "## 평균 검증 F1 Score:  0.40669\n",
      "##\n",
      "## 교차 검증 총 횟수:  70 (분할개수: 7 )\n",
      "## 평균 검증 정확도:  0.42451\n",
      "## 평균 검증 F1 Score:  0.40161\n",
      "##\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Model:  GaussianNB\n",
      "\n",
      "## 교차 검증 총 횟수:  50 (분할개수: 5 )\n",
      "## 평균 검증 정확도:  0.285\n",
      "## 평균 검증 F1 Score:  0.32398\n",
      "##\n",
      "## 교차 검증 총 횟수:  100 (분할개수: 10 )\n",
      "## 평균 검증 정확도:  0.3143\n",
      "## 평균 검증 F1 Score:  0.3453\n",
      "##\n",
      "## 교차 검증 총 횟수:  70 (분할개수: 7 )\n",
      "## 평균 검증 정확도:  0.30109\n",
      "## 평균 검증 F1 Score:  0.33773\n",
      "##\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Model:  Perceptron\n",
      "\n",
      "## 교차 검증 총 횟수:  50 (분할개수: 5 )\n",
      "## 평균 검증 정확도:  0.4135\n",
      "## 평균 검증 F1 Score:  0.29649\n",
      "##\n",
      "## 교차 검증 총 횟수:  100 (분할개수: 10 )\n",
      "## 평균 검증 정확도:  0.3695\n",
      "## 평균 검증 F1 Score:  0.25704\n",
      "##\n",
      "## 교차 검증 총 횟수:  70 (분할개수: 7 )\n",
      "## 평균 검증 정확도:  0.38866\n",
      "## 평균 검증 F1 Score:  0.26934\n",
      "##\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Model:  SGDClassifier\n",
      "\n",
      "## 교차 검증 총 횟수:  50 (분할개수: 5 )\n",
      "## 평균 검증 정확도:  0.3953\n",
      "## 평균 검증 F1 Score:  0.31922\n",
      "##\n",
      "## 교차 검증 총 횟수:  100 (분할개수: 10 )\n",
      "## 평균 검증 정확도:  0.4024\n",
      "## 평균 검증 F1 Score:  0.33017\n",
      "##\n",
      "## 교차 검증 총 횟수:  70 (분할개수: 7 )\n",
      "## 평균 검증 정확도:  0.40298\n",
      "## 평균 검증 F1 Score:  0.33971\n",
      "##\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Model:  DecisionTreeClassifier\n",
      "\n",
      "## 교차 검증 총 횟수:  50 (분할개수: 5 )\n",
      "## 평균 검증 정확도:  0.4042\n",
      "## 평균 검증 F1 Score:  0.40391\n",
      "##\n",
      "## 교차 검증 총 횟수:  100 (분할개수: 10 )\n",
      "## 평균 검증 정확도:  0.4021\n",
      "## 평균 검증 F1 Score:  0.40213\n",
      "##\n",
      "## 교차 검증 총 횟수:  70 (분할개수: 7 )\n",
      "## 평균 검증 정확도:  0.39681\n",
      "## 평균 검증 F1 Score:  0.39697\n",
      "##\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Model:  RandomForestClassifier\n",
      "\n",
      "## 교차 검증 총 횟수:  50 (분할개수: 5 )\n",
      "## 평균 검증 정확도:  0.4418\n",
      "## 평균 검증 F1 Score:  0.41556\n",
      "##\n",
      "## 교차 검증 총 횟수:  100 (분할개수: 10 )\n",
      "## 평균 검증 정확도:  0.454\n",
      "## 평균 검증 F1 Score:  0.427\n",
      "##\n",
      "## 교차 검증 총 횟수:  70 (분할개수: 7 )\n",
      "## 평균 검증 정확도:  0.44523\n",
      "## 평균 검증 F1 Score:  0.4189\n",
      "##\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c6b7a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac5621c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d40fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a171c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab802ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ee4c67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "active-bonus",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-1d81de978959>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp_best_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmax_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp_best_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmax_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "np_best_model = np.array(best_model)\n",
    "max_model = np.argmax(np_best_model, axis=0)\n",
    "print(best_model[max_model,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
