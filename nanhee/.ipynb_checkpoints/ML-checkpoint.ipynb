{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exclusive-religious",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\enssel\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\enssel\\anaconda3\\lib\\site-packages (from xgboost) (1.6.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\enssel\\anaconda3\\lib\\site-packages (from xgboost) (1.19.2)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\enssel\\anaconda3\\lib\\site-packages (3.2.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\enssel\\anaconda3\\lib\\site-packages (from lightgbm) (1.6.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\enssel\\anaconda3\\lib\\site-packages (from lightgbm) (1.19.2)\n",
      "Requirement already satisfied: wheel in c:\\users\\enssel\\anaconda3\\lib\\site-packages (from lightgbm) (0.36.2)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\enssel\\anaconda3\\lib\\site-packages (from lightgbm) (0.24.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\enssel\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\enssel\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "!pip install xgboost\n",
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "analyzed-entity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('Survival_time_event.csv', index_col=0)\n",
    "df2=pd.read_csv('Treatment.csv', index_col=0)\n",
    "df3=pd.read_csv('Clinical_Variables.csv', index_col=0)\n",
    "df4=pd.read_csv('Genetic_alterations.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aware-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1,df2,df3,df4], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "municipal-percentage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['time' 'event' 'Treatment' 'Var1' 'Var2' 'Var3' 'Var4' 'Var5' 'Var6'\n",
      " 'Var7' 'Var8' 'Var9' 'Var10' 'G1' 'G2' 'G3' 'G4' 'G5' 'G6' 'G7' 'G8' 'G9'\n",
      " 'G10' 'G11' 'G12' 'G13' 'G14' 'G15' 'G16' 'G17' 'G18' 'G19' 'G20' 'G21'\n",
      " 'G22' 'G23' 'G24' 'G25' 'G26' 'G27' 'G28' 'G29' 'G30' 'G31' 'G32' 'G33'\n",
      " 'G34' 'G35' 'G36' 'G37' 'G38' 'G39' 'G40' 'G41' 'G42' 'G43' 'G44' 'G45'\n",
      " 'G46' 'G47' 'G48' 'G49' 'G50' 'G51' 'G52' 'G53' 'G54' 'G55' 'G56' 'G57'\n",
      " 'G58' 'G59' 'G60' 'G61' 'G62' 'G63' 'G64' 'G65' 'G66' 'G67' 'G68' 'G69'\n",
      " 'G70' 'G71' 'G72' 'G73' 'G74' 'G75' 'G76' 'G77' 'G78' 'G79' 'G80' 'G81'\n",
      " 'G82' 'G83' 'G84' 'G85' 'G86' 'G87' 'G88' 'G89' 'G90' 'G91' 'G92' 'G93'\n",
      " 'G94' 'G95' 'G96' 'G97' 'G98' 'G99' 'G100' 'G101' 'G102' 'G103' 'G104'\n",
      " 'G105' 'G106' 'G107' 'G108' 'G109' 'G110' 'G111' 'G112' 'G113' 'G114'\n",
      " 'G115' 'G116' 'G117' 'G118' 'G119' 'G120' 'G121' 'G122' 'G123' 'G124'\n",
      " 'G125' 'G126' 'G127' 'G128' 'G129' 'G130' 'G131' 'G132' 'G133' 'G134'\n",
      " 'G135' 'G136' 'G137' 'G138' 'G139' 'G140' 'G141' 'G142' 'G143' 'G144'\n",
      " 'G145' 'G146' 'G147' 'G148' 'G149' 'G150' 'G151' 'G152' 'G153' 'G154'\n",
      " 'G155' 'G156' 'G157' 'G158' 'G159' 'G160' 'G161' 'G162' 'G163' 'G164'\n",
      " 'G165' 'G166' 'G167' 'G168' 'G169' 'G170' 'G171' 'G172' 'G173' 'G174'\n",
      " 'G175' 'G176' 'G177' 'G178' 'G179' 'G180' 'G181' 'G182' 'G183' 'G184'\n",
      " 'G185' 'G186' 'G187' 'G188' 'G189' 'G190' 'G191' 'G192' 'G193' 'G194'\n",
      " 'G195' 'G196' 'G197' 'G198' 'G199' 'G200' 'G201' 'G202' 'G203' 'G204'\n",
      " 'G205' 'G206' 'G207' 'G208' 'G209' 'G210' 'G211' 'G212' 'G213' 'G214'\n",
      " 'G215' 'G216' 'G217' 'G218' 'G219' 'G220' 'G221' 'G222' 'G223' 'G224'\n",
      " 'G225' 'G226' 'G227' 'G228' 'G229' 'G230' 'G231' 'G232' 'G233' 'G234'\n",
      " 'G235' 'G236' 'G237' 'G238' 'G239' 'G240' 'G241' 'G242' 'G243' 'G244'\n",
      " 'G245' 'G246' 'G247' 'G248' 'G249' 'G250' 'G251' 'G252' 'G253' 'G254'\n",
      " 'G255' 'G256' 'G257' 'G258' 'G259' 'G260' 'G261' 'G262' 'G263' 'G264'\n",
      " 'G265' 'G266' 'G267' 'G268' 'G269' 'G270' 'G271' 'G272' 'G273' 'G274'\n",
      " 'G275' 'G276' 'G277' 'G278' 'G279' 'G280' 'G281' 'G282' 'G283' 'G284'\n",
      " 'G285' 'G286' 'G287' 'G288' 'G289' 'G290' 'G291' 'G292' 'G293' 'G294'\n",
      " 'G295' 'G296' 'G297' 'G298' 'G299' 'G300']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Analyze by describing data\n",
    "'''\n",
    "\n",
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baking-nevada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        time  event  Treatment  Var1  Var2  Var3  Var4  Var5  Var6  Var7  ...  \\\n",
      "0  57.448331      1          0     5     1     1     4     6     5     2  ...   \n",
      "1  27.004439      1          0     3     1     3     9     1     1     2  ...   \n",
      "2  43.770511      1          1     2     5     3     4     3     3     3  ...   \n",
      "3  32.281018      1          1     2     7     2     3     5     0     1  ...   \n",
      "4  44.559284      0          0     1     3     0     0     2     2     6  ...   \n",
      "\n",
      "   G291  G292  G293  G294  G295  G296  G297  G298  G299  G300  \n",
      "0     0     0     0     0     0     0     0     0     0     0  \n",
      "1     0     0     0     0     0     0     0     0     0     0  \n",
      "2     0     0     0     0     0     0     0     0     0     0  \n",
      "3     0     1     0     1     0     0     0     0     0     0  \n",
      "4     0     0     0     0     0     0     0     0     0     1  \n",
      "\n",
      "[5 rows x 313 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "specified-bonus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          time  event  Treatment  Var1  Var2  Var3  Var4  Var5  Var6  Var7  \\\n",
      "995  19.289036      0          0     3     5     3     7     0     2     1   \n",
      "996  66.591235      1          1     4     2     1     2     2     2     2   \n",
      "997  62.986021      0          1     4     3     4     9     3     6     6   \n",
      "998  32.736220      1          0     4     1     4     5     6     3     1   \n",
      "999  36.714493      1          0     3     2     1     2     4     3     1   \n",
      "\n",
      "     ...  G291  G292  G293  G294  G295  G296  G297  G298  G299  G300  \n",
      "995  ...     0     0     0     0     0     0     1     0     0     0  \n",
      "996  ...     0     0     1     0     1     0     0     0     1     0  \n",
      "997  ...     0     0     0     0     1     0     0     0     0     0  \n",
      "998  ...     0     0     0     0     0     0     0     1     1     0  \n",
      "999  ...     0     0     0     0     0     0     0     0     0     0  \n",
      "\n",
      "[5 rows x 313 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "regular-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "vocal-theme",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Train & Test Split\n",
    "'''\n",
    "random_index = np.arange(1000)\n",
    "np.random.shuffle(random_index)\n",
    "np.random.shuffle(random_index)\n",
    "\n",
    "train_df, test_df = df.iloc[random_index[:900],:], df.iloc[random_index[900:1000],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "effective-recall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 313)\n",
      "          time  event  Treatment  Var1  Var2  Var3  Var4  Var5  Var6  Var7  \\\n",
      "676  43.504288      1          0     3     1     8     6     5     2     1   \n",
      "868  42.570403      1          0     2     4     2     2     2     6     4   \n",
      "768  26.209765      1          0     2     3     2     3     2     3     1   \n",
      "542  82.097765      1          0     4     0     2     0     5     4     1   \n",
      "635  60.599705      1          1     3     6     4     7     8     4     4   \n",
      "\n",
      "     ...  G291  G292  G293  G294  G295  G296  G297  G298  G299  G300  \n",
      "676  ...     0     0     0     0     0     0     0     0     0     0  \n",
      "868  ...     0     0     1     1     0     0     0     0     0     0  \n",
      "768  ...     0     0     0     0     0     0     0     1     0     0  \n",
      "542  ...     0     0     0     0     0     0     0     0     0     0  \n",
      "635  ...     0     0     0     0     0     0     0     0     0     0  \n",
      "\n",
      "[5 rows x 313 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "lonely-inquiry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             time       event   Treatment        Var1        Var2        Var3  \\\n",
      "count  900.000000  900.000000  900.000000  900.000000  900.000000  900.000000   \n",
      "mean    52.062471    0.895556    0.492222    2.952222    3.286667    3.013333   \n",
      "std     22.382288    0.306006    0.500217    1.855439    1.962961    1.906560   \n",
      "min     -7.945621    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%     37.623754    1.000000    0.000000    2.000000    2.000000    2.000000   \n",
      "50%     47.328116    1.000000    0.000000    3.000000    3.000000    3.000000   \n",
      "75%     61.291046    1.000000    1.000000    4.000000    4.000000    4.000000   \n",
      "max    217.078908    1.000000    1.000000   10.000000   11.000000   11.000000   \n",
      "\n",
      "             Var4        Var5        Var6        Var7  ...        G291  \\\n",
      "count  900.000000  900.000000  900.000000  900.000000  ...  900.000000   \n",
      "mean     3.258889    3.493333    3.242222    2.370000  ...    0.114444   \n",
      "std      1.974441    1.902215    2.082074    1.843665  ...    0.318527   \n",
      "min      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
      "25%      2.000000    2.000000    2.000000    1.000000  ...    0.000000   \n",
      "50%      3.000000    3.000000    3.000000    2.000000  ...    0.000000   \n",
      "75%      4.000000    5.000000    4.000000    4.000000  ...    0.000000   \n",
      "max     12.000000   11.000000   12.000000   10.000000  ...    1.000000   \n",
      "\n",
      "             G292        G293        G294        G295        G296        G297  \\\n",
      "count  900.000000  900.000000  900.000000  900.000000  900.000000  900.000000   \n",
      "mean     0.086667    0.101111    0.104444    0.125556    0.106667    0.105556   \n",
      "std      0.281502    0.301643    0.306006    0.331532    0.308861    0.307439   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
      "\n",
      "             G298        G299        G300  \n",
      "count  900.000000  900.000000  900.000000  \n",
      "mean     0.092222    0.100000    0.096667  \n",
      "std      0.289500    0.300167    0.295668  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      0.000000    0.000000    0.000000  \n",
      "50%      0.000000    0.000000    0.000000  \n",
      "75%      0.000000    0.000000    0.000000  \n",
      "max      1.000000    1.000000    1.000000  \n",
      "\n",
      "[8 rows x 313 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "naked-ethernet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             time      event  Treatment        Var1        Var2       Var3  \\\n",
      "count  100.000000  100.00000     100.00  100.000000  100.000000  100.00000   \n",
      "mean    50.040100    0.85000       0.45    3.030000    3.420000    2.89000   \n",
      "std     20.059302    0.35887       0.50    2.037304    1.875843    1.98934   \n",
      "min      9.843261    0.00000       0.00    0.000000    0.000000    0.00000   \n",
      "25%     36.258342    1.00000       0.00    2.000000    2.000000    2.00000   \n",
      "50%     45.758321    1.00000       0.00    3.000000    3.000000    3.00000   \n",
      "75%     57.097412    1.00000       1.00    4.000000    5.000000    3.25000   \n",
      "max    113.465703    1.00000       1.00   10.000000    9.000000   11.00000   \n",
      "\n",
      "             Var4        Var5        Var6        Var7  ...        G291  \\\n",
      "count  100.000000  100.000000  100.000000  100.000000  ...  100.000000   \n",
      "mean     2.790000    3.450000    3.180000    2.270000  ...    0.090000   \n",
      "std      1.805127    2.021975    1.585158    1.588182  ...    0.287623   \n",
      "min      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
      "25%      2.000000    2.000000    2.000000    1.000000  ...    0.000000   \n",
      "50%      2.000000    3.000000    3.000000    2.000000  ...    0.000000   \n",
      "75%      4.000000    5.000000    4.000000    3.000000  ...    0.000000   \n",
      "max      9.000000    9.000000    7.000000    6.000000  ...    1.000000   \n",
      "\n",
      "             G292        G293        G294        G295        G296       G297  \\\n",
      "count  100.000000  100.000000  100.000000  100.000000  100.000000  100.00000   \n",
      "mean     0.110000    0.110000    0.110000    0.110000    0.110000    0.15000   \n",
      "std      0.314466    0.314466    0.314466    0.314466    0.314466    0.35887   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.00000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.00000   \n",
      "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.00000   \n",
      "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.00000   \n",
      "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.00000   \n",
      "\n",
      "             G298        G299        G300  \n",
      "count  100.000000  100.000000  100.000000  \n",
      "mean     0.070000    0.090000    0.100000  \n",
      "std      0.256432    0.287623    0.301511  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      0.000000    0.000000    0.000000  \n",
      "50%      0.000000    0.000000    0.000000  \n",
      "75%      0.000000    0.000000    0.000000  \n",
      "max      1.000000    1.000000    1.000000  \n",
      "\n",
      "[8 rows x 313 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "proud-bronze",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 311) (900,) (100, 311) (100,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Data & Ground Truth Split\n",
    "'''\n",
    "\n",
    "'''\n",
    "Time data drop\n",
    "'''\n",
    "\n",
    "X_train = train_df.drop(['time', 'event'], axis=1)\n",
    "Y_train = train_df['event']\n",
    "\n",
    "X_test = test_df.drop(['time', 'event'], axis=1)\n",
    "Y_test = test_df['event']\n",
    "\n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "temporal-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Save train & test results\n",
    "\n",
    "When doing train, Shuffle and split the data\n",
    "\n",
    "'''\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "test_method_list = ['LogisticRegression', 'Support Vector Machines', 'KNN or k-Nearest Neighbors',\n",
    "                    'Gaussian Naive Bayes', 'Perceptron', 'Linear SVC', \n",
    "                    'Stochastic Gradient Descent', 'Decision Tree', 'Random Forest', 'Ensemble']\n",
    "\n",
    "ensemble_models = [\n",
    "    ('lrcv', LogisticRegressionCV(max_iter = 5000)),\n",
    "    ('ada', AdaBoostClassifier()),\n",
    "    ('bc', BaggingClassifier()),\n",
    "    ('etc',ExtraTreesClassifier()),\n",
    "    ('gbc', GradientBoostingClassifier()),\n",
    "    ('rfc', RandomForestClassifier(n_estimators=20)),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors = 4)),\n",
    "    ('svc', SVC(probability=True)),\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss')),\n",
    "    ('lgbm', LGBMClassifier()),\n",
    "    ('dtc', DecisionTreeClassifier()),\n",
    "    ('gnb',GaussianNB()),\n",
    "]\n",
    "\n",
    "index = ['Basic','Time_outlier','Time_/365','Clinic_outlier','Clinic_0-4(2steps)','Clinic_0-1(resizing)']\n",
    "\n",
    "result_train_df = pd.DataFrame(columns=test_method_list)\n",
    "result_test_df = pd.DataFrame(columns=test_method_list)\n",
    "result_acc_test_df = pd.DataFrame(columns=test_method_list)\n",
    "result_pre_test_df = pd.DataFrame(columns=test_method_list)\n",
    "result_rec_test_df = pd.DataFrame(columns=test_method_list)\n",
    "result_f1score_test_df = pd.DataFrame(columns=test_method_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "first-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model, predict and solve\n",
    "\n",
    "\n",
    "- Methods\n",
    "Logistic Regression\n",
    "KNN or k-Nearest Neighbors\n",
    "Support Vector Machines\n",
    "Naive Bayes classifier\n",
    "Decision Tree\n",
    "Random Forrest\n",
    "Perceptron\n",
    "Artificial neural network\n",
    "RVM or Relevance Vector Machine\n",
    "Ensemble model\n",
    "'''\n",
    "\n",
    "\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    #     print('confusion matrix')\n",
    "    #     print(confusion)\n",
    "    print('accuracy:{}, precision:{}, recall:{}'.format(accuracy, precision, recall))\n",
    "    \n",
    "    return accuracy, precision, recall\n",
    "\n",
    "\n",
    "def training():\n",
    "    result_train = []\n",
    "    result_test = []\n",
    "    result_acc = []\n",
    "    result_pre = []\n",
    "    result_rec = []\n",
    "    result_f1 = []\n",
    "    for input_method in test_method_list:\n",
    "        print('*** Method: ', input_method)\n",
    "\n",
    "        if input_method == 'LogisticRegression':\n",
    "            model = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "        elif input_method == 'Support Vector Machines':\n",
    "            model = SVC()\n",
    "\n",
    "        elif input_method == 'KNN or k-Nearest Neighbors':\n",
    "            model = KNeighborsClassifier(n_neighbors = 4)\n",
    "\n",
    "        elif input_method == 'Gaussian Naive Bayes':\n",
    "            model = GaussianNB()\n",
    "\n",
    "        elif input_method == 'Perceptron':\n",
    "            model = Perceptron()\n",
    "\n",
    "        elif input_method == 'Linear SVC':\n",
    "            model = LinearSVC(max_iter=500000)\n",
    "\n",
    "        elif input_method == 'Stochastic Gradient Descent':\n",
    "            model = SGDClassifier()\n",
    "\n",
    "        elif input_method == 'Decision Tree':\n",
    "            model = DecisionTreeClassifier()\n",
    "\n",
    "        elif input_method == 'Random Forest':\n",
    "            model = RandomForestClassifier(n_estimators=20)\n",
    "            \n",
    "        elif input_method == 'Ensemble':\n",
    "            model  = VotingClassifier(ensemble_models, voting='soft') #, weights=[0]*len(ensemble_models)\n",
    "    \n",
    "        # Train\n",
    "        model.fit(X_train, Y_train)\n",
    "        acc_log = round(model.score(X_train, Y_train) * 100, 2)\n",
    "        print('trained-acc: ', acc_log)\n",
    "        result_train.append(acc_log)\n",
    "\n",
    "\n",
    "        # Test\n",
    "        acc_log = round(model.score(X_test, Y_test) * 100, 2)\n",
    "        print('test-acc: ', acc_log)\n",
    "        result_test.append(acc_log)\n",
    "        \n",
    "        # f1 score\n",
    "        Y_pred = model.predict(X_test)\n",
    "        acc, pre, rec = get_clf_eval(Y_test, Y_pred)\n",
    "        result_acc.append(acc)\n",
    "        result_pre.append(pre)\n",
    "        result_rec.append(rec)\n",
    "        f1 = f1_score(Y_test, Y_pred)\n",
    "        print('f1 score:{}'.format(f1))\n",
    "        result_f1.append(f1)\n",
    "        \n",
    "        print()\n",
    "        print()\n",
    "\n",
    "    result_train_df.loc[result_train_df.shape[0]] = result_train\n",
    "    result_test_df.loc[result_test_df.shape[0]] = result_test\n",
    "    result_acc_test_df.loc[result_acc_test_df.shape[0]] = result_acc\n",
    "    result_pre_test_df.loc[result_pre_test_df.shape[0]] = result_pre\n",
    "    result_rec_test_df.loc[result_rec_test_df.shape[0]] = result_rec\n",
    "    result_f1score_test_df.loc[result_f1score_test_df.shape[0]] = result_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "centered-month",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Method:  LogisticRegression\n",
      "trained-acc:  94.78\n",
      "test-acc:  77.0\n",
      "accuracy:0.77, precision:0.8444444444444444, recall:0.8941176470588236\n",
      "f1 score:0.8685714285714287\n",
      "\n",
      "\n",
      "*** Method:  Support Vector Machines\n",
      "trained-acc:  89.56\n",
      "test-acc:  85.0\n",
      "accuracy:0.85, precision:0.85, recall:1.0\n",
      "f1 score:0.9189189189189189\n",
      "\n",
      "\n",
      "*** Method:  KNN or k-Nearest Neighbors\n",
      "trained-acc:  90.44\n",
      "test-acc:  84.0\n",
      "accuracy:0.84, precision:0.8484848484848485, recall:0.9882352941176471\n",
      "f1 score:0.9130434782608696\n",
      "\n",
      "\n",
      "*** Method:  Gaussian Naive Bayes\n",
      "trained-acc:  85.89\n",
      "test-acc:  72.0\n",
      "accuracy:0.72, precision:0.8607594936708861, recall:0.8\n",
      "f1 score:0.829268292682927\n",
      "\n",
      "\n",
      "*** Method:  Perceptron\n",
      "trained-acc:  70.11\n",
      "test-acc:  62.0\n",
      "accuracy:0.62, precision:0.8852459016393442, recall:0.6352941176470588\n",
      "f1 score:0.7397260273972602\n",
      "\n",
      "\n",
      "*** Method:  Linear SVC\n",
      "trained-acc:  99.89\n",
      "test-acc:  73.0\n",
      "accuracy:0.73, precision:0.8625, recall:0.8117647058823529\n",
      "f1 score:0.8363636363636364\n",
      "\n",
      "\n",
      "*** Method:  Stochastic Gradient Descent\n",
      "trained-acc:  82.89\n",
      "test-acc:  70.0\n",
      "accuracy:0.7, precision:0.8767123287671232, recall:0.7529411764705882\n",
      "f1 score:0.8101265822784809\n",
      "\n",
      "\n",
      "*** Method:  Decision Tree\n",
      "trained-acc:  100.0\n",
      "test-acc:  68.0\n",
      "accuracy:0.68, precision:0.8354430379746836, recall:0.7764705882352941\n",
      "f1 score:0.8048780487804879\n",
      "\n",
      "\n",
      "*** Method:  Random Forest\n",
      "trained-acc:  99.78\n",
      "test-acc:  85.0\n",
      "accuracy:0.85, precision:0.85, recall:1.0\n",
      "f1 score:0.9189189189189189\n",
      "\n",
      "\n",
      "*** Method:  Ensemble\n",
      "trained-acc:  100.0\n",
      "test-acc:  85.0\n",
      "accuracy:0.85, precision:0.85, recall:1.0\n",
      "f1 score:0.9189189189189189\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Basic Training & Test\n",
    "\n",
    "'''\n",
    "\n",
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "strange-norfolk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlier of time: \n",
      "905   -7.945621\n",
      "Name: time, dtype: float64\n",
      "\n",
      "              time        event\n",
      "count  1000.000000  1000.000000\n",
      "mean     51.876125     0.891000\n",
      "std      22.122689     0.311795\n",
      "min       7.070708     0.000000\n",
      "25%      37.401307     1.000000\n",
      "50%      47.064712     1.000000\n",
      "75%      60.966476     1.000000\n",
      "max     217.078908     1.000000\n",
      "\n",
      "*** Method:  LogisticRegression\n",
      "trained-acc:  95.44\n",
      "test-acc:  79.0\n",
      "accuracy:0.79, precision:0.872093023255814, recall:0.8823529411764706\n",
      "f1 score:0.8771929824561403\n",
      "\n",
      "\n",
      "*** Method:  Support Vector Machines\n",
      "trained-acc:  89.56\n",
      "test-acc:  85.0\n",
      "accuracy:0.85, precision:0.85, recall:1.0\n",
      "f1 score:0.9189189189189189\n",
      "\n",
      "\n",
      "*** Method:  KNN or k-Nearest Neighbors\n",
      "trained-acc:  91.11\n",
      "test-acc:  87.0\n",
      "accuracy:0.87, precision:0.8673469387755102, recall:1.0\n",
      "f1 score:0.9289617486338798\n",
      "\n",
      "\n",
      "*** Method:  Gaussian Naive Bayes\n",
      "trained-acc:  86.11\n",
      "test-acc:  72.0\n",
      "accuracy:0.72, precision:0.8607594936708861, recall:0.8\n",
      "f1 score:0.829268292682927\n",
      "\n",
      "\n",
      "*** Method:  Perceptron\n",
      "trained-acc:  67.33\n",
      "test-acc:  60.0\n",
      "accuracy:0.6, precision:0.8947368421052632, recall:0.6\n",
      "f1 score:0.7183098591549296\n",
      "\n",
      "\n",
      "*** Method:  Linear SVC\n",
      "trained-acc:  99.89\n",
      "test-acc:  77.0\n",
      "accuracy:0.77, precision:0.8780487804878049, recall:0.8470588235294118\n",
      "f1 score:0.8622754491017964\n",
      "\n",
      "\n",
      "*** Method:  Stochastic Gradient Descent\n",
      "trained-acc:  50.44\n",
      "test-acc:  43.0\n",
      "accuracy:0.43, precision:0.8888888888888888, recall:0.3764705882352941\n",
      "f1 score:0.5289256198347108\n",
      "\n",
      "\n",
      "*** Method:  Decision Tree\n",
      "trained-acc:  100.0\n",
      "test-acc:  75.0\n",
      "accuracy:0.75, precision:0.8488372093023255, recall:0.8588235294117647\n",
      "f1 score:0.8538011695906433\n",
      "\n",
      "\n",
      "*** Method:  Random Forest\n",
      "trained-acc:  99.78\n",
      "test-acc:  85.0\n",
      "accuracy:0.85, precision:0.85, recall:1.0\n",
      "f1 score:0.9189189189189189\n",
      "\n",
      "\n",
      "*** Method:  Ensemble\n",
      "trained-acc:  100.0\n",
      "test-acc:  87.0\n",
      "accuracy:0.87, precision:0.8673469387755102, recall:1.0\n",
      "f1 score:0.9289617486338798\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Add Time data\n",
    "\n",
    "1) outlier value drop\n",
    "2) clustering from step 0-N days to step 0-N/365 days\n",
    "'''\n",
    "\n",
    "'''\n",
    "1)\n",
    "'''\n",
    "print('outlier of time: ')\n",
    "print(df1.loc[df1['time'] < 0, 'time'], end='\\n\\n')\n",
    "\n",
    "df1_outlier = df1.copy()\n",
    "df1_outlier.loc[df1_outlier['time'] < 0, 'time'] = abs(df1_outlier.loc[df1_outlier['time'] < 0, 'time'])\n",
    "print(df1_outlier.describe(), end='\\n\\n')\n",
    "\n",
    "df = pd.concat([df1_outlier,df2,df3,df4], axis=1)\n",
    "train_df, test_df = df.iloc[random_index[:900],:], df.iloc[random_index[900:1000],:]\n",
    "\n",
    "X_train = train_df.drop(['event'], axis=1)\n",
    "Y_train = train_df['event']\n",
    "\n",
    "X_test = test_df.drop(['event'], axis=1)\n",
    "Y_test = test_df['event']\n",
    "\n",
    "\n",
    "'''\n",
    "Add Time data(1) Training & Test\n",
    "\n",
    "'''\n",
    "\n",
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "technical-might",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              time        event\n",
      "count  1000.000000  1000.000000\n",
      "mean      0.142126     0.891000\n",
      "std       0.060610     0.311795\n",
      "min       0.019372     0.000000\n",
      "25%       0.102469     1.000000\n",
      "50%       0.128944     1.000000\n",
      "75%       0.167031     1.000000\n",
      "max       0.594737     1.000000\n",
      "\n",
      "*** Method:  LogisticRegression\n",
      "trained-acc:  94.78\n",
      "test-acc:  77.0\n",
      "accuracy:0.77, precision:0.8444444444444444, recall:0.8941176470588236\n",
      "f1 score:0.8685714285714287\n",
      "\n",
      "\n",
      "*** Method:  Support Vector Machines\n",
      "trained-acc:  89.56\n",
      "test-acc:  85.0\n",
      "accuracy:0.85, precision:0.85, recall:1.0\n",
      "f1 score:0.9189189189189189\n",
      "\n",
      "\n",
      "*** Method:  KNN or k-Nearest Neighbors\n",
      "trained-acc:  90.22\n",
      "test-acc:  83.0\n",
      "accuracy:0.83, precision:0.8469387755102041, recall:0.9764705882352941\n",
      "f1 score:0.907103825136612\n",
      "\n",
      "\n",
      "*** Method:  Gaussian Naive Bayes\n",
      "trained-acc:  86.11\n",
      "test-acc:  72.0\n",
      "accuracy:0.72, precision:0.8607594936708861, recall:0.8\n",
      "f1 score:0.829268292682927\n",
      "\n",
      "\n",
      "*** Method:  Perceptron\n",
      "trained-acc:  92.78\n",
      "test-acc:  81.0\n",
      "accuracy:0.81, precision:0.8586956521739131, recall:0.9294117647058824\n",
      "f1 score:0.8926553672316385\n",
      "\n",
      "\n",
      "*** Method:  Linear SVC\n",
      "trained-acc:  99.89\n",
      "test-acc:  73.0\n",
      "accuracy:0.73, precision:0.8625, recall:0.8117647058823529\n",
      "f1 score:0.8363636363636364\n",
      "\n",
      "\n",
      "*** Method:  Stochastic Gradient Descent\n",
      "trained-acc:  95.78\n",
      "test-acc:  76.0\n",
      "accuracy:0.76, precision:0.8674698795180723, recall:0.8470588235294118\n",
      "f1 score:0.8571428571428572\n",
      "\n",
      "\n",
      "*** Method:  Decision Tree\n",
      "trained-acc:  100.0\n",
      "test-acc:  77.0\n",
      "accuracy:0.77, precision:0.8604651162790697, recall:0.8705882352941177\n",
      "f1 score:0.8654970760233918\n",
      "\n",
      "\n",
      "*** Method:  Random Forest\n",
      "trained-acc:  99.33\n",
      "test-acc:  85.0\n",
      "accuracy:0.85, precision:0.85, recall:1.0\n",
      "f1 score:0.9189189189189189\n",
      "\n",
      "\n",
      "*** Method:  Ensemble\n",
      "trained-acc:  100.0\n",
      "test-acc:  87.0\n",
      "accuracy:0.87, precision:0.8673469387755102, recall:1.0\n",
      "f1 score:0.9289617486338798\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2)\n",
    "'''\n",
    "df1_normalize = df1_outlier.copy()\n",
    "df1_normalize['time'] = df1_normalize['time']/365.0\n",
    "print(df1_normalize.describe(), end='\\n\\n')\n",
    "\n",
    "df = pd.concat([df1_normalize,df2,df3,df4], axis=1)\n",
    "train_df, test_df = df.iloc[random_index[:900],:], df.iloc[random_index[900:1000],:]\n",
    "\n",
    "X_train = train_df.drop(['event'], axis=1)\n",
    "Y_train = train_df['event']\n",
    "\n",
    "X_test = test_df.drop(['event'], axis=1)\n",
    "Y_test = test_df['event']\n",
    "\n",
    "\n",
    "'''\n",
    "Add Time data(1) Training & Test\n",
    "\n",
    "'''\n",
    "\n",
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "usual-church",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Var1\n",
      "2    235\n",
      "3    204\n",
      "1    171\n",
      "4    139\n",
      "5     95\n",
      "0     57\n",
      "6     50\n",
      "7     27\n",
      "8     13\n",
      "9      9\n",
      "Name: Var1, dtype: int64\n",
      "--------------------\n",
      "# Var2\n",
      "3    221\n",
      "2    218\n",
      "4    163\n",
      "1    113\n",
      "5    109\n",
      "6     65\n",
      "0     48\n",
      "7     30\n",
      "9     20\n",
      "8     13\n",
      "Name: Var2, dtype: int64\n",
      "--------------------\n",
      "# Var3\n",
      "2    260\n",
      "3    196\n",
      "1    156\n",
      "4    130\n",
      "5     97\n",
      "0     55\n",
      "6     55\n",
      "7     23\n",
      "8     16\n",
      "9     12\n",
      "Name: Var3, dtype: int64\n",
      "--------------------\n",
      "# Var4\n",
      "2    242\n",
      "3    195\n",
      "1    150\n",
      "4    140\n",
      "5    106\n",
      "6     67\n",
      "0     36\n",
      "7     32\n",
      "8     16\n",
      "9     16\n",
      "Name: Var4, dtype: int64\n",
      "--------------------\n",
      "# Var5\n",
      "2    247\n",
      "3    223\n",
      "4    161\n",
      "5    124\n",
      "1     76\n",
      "6     63\n",
      "7     41\n",
      "0     28\n",
      "9     19\n",
      "8     18\n",
      "Name: Var5, dtype: int64\n",
      "--------------------\n",
      "# Var6\n",
      "2    240\n",
      "3    212\n",
      "4    128\n",
      "1    127\n",
      "5     99\n",
      "6     64\n",
      "0     53\n",
      "7     40\n",
      "8     20\n",
      "9     17\n",
      "Name: Var6, dtype: int64\n",
      "--------------------\n",
      "# Var7\n",
      "1    269\n",
      "2    208\n",
      "3    144\n",
      "0    128\n",
      "4    118\n",
      "5     62\n",
      "6     47\n",
      "7     16\n",
      "8      6\n",
      "9      2\n",
      "Name: Var7, dtype: int64\n",
      "--------------------\n",
      "# Var8\n",
      "1    241\n",
      "2    227\n",
      "3    171\n",
      "0    127\n",
      "4    101\n",
      "5     69\n",
      "6     30\n",
      "7     20\n",
      "8     10\n",
      "9      4\n",
      "Name: Var8, dtype: int64\n",
      "--------------------\n",
      "# Var9\n",
      "2    250\n",
      "1    235\n",
      "3    157\n",
      "0    135\n",
      "4    100\n",
      "5     57\n",
      "6     33\n",
      "7     22\n",
      "9      6\n",
      "8      5\n",
      "Name: Var9, dtype: int64\n",
      "--------------------\n",
      "# Var10\n",
      "1    287\n",
      "2    205\n",
      "3    156\n",
      "0    114\n",
      "4    108\n",
      "5     62\n",
      "6     40\n",
      "7     18\n",
      "8      5\n",
      "9      5\n",
      "Name: Var10, dtype: int64\n",
      "--------------------\n",
      "\n",
      "*** Method:  LogisticRegression\n",
      "trained-acc:  95.44\n",
      "test-acc:  79.0\n",
      "accuracy:0.79, precision:0.872093023255814, recall:0.8823529411764706\n",
      "f1 score:0.8771929824561403\n",
      "\n",
      "\n",
      "*** Method:  Support Vector Machines\n",
      "trained-acc:  89.56\n",
      "test-acc:  85.0\n",
      "accuracy:0.85, precision:0.85, recall:1.0\n",
      "f1 score:0.9189189189189189\n",
      "\n",
      "\n",
      "*** Method:  KNN or k-Nearest Neighbors\n",
      "trained-acc:  91.11\n",
      "test-acc:  87.0\n",
      "accuracy:0.87, precision:0.8673469387755102, recall:1.0\n",
      "f1 score:0.9289617486338798\n",
      "\n",
      "\n",
      "*** Method:  Gaussian Naive Bayes\n",
      "trained-acc:  85.89\n",
      "test-acc:  72.0\n",
      "accuracy:0.72, precision:0.8607594936708861, recall:0.8\n",
      "f1 score:0.829268292682927\n",
      "\n",
      "\n",
      "*** Method:  Perceptron\n",
      "trained-acc:  10.44\n",
      "test-acc:  15.0\n",
      "accuracy:0.15, precision:0.0, recall:0.0\n",
      "f1 score:0.0\n",
      "\n",
      "\n",
      "*** Method:  Linear SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained-acc:  99.89\n",
      "test-acc:  77.0\n",
      "accuracy:0.77, precision:0.8780487804878049, recall:0.8470588235294118\n",
      "f1 score:0.8622754491017964\n",
      "\n",
      "\n",
      "*** Method:  Stochastic Gradient Descent\n",
      "trained-acc:  90.33\n",
      "test-acc:  87.0\n",
      "accuracy:0.87, precision:0.8673469387755102, recall:1.0\n",
      "f1 score:0.9289617486338798\n",
      "\n",
      "\n",
      "*** Method:  Decision Tree\n",
      "trained-acc:  100.0\n",
      "test-acc:  76.0\n",
      "accuracy:0.76, precision:0.8674698795180723, recall:0.8470588235294118\n",
      "f1 score:0.8571428571428572\n",
      "\n",
      "\n",
      "*** Method:  Random Forest\n",
      "trained-acc:  99.67\n",
      "test-acc:  86.0\n",
      "accuracy:0.86, precision:0.8585858585858586, recall:1.0\n",
      "f1 score:0.9239130434782609\n",
      "\n",
      "\n",
      "*** Method:  Ensemble\n",
      "trained-acc:  100.0\n",
      "test-acc:  87.0\n",
      "accuracy:0.87, precision:0.8673469387755102, recall:1.0\n",
      "f1 score:0.9289617486338798\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Correlating numerical features of Clinic data\n",
    "\n",
    "- outlier value drop\n",
    "- clustering from step 0-9 to step 0-4(clustering 2 steps)/0-1(just resizing)\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "1)\n",
    "'''\n",
    "df3_outlier = df3.copy()\n",
    "\n",
    "\n",
    "# drop outlier\n",
    "for col in df3_outlier.columns:\n",
    "    for outlier in range(10,13):\n",
    "        df3_outlier = df3_outlier.replace(outlier, 9)\n",
    "\n",
    "# visualize\n",
    "for col in df3_outlier.columns:\n",
    "    print('#', col)\n",
    "    print(df3_outlier[col].value_counts())\n",
    "    print('-'*20)\n",
    "\n",
    "\n",
    "df = pd.concat([df1_outlier,df2,df3_outlier,df4], axis=1)\n",
    "train_df, test_df = df.iloc[random_index[:900],:], df.iloc[random_index[900:1000],:]\n",
    "\n",
    "X_train = train_df.drop(['event'], axis=1)\n",
    "Y_train = train_df['event']\n",
    "\n",
    "X_test = test_df.drop(['event'], axis=1)\n",
    "Y_test = test_df['event']\n",
    "\n",
    "\n",
    "'''\n",
    "Add Time data(1) +  Correlating Clinic data(1) \n",
    "Training & Test\n",
    "'''\n",
    "\n",
    "print()\n",
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "conscious-large",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Var1         Var2         Var3         Var4         Var5  \\\n",
      "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
      "mean      1.226000     1.400000     1.256000     1.354000     1.500000   \n",
      "std       0.958041     0.975167     0.968195     0.995829     0.942809   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "50%       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "75%       2.000000     2.000000     2.000000     2.000000     2.000000   \n",
      "max       4.000000     4.000000     4.000000     4.000000     4.000000   \n",
      "\n",
      "              Var6         Var7         Var8         Var9        Var10  \n",
      "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  \n",
      "mean      1.366000     0.933000     0.944000     0.930000     0.915000  \n",
      "std       1.011468     0.947316     0.928292     0.917574     0.941627  \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "25%       1.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "50%       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
      "75%       2.000000     2.000000     1.000000     1.000000     1.000000  \n",
      "max       4.000000     4.000000     4.000000     4.000000     4.000000  \n",
      "\n",
      "*** Method:  LogisticRegression\n",
      "trained-acc:  95.33\n",
      "test-acc:  78.0\n",
      "accuracy:0.78, precision:0.8705882352941177, recall:0.8705882352941177\n",
      "f1 score:0.8705882352941176\n",
      "\n",
      "\n",
      "*** Method:  Support Vector Machines\n",
      "trained-acc:  89.56\n",
      "test-acc:  85.0\n",
      "accuracy:0.85, precision:0.85, recall:1.0\n",
      "f1 score:0.9189189189189189\n",
      "\n",
      "\n",
      "*** Method:  KNN or k-Nearest Neighbors\n",
      "trained-acc:  91.89\n",
      "test-acc:  87.0\n",
      "accuracy:0.87, precision:0.8829787234042553, recall:0.9764705882352941\n",
      "f1 score:0.9273743016759776\n",
      "\n",
      "\n",
      "*** Method:  Gaussian Naive Bayes\n",
      "trained-acc:  85.78\n",
      "test-acc:  72.0\n",
      "accuracy:0.72, precision:0.8607594936708861, recall:0.8\n",
      "f1 score:0.829268292682927\n",
      "\n",
      "\n",
      "*** Method:  Perceptron\n",
      "trained-acc:  93.11\n",
      "test-acc:  86.0\n",
      "accuracy:0.86, precision:0.8901098901098901, recall:0.9529411764705882\n",
      "f1 score:0.9204545454545454\n",
      "\n",
      "\n",
      "*** Method:  Linear SVC\n",
      "trained-acc:  100.0\n",
      "test-acc:  76.0\n",
      "accuracy:0.76, precision:0.8765432098765432, recall:0.8352941176470589\n",
      "f1 score:0.8554216867469879\n",
      "\n",
      "\n",
      "*** Method:  Stochastic Gradient Descent\n",
      "trained-acc:  92.44\n",
      "test-acc:  85.0\n",
      "accuracy:0.85, precision:0.8723404255319149, recall:0.9647058823529412\n",
      "f1 score:0.9162011173184357\n",
      "\n",
      "\n",
      "*** Method:  Decision Tree\n",
      "trained-acc:  100.0\n",
      "test-acc:  82.0\n",
      "accuracy:0.82, precision:0.8764044943820225, recall:0.9176470588235294\n",
      "f1 score:0.896551724137931\n",
      "\n",
      "\n",
      "*** Method:  Random Forest\n",
      "trained-acc:  100.0\n",
      "test-acc:  86.0\n",
      "accuracy:0.86, precision:0.8585858585858586, recall:1.0\n",
      "f1 score:0.9239130434782609\n",
      "\n",
      "\n",
      "*** Method:  Ensemble\n",
      "trained-acc:  100.0\n",
      "test-acc:  87.0\n",
      "accuracy:0.87, precision:0.8673469387755102, recall:1.0\n",
      "f1 score:0.9289617486338798\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2-1) 2 steps clustering(0-4)\n",
    "'''\n",
    "df3_2c = df3_outlier.copy()\n",
    "\n",
    "for col in df3_2c.columns:\n",
    "    df3_2c.loc[df3_2c[col] <= 1, col] = 0\n",
    "    df3_2c.loc[(df3_2c[col] > 1) & (df3_2c[col] <= 3), col] = 1\n",
    "    df3_2c.loc[(df3_2c[col] > 3) & (df3_2c[col] <= 5), col] = 2\n",
    "    df3_2c.loc[(df3_2c[col] > 5) & (df3_2c[col] <= 7), col] = 3\n",
    "    df3_2c.loc[(df3_2c[col] > 7) & (df3_2c[col] <= 9), col] = 4\n",
    "\n",
    "print(df3_2c.describe(), end='\\n\\n')\n",
    "\n",
    "df = pd.concat([df1_outlier,df2,df3_2c,df4], axis=1)\n",
    "train_df, test_df = df.iloc[random_index[:900],:], df.iloc[random_index[900:1000],:]\n",
    "\n",
    "X_train = train_df.drop(['event'], axis=1)\n",
    "Y_train = train_df['event']\n",
    "\n",
    "X_test = test_df.drop(['event'], axis=1)\n",
    "Y_test = test_df['event']\n",
    "\n",
    "\n",
    "'''\n",
    "Add Time data(1) +  Correlating Clinic data(2-1) \n",
    "Training & Test\n",
    "'''\n",
    "\n",
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "colonial-maryland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Var1         Var2         Var3         Var4         Var5  \\\n",
      "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
      "mean      0.328667     0.365889     0.332889     0.356333     0.387000   \n",
      "std       0.207386     0.214559     0.210689     0.216080     0.210446   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.222222     0.222222     0.222222     0.222222     0.222222   \n",
      "50%       0.333333     0.333333     0.333333     0.333333     0.333333   \n",
      "75%       0.444444     0.444444     0.444444     0.444444     0.555556   \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "              Var6         Var7         Var8         Var9        Var10  \n",
      "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  \n",
      "mean      0.358556     0.262111     0.265889     0.259667     0.262000  \n",
      "std       0.223040     0.201703     0.202755     0.201437     0.201204  \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "25%       0.222222     0.111111     0.111111     0.111111     0.111111  \n",
      "50%       0.333333     0.222222     0.222222     0.222222     0.222222  \n",
      "75%       0.444444     0.444444     0.333333     0.333333     0.333333  \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
      "\n",
      "*** Method:  LogisticRegression\n",
      "trained-acc:  94.78\n",
      "test-acc:  79.0\n",
      "accuracy:0.79, precision:0.8809523809523809, recall:0.8705882352941177\n",
      "f1 score:0.8757396449704142\n",
      "\n",
      "\n",
      "*** Method:  Support Vector Machines\n",
      "trained-acc:  89.56\n",
      "test-acc:  85.0\n",
      "accuracy:0.85, precision:0.85, recall:1.0\n",
      "f1 score:0.9189189189189189\n",
      "\n",
      "\n",
      "*** Method:  KNN or k-Nearest Neighbors\n",
      "trained-acc:  91.44\n",
      "test-acc:  84.0\n",
      "accuracy:0.84, precision:0.8631578947368421, recall:0.9647058823529412\n",
      "f1 score:0.9111111111111111\n",
      "\n",
      "\n",
      "*** Method:  Gaussian Naive Bayes\n",
      "trained-acc:  85.89\n",
      "test-acc:  72.0\n",
      "accuracy:0.72, precision:0.8607594936708861, recall:0.8\n",
      "f1 score:0.829268292682927\n",
      "\n",
      "\n",
      "*** Method:  Perceptron\n",
      "trained-acc:  30.22\n",
      "test-acc:  32.0\n",
      "accuracy:0.32, precision:0.9047619047619048, recall:0.2235294117647059\n",
      "f1 score:0.3584905660377359\n",
      "\n",
      "\n",
      "*** Method:  Linear SVC\n",
      "trained-acc:  100.0\n",
      "test-acc:  76.0\n",
      "accuracy:0.76, precision:0.8765432098765432, recall:0.8352941176470589\n",
      "f1 score:0.8554216867469879\n",
      "\n",
      "\n",
      "*** Method:  Stochastic Gradient Descent\n",
      "trained-acc:  90.0\n",
      "test-acc:  86.0\n",
      "accuracy:0.86, precision:0.8585858585858586, recall:1.0\n",
      "f1 score:0.9239130434782609\n",
      "\n",
      "\n",
      "*** Method:  Decision Tree\n",
      "trained-acc:  100.0\n",
      "test-acc:  77.0\n",
      "accuracy:0.77, precision:0.8522727272727273, recall:0.8823529411764706\n",
      "f1 score:0.8670520231213872\n",
      "\n",
      "\n",
      "*** Method:  Random Forest\n",
      "trained-acc:  99.67\n",
      "test-acc:  86.0\n",
      "accuracy:0.86, precision:0.8585858585858586, recall:1.0\n",
      "f1 score:0.9239130434782609\n",
      "\n",
      "\n",
      "*** Method:  Ensemble\n",
      "trained-acc:  100.0\n",
      "test-acc:  87.0\n",
      "accuracy:0.87, precision:0.8673469387755102, recall:1.0\n",
      "f1 score:0.9289617486338798\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2-2) just resizing(0-1)\n",
    "'''\n",
    "df3_rs = df3_outlier.copy()\n",
    "\n",
    "for col in df3_rs.columns:\n",
    "    df3_rs[col] = df3_rs[col]/9\n",
    "\n",
    "print(df3_rs.describe(), end='\\n\\n')\n",
    "\n",
    "df = pd.concat([df1_outlier,df2,df3_rs,df4], axis=1)\n",
    "train_df, test_df = df.iloc[random_index[:900],:], df.iloc[random_index[900:1000],:]\n",
    "\n",
    "X_train = train_df.drop(['event'], axis=1)\n",
    "Y_train = train_df['event']\n",
    "\n",
    "X_test = test_df.drop(['event'], axis=1)\n",
    "Y_test = test_df['event']\n",
    "\n",
    "\n",
    "'''\n",
    "Add Time data(1) +  Correlating Clinic data(2-2) \n",
    "Training & Test\n",
    "'''\n",
    "\n",
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0bea627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** train result ***\n",
      "\n",
      "                      LogisticRegression  Support Vector Machines  \\\n",
      "Basic                              94.78                    89.56   \n",
      "Time_outlier                       95.44                    89.56   \n",
      "Time_/365                          94.78                    89.56   \n",
      "Clinic_outlier                     95.44                    89.56   \n",
      "Clinic_0-4(2steps)                 95.33                    89.56   \n",
      "Clinic_0-1(resizing)               94.78                    89.56   \n",
      "\n",
      "                      KNN or k-Nearest Neighbors  Gaussian Naive Bayes  \\\n",
      "Basic                                      90.44                 85.89   \n",
      "Time_outlier                               91.11                 86.11   \n",
      "Time_/365                                  90.22                 86.11   \n",
      "Clinic_outlier                             91.11                 85.89   \n",
      "Clinic_0-4(2steps)                         91.89                 85.78   \n",
      "Clinic_0-1(resizing)                       91.44                 85.89   \n",
      "\n",
      "                      Perceptron  Linear SVC  Stochastic Gradient Descent  \\\n",
      "Basic                      70.11       99.89                        82.89   \n",
      "Time_outlier               67.33       99.89                        50.44   \n",
      "Time_/365                  92.78       99.89                        95.78   \n",
      "Clinic_outlier             10.44       99.89                        90.33   \n",
      "Clinic_0-4(2steps)         93.11      100.00                        92.44   \n",
      "Clinic_0-1(resizing)       30.22      100.00                        90.00   \n",
      "\n",
      "                      Decision Tree  Random Forest  Ensemble  \n",
      "Basic                         100.0          99.78     100.0  \n",
      "Time_outlier                  100.0          99.78     100.0  \n",
      "Time_/365                     100.0          99.33     100.0  \n",
      "Clinic_outlier                100.0          99.67     100.0  \n",
      "Clinic_0-4(2steps)            100.0         100.00     100.0  \n",
      "Clinic_0-1(resizing)          100.0          99.67     100.0  \n",
      "\n",
      "\n",
      "\n",
      "*** test result ***\n",
      "\n",
      "                      LogisticRegression  Support Vector Machines  \\\n",
      "Basic                               77.0                     85.0   \n",
      "Time_outlier                        79.0                     85.0   \n",
      "Time_/365                           77.0                     85.0   \n",
      "Clinic_outlier                      79.0                     85.0   \n",
      "Clinic_0-4(2steps)                  78.0                     85.0   \n",
      "Clinic_0-1(resizing)                79.0                     85.0   \n",
      "\n",
      "                      KNN or k-Nearest Neighbors  Gaussian Naive Bayes  \\\n",
      "Basic                                       84.0                  72.0   \n",
      "Time_outlier                                87.0                  72.0   \n",
      "Time_/365                                   83.0                  72.0   \n",
      "Clinic_outlier                              87.0                  72.0   \n",
      "Clinic_0-4(2steps)                          87.0                  72.0   \n",
      "Clinic_0-1(resizing)                        84.0                  72.0   \n",
      "\n",
      "                      Perceptron  Linear SVC  Stochastic Gradient Descent  \\\n",
      "Basic                       62.0        73.0                         70.0   \n",
      "Time_outlier                60.0        77.0                         43.0   \n",
      "Time_/365                   81.0        73.0                         76.0   \n",
      "Clinic_outlier              15.0        77.0                         87.0   \n",
      "Clinic_0-4(2steps)          86.0        76.0                         85.0   \n",
      "Clinic_0-1(resizing)        32.0        76.0                         86.0   \n",
      "\n",
      "                      Decision Tree  Random Forest  Ensemble  \n",
      "Basic                          68.0           85.0      85.0  \n",
      "Time_outlier                   75.0           85.0      87.0  \n",
      "Time_/365                      77.0           85.0      87.0  \n",
      "Clinic_outlier                 76.0           86.0      87.0  \n",
      "Clinic_0-4(2steps)             82.0           86.0      87.0  \n",
      "Clinic_0-1(resizing)           77.0           86.0      87.0  \n",
      "\n",
      "\n",
      "\n",
      "*** test acc ***\n",
      "\n",
      "                      LogisticRegression  Support Vector Machines  \\\n",
      "Basic                               0.77                     0.85   \n",
      "Time_outlier                        0.79                     0.85   \n",
      "Time_/365                           0.77                     0.85   \n",
      "Clinic_outlier                      0.79                     0.85   \n",
      "Clinic_0-4(2steps)                  0.78                     0.85   \n",
      "Clinic_0-1(resizing)                0.79                     0.85   \n",
      "\n",
      "                      KNN or k-Nearest Neighbors  Gaussian Naive Bayes  \\\n",
      "Basic                                       0.84                  0.72   \n",
      "Time_outlier                                0.87                  0.72   \n",
      "Time_/365                                   0.83                  0.72   \n",
      "Clinic_outlier                              0.87                  0.72   \n",
      "Clinic_0-4(2steps)                          0.87                  0.72   \n",
      "Clinic_0-1(resizing)                        0.84                  0.72   \n",
      "\n",
      "                      Perceptron  Linear SVC  Stochastic Gradient Descent  \\\n",
      "Basic                       0.62        0.73                         0.70   \n",
      "Time_outlier                0.60        0.77                         0.43   \n",
      "Time_/365                   0.81        0.73                         0.76   \n",
      "Clinic_outlier              0.15        0.77                         0.87   \n",
      "Clinic_0-4(2steps)          0.86        0.76                         0.85   \n",
      "Clinic_0-1(resizing)        0.32        0.76                         0.86   \n",
      "\n",
      "                      Decision Tree  Random Forest  Ensemble  \n",
      "Basic                          0.68           0.85      0.85  \n",
      "Time_outlier                   0.75           0.85      0.87  \n",
      "Time_/365                      0.77           0.85      0.87  \n",
      "Clinic_outlier                 0.76           0.86      0.87  \n",
      "Clinic_0-4(2steps)             0.82           0.86      0.87  \n",
      "Clinic_0-1(resizing)           0.77           0.86      0.87  \n",
      "\n",
      "\n",
      "\n",
      "*** test pre ***\n",
      "\n",
      "                      LogisticRegression  Support Vector Machines  \\\n",
      "Basic                           0.844444                     0.85   \n",
      "Time_outlier                    0.872093                     0.85   \n",
      "Time_/365                       0.844444                     0.85   \n",
      "Clinic_outlier                  0.872093                     0.85   \n",
      "Clinic_0-4(2steps)              0.870588                     0.85   \n",
      "Clinic_0-1(resizing)            0.880952                     0.85   \n",
      "\n",
      "                      KNN or k-Nearest Neighbors  Gaussian Naive Bayes  \\\n",
      "Basic                                   0.848485              0.860759   \n",
      "Time_outlier                            0.867347              0.860759   \n",
      "Time_/365                               0.846939              0.860759   \n",
      "Clinic_outlier                          0.867347              0.860759   \n",
      "Clinic_0-4(2steps)                      0.882979              0.860759   \n",
      "Clinic_0-1(resizing)                    0.863158              0.860759   \n",
      "\n",
      "                      Perceptron  Linear SVC  Stochastic Gradient Descent  \\\n",
      "Basic                   0.885246    0.862500                     0.876712   \n",
      "Time_outlier            0.894737    0.878049                     0.888889   \n",
      "Time_/365               0.858696    0.862500                     0.867470   \n",
      "Clinic_outlier          0.000000    0.878049                     0.867347   \n",
      "Clinic_0-4(2steps)      0.890110    0.876543                     0.872340   \n",
      "Clinic_0-1(resizing)    0.904762    0.876543                     0.858586   \n",
      "\n",
      "                      Decision Tree  Random Forest  Ensemble  \n",
      "Basic                      0.835443       0.850000  0.850000  \n",
      "Time_outlier               0.848837       0.850000  0.867347  \n",
      "Time_/365                  0.860465       0.850000  0.867347  \n",
      "Clinic_outlier             0.867470       0.858586  0.867347  \n",
      "Clinic_0-4(2steps)         0.876404       0.858586  0.867347  \n",
      "Clinic_0-1(resizing)       0.852273       0.858586  0.867347  \n",
      "\n",
      "\n",
      "\n",
      "*** test rec ***\n",
      "\n",
      "                      LogisticRegression  Support Vector Machines  \\\n",
      "Basic                           0.894118                      1.0   \n",
      "Time_outlier                    0.882353                      1.0   \n",
      "Time_/365                       0.894118                      1.0   \n",
      "Clinic_outlier                  0.882353                      1.0   \n",
      "Clinic_0-4(2steps)              0.870588                      1.0   \n",
      "Clinic_0-1(resizing)            0.870588                      1.0   \n",
      "\n",
      "                      KNN or k-Nearest Neighbors  Gaussian Naive Bayes  \\\n",
      "Basic                                   0.988235                   0.8   \n",
      "Time_outlier                            1.000000                   0.8   \n",
      "Time_/365                               0.976471                   0.8   \n",
      "Clinic_outlier                          1.000000                   0.8   \n",
      "Clinic_0-4(2steps)                      0.976471                   0.8   \n",
      "Clinic_0-1(resizing)                    0.964706                   0.8   \n",
      "\n",
      "                      Perceptron  Linear SVC  Stochastic Gradient Descent  \\\n",
      "Basic                   0.635294    0.811765                     0.752941   \n",
      "Time_outlier            0.600000    0.847059                     0.376471   \n",
      "Time_/365               0.929412    0.811765                     0.847059   \n",
      "Clinic_outlier          0.000000    0.847059                     1.000000   \n",
      "Clinic_0-4(2steps)      0.952941    0.835294                     0.964706   \n",
      "Clinic_0-1(resizing)    0.223529    0.835294                     1.000000   \n",
      "\n",
      "                      Decision Tree  Random Forest  Ensemble  \n",
      "Basic                      0.776471            1.0       1.0  \n",
      "Time_outlier               0.858824            1.0       1.0  \n",
      "Time_/365                  0.870588            1.0       1.0  \n",
      "Clinic_outlier             0.847059            1.0       1.0  \n",
      "Clinic_0-4(2steps)         0.917647            1.0       1.0  \n",
      "Clinic_0-1(resizing)       0.882353            1.0       1.0  \n",
      "\n",
      "\n",
      "\n",
      "*** test f1 ***\n",
      "\n",
      "                      LogisticRegression  Support Vector Machines  \\\n",
      "Basic                           0.868571                 0.918919   \n",
      "Time_outlier                    0.877193                 0.918919   \n",
      "Time_/365                       0.868571                 0.918919   \n",
      "Clinic_outlier                  0.877193                 0.918919   \n",
      "Clinic_0-4(2steps)              0.870588                 0.918919   \n",
      "Clinic_0-1(resizing)            0.875740                 0.918919   \n",
      "\n",
      "                      KNN or k-Nearest Neighbors  Gaussian Naive Bayes  \\\n",
      "Basic                                   0.913043              0.829268   \n",
      "Time_outlier                            0.928962              0.829268   \n",
      "Time_/365                               0.907104              0.829268   \n",
      "Clinic_outlier                          0.928962              0.829268   \n",
      "Clinic_0-4(2steps)                      0.927374              0.829268   \n",
      "Clinic_0-1(resizing)                    0.911111              0.829268   \n",
      "\n",
      "                      Perceptron  Linear SVC  Stochastic Gradient Descent  \\\n",
      "Basic                   0.739726    0.836364                     0.810127   \n",
      "Time_outlier            0.718310    0.862275                     0.528926   \n",
      "Time_/365               0.892655    0.836364                     0.857143   \n",
      "Clinic_outlier          0.000000    0.862275                     0.928962   \n",
      "Clinic_0-4(2steps)      0.920455    0.855422                     0.916201   \n",
      "Clinic_0-1(resizing)    0.358491    0.855422                     0.923913   \n",
      "\n",
      "                      Decision Tree  Random Forest  Ensemble  \n",
      "Basic                      0.804878       0.918919  0.918919  \n",
      "Time_outlier               0.853801       0.918919  0.928962  \n",
      "Time_/365                  0.865497       0.918919  0.928962  \n",
      "Clinic_outlier             0.857143       0.923913  0.928962  \n",
      "Clinic_0-4(2steps)         0.896552       0.923913  0.928962  \n",
      "Clinic_0-1(resizing)       0.867052       0.923913  0.928962  \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('*** train result ***', end='\\n\\n')\n",
    "result_train_df.index = index\n",
    "print(result_train_df)\n",
    "print(end='\\n\\n\\n')\n",
    "\n",
    "print('*** test result ***', end='\\n\\n')\n",
    "result_test_df.index = index\n",
    "print(result_test_df)\n",
    "print(end='\\n\\n\\n')\n",
    "\n",
    "print('*** test acc ***', end='\\n\\n')\n",
    "result_acc_test_df.index = index\n",
    "print(result_acc_test_df)\n",
    "print(end='\\n\\n\\n')\n",
    "\n",
    "print('*** test pre ***', end='\\n\\n')\n",
    "result_pre_test_df.index = index\n",
    "print(result_pre_test_df)\n",
    "print(end='\\n\\n\\n')\n",
    "\n",
    "print('*** test rec ***', end='\\n\\n')\n",
    "result_rec_test_df.index = index\n",
    "print(result_rec_test_df)\n",
    "print(end='\\n\\n\\n')\n",
    "\n",
    "print('*** test f1 ***', end='\\n\\n')\n",
    "result_f1score_test_df.index = index\n",
    "print(result_f1score_test_df)\n",
    "print(end='\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99029de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression              95.44\n",
      "Support Vector Machines         89.56\n",
      "KNN or k-Nearest Neighbors      91.89\n",
      "Gaussian Naive Bayes            86.11\n",
      "Perceptron                      93.11\n",
      "Linear SVC                     100.00\n",
      "Stochastic Gradient Descent     95.78\n",
      "Decision Tree                  100.00\n",
      "Random Forest                  100.00\n",
      "Ensemble                       100.00\n",
      "Name: max, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(result_train_df.describe().loc['max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce0ea3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression             79.0\n",
      "Support Vector Machines        85.0\n",
      "KNN or k-Nearest Neighbors     87.0\n",
      "Gaussian Naive Bayes           72.0\n",
      "Perceptron                     86.0\n",
      "Linear SVC                     77.0\n",
      "Stochastic Gradient Descent    87.0\n",
      "Decision Tree                  82.0\n",
      "Random Forest                  86.0\n",
      "Ensemble                       87.0\n",
      "Name: max, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(result_test_df.describe().loc['max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "tired-routine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression             0.79\n",
      "Support Vector Machines        0.85\n",
      "KNN or k-Nearest Neighbors     0.87\n",
      "Gaussian Naive Bayes           0.72\n",
      "Perceptron                     0.86\n",
      "Linear SVC                     0.77\n",
      "Stochastic Gradient Descent    0.87\n",
      "Decision Tree                  0.82\n",
      "Random Forest                  0.86\n",
      "Ensemble                       0.87\n",
      "Name: max, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(result_acc_test_df.describe().loc['max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "usual-regard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression             0.880952\n",
      "Support Vector Machines        0.850000\n",
      "KNN or k-Nearest Neighbors     0.882979\n",
      "Gaussian Naive Bayes           0.860759\n",
      "Perceptron                     0.904762\n",
      "Linear SVC                     0.878049\n",
      "Stochastic Gradient Descent    0.888889\n",
      "Decision Tree                  0.876404\n",
      "Random Forest                  0.858586\n",
      "Ensemble                       0.867347\n",
      "Name: max, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(result_pre_test_df.describe().loc['max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "golden-level",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression             0.894118\n",
      "Support Vector Machines        1.000000\n",
      "KNN or k-Nearest Neighbors     1.000000\n",
      "Gaussian Naive Bayes           0.800000\n",
      "Perceptron                     0.952941\n",
      "Linear SVC                     0.847059\n",
      "Stochastic Gradient Descent    1.000000\n",
      "Decision Tree                  0.917647\n",
      "Random Forest                  1.000000\n",
      "Ensemble                       1.000000\n",
      "Name: max, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(result_rec_test_df.describe().loc['max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "monthly-hungary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression             0.877193\n",
      "Support Vector Machines        0.918919\n",
      "KNN or k-Nearest Neighbors     0.928962\n",
      "Gaussian Naive Bayes           0.829268\n",
      "Perceptron                     0.920455\n",
      "Linear SVC                     0.862275\n",
      "Stochastic Gradient Descent    0.928962\n",
      "Decision Tree                  0.896552\n",
      "Random Forest                  0.923913\n",
      "Ensemble                       0.928962\n",
      "Name: max, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(result_f1score_test_df.describe().loc['max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "interstate-sheffield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE    /  :  (900, 312) (900,)\n",
      "SMOTE     : \n",
      "1    806\n",
      "0     94\n",
      "Name: event, dtype: int64\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SMOTE    /  :  (1612, 312) (1612,)\n",
      "SMOTE     : \n",
      "0    806\n",
      "1    806\n",
      "Name: event, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "SMOTE at df1_outlier and df3_outlier\n",
    "\n",
    "Add Time data(1) +  Correlating Clinic data(1) \n",
    "Training & Test\n",
    "\n",
    "'''\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "df = pd.concat([df1_outlier,df2,df3_outlier,df4], axis=1)\n",
    "train_df, test_df = df.iloc[random_index[:900],:], df.iloc[random_index[900:1000],:]\n",
    "\n",
    "X_train = train_df.drop(['event'], axis=1)\n",
    "Y_train = train_df['event']\n",
    "\n",
    "X_test = test_df.drop(['event'], axis=1)\n",
    "Y_test = test_df['event']\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "X_train_over, Y_train_over = smote.fit_resample(X_train, Y_train)\n",
    "\n",
    "# print()\n",
    "# training()\n",
    "\n",
    "print('SMOTE    /  : ', X_train.shape, Y_train.shape)\n",
    "print('SMOTE     : ')\n",
    "print(pd.Series(Y_train).value_counts())\n",
    "print('-'*100)\n",
    "print('SMOTE    /  : ', X_train_over.shape, Y_train_over.shape)\n",
    "print('SMOTE     : ')\n",
    "print(pd.Series(Y_train_over).value_counts())\n",
    "\n",
    "def training():\n",
    "    result_train = []\n",
    "    result_test = []\n",
    "    result_acc = []\n",
    "    result_pre = []\n",
    "    result_rec = []\n",
    "    result_f1 = []\n",
    "    for input_method in test_method_list:\n",
    "        print('*** Method: ', input_method)\n",
    "\n",
    "        if input_method == 'LogisticRegression':\n",
    "            model = LogisticRegression(max_iter = 10000)\n",
    "\n",
    "        elif input_method == 'Support Vector Machines':\n",
    "            model = SVC()\n",
    "\n",
    "        elif input_method == 'KNN or k-Nearest Neighbors':\n",
    "            model = KNeighborsClassifier(n_neighbors = 4)\n",
    "\n",
    "        elif input_method == 'Gaussian Naive Bayes':\n",
    "            model = GaussianNB()\n",
    "\n",
    "        elif input_method == 'Perceptron':\n",
    "            model = Perceptron()\n",
    "\n",
    "        elif input_method == 'Linear SVC':\n",
    "            model = LinearSVC(max_iter=1000000)\n",
    "\n",
    "        elif input_method == 'Stochastic Gradient Descent':\n",
    "            model = SGDClassifier()\n",
    "\n",
    "        elif input_method == 'Decision Tree':\n",
    "            model = DecisionTreeClassifier()\n",
    "\n",
    "        elif input_method == 'Random Forest':\n",
    "            model = RandomForestClassifier(n_estimators=20)\n",
    "            \n",
    "        elif input_method == 'Ensemble':\n",
    "            model  = VotingClassifier(ensemble_models, voting='soft') #, weights=[0]*len(ensemble_models)\n",
    "    \n",
    "        # Train\n",
    "        model.fit(X_train_over, Y_train_over)\n",
    "        acc_log = round(model.score(X_train_over, Y_train_over) * 100, 2)\n",
    "        print('trained-acc: ', acc_log)\n",
    "        result_train.append(acc_log)\n",
    "\n",
    "\n",
    "        # Test\n",
    "        print('test- ')\n",
    "        \n",
    "        # f1 score\n",
    "        Y_pred = model.predict(X_test)\n",
    "        acc, pre, rec = get_clf_eval(Y_test, Y_pred)\n",
    "        result_acc.append(acc)\n",
    "        result_pre.append(pre)\n",
    "        result_rec.append(rec)\n",
    "        f1 = f1_score(Y_test, Y_pred, average='weighted')\n",
    "        print('f1 score:{}'.format(f1))\n",
    "        result_f1.append(f1)\n",
    "        print()\n",
    "        print()\n",
    "        \n",
    "        \n",
    "    result_train_df.loc[result_train_df.shape[0]] = result_train\n",
    "    #     result_test_df.loc[result_test_df.shape[0]] = result_test\n",
    "    result_acc_test_df.loc[result_acc_test_df.shape[0]] = result_acc\n",
    "    result_pre_test_df.loc[result_pre_test_df.shape[0]] = result_pre\n",
    "    result_rec_test_df.loc[result_rec_test_df.shape[0]] = result_rec\n",
    "    result_f1score_test_df.loc[result_f1score_test_df.shape[0]] = result_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ignored-waters",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Method:  LogisticRegression\n",
      "trained-acc:  96.84\n",
      "test- \n",
      "accuracy:0.79, precision:0.872093023255814, recall:0.8823529411764706\n",
      "f1 score:0.786993345432547\n",
      "\n",
      "\n",
      "*** Method:  Support Vector Machines\n",
      "trained-acc:  87.59\n",
      "test- \n",
      "accuracy:0.8, precision:0.9012345679012346, recall:0.8588235294117647\n",
      "f1 score:0.8093550673281359\n",
      "\n",
      "\n",
      "*** Method:  KNN or k-Nearest Neighbors\n",
      "trained-acc:  56.33\n",
      "test- \n",
      "accuracy:0.19, precision:1.0, recall:0.047058823529411764\n",
      "f1 score:0.11694503492256303\n",
      "\n",
      "\n",
      "*** Method:  Gaussian Naive Bayes\n",
      "trained-acc:  94.17\n",
      "test- \n",
      "accuracy:0.85, precision:0.85, recall:1.0\n",
      "f1 score:0.781081081081081\n",
      "\n",
      "\n",
      "*** Method:  Perceptron\n",
      "trained-acc:  81.14\n",
      "test- \n",
      "accuracy:0.6, precision:0.8571428571428571, recall:0.6352941176470588\n",
      "f1 score:0.6548856548856549\n",
      "\n",
      "\n",
      "*** Method:  Linear SVC\n",
      "trained-acc:  99.57\n",
      "test- \n",
      "accuracy:0.76, precision:0.8765432098765432, recall:0.8352941176470589\n",
      "f1 score:0.7712260807937632\n",
      "\n",
      "\n",
      "*** Method:  Stochastic Gradient Descent\n",
      "trained-acc:  92.31\n",
      "test- \n",
      "accuracy:0.84, precision:0.8556701030927835, recall:0.9764705882352941\n",
      "f1 score:0.791941391941392\n",
      "\n",
      "\n",
      "*** Method:  Decision Tree\n",
      "trained-acc:  100.0\n",
      "test- \n",
      "accuracy:0.69, precision:0.8461538461538461, recall:0.7764705882352941\n",
      "f1 score:0.712667882606533\n",
      "\n",
      "\n",
      "*** Method:  Random Forest\n",
      "trained-acc:  100.0\n",
      "test- \n",
      "accuracy:0.87, precision:0.8673469387755102, recall:1.0\n",
      "f1 score:0.8249116039858566\n",
      "\n",
      "\n",
      "*** Method:  Ensemble\n",
      "trained-acc:  100.0\n",
      "test- \n",
      "accuracy:0.85, precision:0.8645833333333334, recall:0.9764705882352941\n",
      "f1 score:0.8111369584181449\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "SMOTE\n",
    "\n",
    "'''\n",
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "stupid-walnut",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE    /  :  (900, 312) (900,)\n",
      "SMOTE     : \n",
      "1    806\n",
      "0     94\n",
      "Name: event, dtype: int64\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SMOTE    /  :  (1615, 312) (1615,)\n",
      "SMOTE     : \n",
      "0    809\n",
      "1    806\n",
      "Name: event, dtype: int64\n",
      "\n",
      "*** Method:  LogisticRegression\n",
      "trained-acc:  96.84\n",
      "test- \n",
      "accuracy:0.78, precision:0.8705882352941177, recall:0.8705882352941177\n",
      "f1 score:0.7799999999999998\n",
      "\n",
      "\n",
      "*** Method:  Support Vector Machines\n",
      "trained-acc:  87.24\n",
      "test- \n",
      "accuracy:0.76, precision:0.8860759493670886, recall:0.8235294117647058\n",
      "f1 score:0.7756097560975609\n",
      "\n",
      "\n",
      "*** Method:  KNN or k-Nearest Neighbors\n",
      "trained-acc:  56.35\n",
      "test- \n",
      "accuracy:0.2, precision:1.0, recall:0.058823529411764705\n",
      "f1 score:0.13535353535353536\n",
      "\n",
      "\n",
      "*** Method:  Gaussian Naive Bayes\n",
      "trained-acc:  94.18\n",
      "test- \n",
      "accuracy:0.85, precision:0.85, recall:1.0\n",
      "f1 score:0.781081081081081\n",
      "\n",
      "\n",
      "*** Method:  Perceptron\n",
      "trained-acc:  93.0\n",
      "test- \n",
      "accuracy:0.85, precision:0.85, recall:1.0\n",
      "f1 score:0.781081081081081\n",
      "\n",
      "\n",
      "*** Method:  Linear SVC\n",
      "trained-acc:  99.63\n",
      "test- \n",
      "accuracy:0.72, precision:0.8607594936708861, recall:0.8\n",
      "f1 score:0.7382113821138212\n",
      "\n",
      "\n",
      "*** Method:  Stochastic Gradient Descent\n",
      "trained-acc:  63.78\n",
      "test- \n",
      "accuracy:0.29, precision:0.7916666666666666, recall:0.2235294117647059\n",
      "f1 score:0.32929730819639075\n",
      "\n",
      "\n",
      "*** Method:  Decision Tree\n",
      "trained-acc:  100.0\n",
      "test- \n",
      "accuracy:0.71, precision:0.8783783783783784, recall:0.7647058823529411\n",
      "f1 score:0.7388709924835096\n",
      "\n",
      "\n",
      "*** Method:  Random Forest\n",
      "trained-acc:  100.0\n",
      "test- \n",
      "accuracy:0.84, precision:0.8556701030927835, recall:0.9764705882352941\n",
      "f1 score:0.791941391941392\n",
      "\n",
      "\n",
      "*** Method:  Ensemble\n",
      "trained-acc:  100.0\n",
      "test- \n",
      "accuracy:0.86, precision:0.865979381443299, recall:0.9882352941176471\n",
      "f1 score:0.8179487179487179\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "ADASYN\n",
    "'''\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "ada = ADASYN(random_state=0, sampling_strategy  ='minority' )\n",
    "X_train_over, Y_train_over = ada.fit_resample(X_train, Y_train)\n",
    "\n",
    "# print()\n",
    "# training()\n",
    "\n",
    "print('SMOTE    /  : ', X_train.shape, Y_train.shape)\n",
    "print('SMOTE     : ')\n",
    "print(pd.Series(Y_train).value_counts())\n",
    "print('-'*100)\n",
    "print('SMOTE    /  : ', X_train_over.shape, Y_train_over.shape)\n",
    "print('SMOTE     : ')\n",
    "print(pd.Series(Y_train_over).value_counts())\n",
    "\n",
    "\n",
    "\n",
    "print()\n",
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "spectacular-forwarding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE    /  :  (900, 312) (900,)\n",
      "SMOTE     : \n",
      "1    806\n",
      "0     94\n",
      "Name: event, dtype: int64\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SMOTE    /  :  (1612, 312) (1612,)\n",
      "SMOTE     : \n",
      "0    806\n",
      "1    806\n",
      "Name: event, dtype: int64\n",
      "*** Method:  LogisticRegression\n",
      "trained-acc:  96.9\n",
      "test- \n",
      "accuracy:0.78, precision:0.8705882352941177, recall:0.8705882352941177\n",
      "f1 score:0.7799999999999998\n",
      "\n",
      "\n",
      "*** Method:  Support Vector Machines\n",
      "trained-acc:  87.1\n",
      "test- \n",
      "accuracy:0.81, precision:0.9024390243902439, recall:0.8705882352941177\n",
      "f1 score:0.8169297768100162\n",
      "\n",
      "\n",
      "*** Method:  KNN or k-Nearest Neighbors\n",
      "trained-acc:  57.07\n",
      "test- \n",
      "accuracy:0.21, precision:1.0, recall:0.07058823529411765\n",
      "f1 score:0.15337231575763688\n",
      "\n",
      "\n",
      "*** Method:  Gaussian Naive Bayes\n",
      "trained-acc:  94.17\n",
      "test- \n",
      "accuracy:0.85, precision:0.85, recall:1.0\n",
      "f1 score:0.781081081081081\n",
      "\n",
      "\n",
      "*** Method:  Perceptron\n",
      "trained-acc:  94.17\n",
      "test- \n",
      "accuracy:0.85, precision:0.85, recall:1.0\n",
      "f1 score:0.781081081081081\n",
      "\n",
      "\n",
      "*** Method:  Linear SVC\n",
      "trained-acc:  99.69\n",
      "test- \n",
      "accuracy:0.73, precision:0.8717948717948718, recall:0.8\n",
      "f1 score:0.7497429945282705\n",
      "\n",
      "\n",
      "*** Method:  Stochastic Gradient Descent\n",
      "trained-acc:  93.92\n",
      "test- \n",
      "accuracy:0.81, precision:0.8586956521739131, recall:0.9294117647058824\n",
      "f1 score:0.7848440186686318\n",
      "\n",
      "\n",
      "*** Method:  Decision Tree\n",
      "trained-acc:  100.0\n",
      "test- \n",
      "accuracy:0.72, precision:0.8701298701298701, recall:0.788235294117647\n",
      "f1 score:0.7425601039636126\n",
      "\n",
      "\n",
      "*** Method:  Random Forest\n",
      "trained-acc:  99.94\n",
      "test- \n",
      "accuracy:0.83, precision:0.8469387755102041, recall:0.9764705882352941\n",
      "f1 score:0.7710382513661201\n",
      "\n",
      "\n",
      "*** Method:  Ensemble\n",
      "trained-acc:  100.0\n",
      "test- \n",
      "accuracy:0.86, precision:0.865979381443299, recall:0.9882352941176471\n",
      "f1 score:0.8179487179487179\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "SMOTETomek\n",
    "\n",
    "'''\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smtom = SMOTETomek(random_state=139)\n",
    "X_train_over, Y_train_over = smtom.fit_resample(X_train, Y_train)\n",
    "\n",
    "# print()\n",
    "# training()\n",
    "\n",
    "print('SMOTE    /  : ', X_train.shape, Y_train.shape)\n",
    "print('SMOTE     : ')\n",
    "print(pd.Series(Y_train).value_counts())\n",
    "print('-'*100)\n",
    "print('SMOTE    /  : ', X_train_over.shape, Y_train_over.shape)\n",
    "print('SMOTE     : ')\n",
    "print(pd.Series(Y_train_over).value_counts())\n",
    "\n",
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "minor-default",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE    /  :  (900, 312) (900,)\n",
      "SMOTE     : \n",
      "1    806\n",
      "0     94\n",
      "Name: event, dtype: int64\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SMOTE    /  :  (953, 312) (953,)\n",
      "SMOTE     : \n",
      "0    800\n",
      "1    153\n",
      "Name: event, dtype: int64\n",
      "*** Method:  LogisticRegression\n",
      "trained-acc:  99.9\n",
      "test- \n",
      "accuracy:0.55, precision:0.8571428571428571, recall:0.5647058823529412\n",
      "f1 score:0.6143166245943023\n",
      "\n",
      "\n",
      "*** Method:  Support Vector Machines\n",
      "trained-acc:  84.37\n",
      "test- \n",
      "accuracy:0.15, precision:0.0, recall:0.0\n",
      "f1 score:0.0391304347826087\n",
      "\n",
      "\n",
      "*** Method:  KNN or k-Nearest Neighbors\n",
      "trained-acc:  89.19\n",
      "test- \n",
      "accuracy:0.17, precision:1.0, recall:0.023529411764705882\n",
      "f1 score:0.07890346861967247\n",
      "\n",
      "\n",
      "*** Method:  Gaussian Naive Bayes\n",
      "trained-acc:  90.45\n",
      "test- \n",
      "accuracy:0.85, precision:0.85, recall:1.0\n",
      "f1 score:0.781081081081081\n",
      "\n",
      "\n",
      "*** Method:  Perceptron\n",
      "trained-acc:  86.15\n",
      "test- \n",
      "accuracy:0.23, precision:0.75, recall:0.1411764705882353\n",
      "f1 score:0.2353135313531353\n",
      "\n",
      "\n",
      "*** Method:  Linear SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained-acc:  100.0\n",
      "test- \n",
      "accuracy:0.57, precision:0.8620689655172413, recall:0.5882352941176471\n",
      "f1 score:0.6312476996687524\n",
      "\n",
      "\n",
      "*** Method:  Stochastic Gradient Descent\n",
      "trained-acc:  94.33\n",
      "test- \n",
      "accuracy:0.68, precision:0.8732394366197183, recall:0.7294117647058823\n",
      "f1 score:0.7165501165501166\n",
      "\n",
      "\n",
      "*** Method:  Decision Tree\n",
      "trained-acc:  100.0\n",
      "test- \n",
      "accuracy:0.57, precision:0.875, recall:0.5764705882352941\n",
      "f1 score:0.6314581079456666\n",
      "\n",
      "\n",
      "*** Method:  Random Forest\n",
      "trained-acc:  100.0\n",
      "test- \n",
      "accuracy:0.55, precision:0.8703703703703703, recall:0.5529411764705883\n",
      "f1 score:0.6141644061799739\n",
      "\n",
      "\n",
      "*** Method:  Ensemble\n",
      "trained-acc:  100.0\n",
      "test- \n",
      "accuracy:0.54, precision:0.9148936170212766, recall:0.5058823529411764\n",
      "f1 score:0.6023172905525848\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "SMOTEENN\n",
    "\n",
    "'''\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "smenn = SMOTEENN(random_state=139, sampling_strategy  ='all')\n",
    "X_train_over, Y_train_over = smenn.fit_resample(X_train, Y_train)\n",
    "\n",
    "# print()\n",
    "# training()\n",
    "\n",
    "print('SMOTE    /  : ', X_train.shape, Y_train.shape)\n",
    "print('SMOTE     : ')\n",
    "print(pd.Series(Y_train).value_counts())\n",
    "print('-'*100)\n",
    "print('SMOTE    /  : ', X_train_over.shape, Y_train_over.shape)\n",
    "print('SMOTE     : ')\n",
    "print(pd.Series(Y_train_over).value_counts())\n",
    "\n",
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "proud-camping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** train result ***\n",
      "\n",
      "                      LogisticRegression  Support Vector Machines  \\\n",
      "Basic                              94.78                    89.56   \n",
      "Time_outlier                       95.44                    89.56   \n",
      "Time_/365                          94.78                    89.56   \n",
      "Clinic_outlier                     95.44                    89.56   \n",
      "Clinic_0-4(2steps)                 95.33                    89.56   \n",
      "Clinic_0-1(resizing)               94.78                    89.56   \n",
      "SMOTE                              96.84                    87.59   \n",
      "ADASYN                             96.84                    87.24   \n",
      "SMOTETomek                         96.90                    87.10   \n",
      "SMOTEENN                           99.90                    84.37   \n",
      "\n",
      "                      KNN or k-Nearest Neighbors  Gaussian Naive Bayes  \\\n",
      "Basic                                      90.44                 85.89   \n",
      "Time_outlier                               91.11                 86.11   \n",
      "Time_/365                                  90.22                 86.11   \n",
      "Clinic_outlier                             91.11                 85.89   \n",
      "Clinic_0-4(2steps)                         91.89                 85.78   \n",
      "Clinic_0-1(resizing)                       91.44                 85.89   \n",
      "SMOTE                                      56.33                 94.17   \n",
      "ADASYN                                     56.35                 94.18   \n",
      "SMOTETomek                                 57.07                 94.17   \n",
      "SMOTEENN                                   89.19                 90.45   \n",
      "\n",
      "                      Perceptron  Linear SVC  Stochastic Gradient Descent  \\\n",
      "Basic                      70.11       99.89                        82.89   \n",
      "Time_outlier               67.33       99.89                        50.44   \n",
      "Time_/365                  92.78       99.89                        95.78   \n",
      "Clinic_outlier             10.44       99.89                        90.33   \n",
      "Clinic_0-4(2steps)         93.11      100.00                        92.44   \n",
      "Clinic_0-1(resizing)       30.22      100.00                        90.00   \n",
      "SMOTE                      81.14       99.57                        92.31   \n",
      "ADASYN                     93.00       99.63                        63.78   \n",
      "SMOTETomek                 94.17       99.69                        93.92   \n",
      "SMOTEENN                   86.15      100.00                        94.33   \n",
      "\n",
      "                      Decision Tree  Random Forest  Ensemble  \n",
      "Basic                         100.0          99.78     100.0  \n",
      "Time_outlier                  100.0          99.78     100.0  \n",
      "Time_/365                     100.0          99.33     100.0  \n",
      "Clinic_outlier                100.0          99.67     100.0  \n",
      "Clinic_0-4(2steps)            100.0         100.00     100.0  \n",
      "Clinic_0-1(resizing)          100.0          99.67     100.0  \n",
      "SMOTE                         100.0         100.00     100.0  \n",
      "ADASYN                        100.0         100.00     100.0  \n",
      "SMOTETomek                    100.0          99.94     100.0  \n",
      "SMOTEENN                      100.0         100.00     100.0  \n",
      "\n",
      "\n",
      "\n",
      "*** test acc ***\n",
      "\n",
      "                      LogisticRegression  Support Vector Machines  \\\n",
      "Basic                               0.77                     0.85   \n",
      "Time_outlier                        0.79                     0.85   \n",
      "Time_/365                           0.77                     0.85   \n",
      "Clinic_outlier                      0.79                     0.85   \n",
      "Clinic_0-4(2steps)                  0.78                     0.85   \n",
      "Clinic_0-1(resizing)                0.79                     0.85   \n",
      "SMOTE                               0.79                     0.80   \n",
      "ADASYN                              0.78                     0.76   \n",
      "SMOTETomek                          0.78                     0.81   \n",
      "SMOTEENN                            0.55                     0.15   \n",
      "\n",
      "                      KNN or k-Nearest Neighbors  Gaussian Naive Bayes  \\\n",
      "Basic                                       0.84                  0.72   \n",
      "Time_outlier                                0.87                  0.72   \n",
      "Time_/365                                   0.83                  0.72   \n",
      "Clinic_outlier                              0.87                  0.72   \n",
      "Clinic_0-4(2steps)                          0.87                  0.72   \n",
      "Clinic_0-1(resizing)                        0.84                  0.72   \n",
      "SMOTE                                       0.19                  0.85   \n",
      "ADASYN                                      0.20                  0.85   \n",
      "SMOTETomek                                  0.21                  0.85   \n",
      "SMOTEENN                                    0.17                  0.85   \n",
      "\n",
      "                      Perceptron  Linear SVC  Stochastic Gradient Descent  \\\n",
      "Basic                       0.62        0.73                         0.70   \n",
      "Time_outlier                0.60        0.77                         0.43   \n",
      "Time_/365                   0.81        0.73                         0.76   \n",
      "Clinic_outlier              0.15        0.77                         0.87   \n",
      "Clinic_0-4(2steps)          0.86        0.76                         0.85   \n",
      "Clinic_0-1(resizing)        0.32        0.76                         0.86   \n",
      "SMOTE                       0.60        0.76                         0.84   \n",
      "ADASYN                      0.85        0.72                         0.29   \n",
      "SMOTETomek                  0.85        0.73                         0.81   \n",
      "SMOTEENN                    0.23        0.57                         0.68   \n",
      "\n",
      "                      Decision Tree  Random Forest  Ensemble  \n",
      "Basic                          0.68           0.85      0.85  \n",
      "Time_outlier                   0.75           0.85      0.87  \n",
      "Time_/365                      0.77           0.85      0.87  \n",
      "Clinic_outlier                 0.76           0.86      0.87  \n",
      "Clinic_0-4(2steps)             0.82           0.86      0.87  \n",
      "Clinic_0-1(resizing)           0.77           0.86      0.87  \n",
      "SMOTE                          0.69           0.87      0.85  \n",
      "ADASYN                         0.71           0.84      0.86  \n",
      "SMOTETomek                     0.72           0.83      0.86  \n",
      "SMOTEENN                       0.57           0.55      0.54  \n",
      "\n",
      "\n",
      "\n",
      "*** test pre ***\n",
      "\n",
      "                      LogisticRegression  Support Vector Machines  \\\n",
      "Basic                           0.844444                 0.850000   \n",
      "Time_outlier                    0.872093                 0.850000   \n",
      "Time_/365                       0.844444                 0.850000   \n",
      "Clinic_outlier                  0.872093                 0.850000   \n",
      "Clinic_0-4(2steps)              0.870588                 0.850000   \n",
      "Clinic_0-1(resizing)            0.880952                 0.850000   \n",
      "SMOTE                           0.872093                 0.901235   \n",
      "ADASYN                          0.870588                 0.886076   \n",
      "SMOTETomek                      0.870588                 0.902439   \n",
      "SMOTEENN                        0.857143                 0.000000   \n",
      "\n",
      "                      KNN or k-Nearest Neighbors  Gaussian Naive Bayes  \\\n",
      "Basic                                   0.848485              0.860759   \n",
      "Time_outlier                            0.867347              0.860759   \n",
      "Time_/365                               0.846939              0.860759   \n",
      "Clinic_outlier                          0.867347              0.860759   \n",
      "Clinic_0-4(2steps)                      0.882979              0.860759   \n",
      "Clinic_0-1(resizing)                    0.863158              0.860759   \n",
      "SMOTE                                   1.000000              0.850000   \n",
      "ADASYN                                  1.000000              0.850000   \n",
      "SMOTETomek                              1.000000              0.850000   \n",
      "SMOTEENN                                1.000000              0.850000   \n",
      "\n",
      "                      Perceptron  Linear SVC  Stochastic Gradient Descent  \\\n",
      "Basic                   0.885246    0.862500                     0.876712   \n",
      "Time_outlier            0.894737    0.878049                     0.888889   \n",
      "Time_/365               0.858696    0.862500                     0.867470   \n",
      "Clinic_outlier          0.000000    0.878049                     0.867347   \n",
      "Clinic_0-4(2steps)      0.890110    0.876543                     0.872340   \n",
      "Clinic_0-1(resizing)    0.904762    0.876543                     0.858586   \n",
      "SMOTE                   0.857143    0.876543                     0.855670   \n",
      "ADASYN                  0.850000    0.860759                     0.791667   \n",
      "SMOTETomek              0.850000    0.871795                     0.858696   \n",
      "SMOTEENN                0.750000    0.862069                     0.873239   \n",
      "\n",
      "                      Decision Tree  Random Forest  Ensemble  \n",
      "Basic                      0.835443       0.850000  0.850000  \n",
      "Time_outlier               0.848837       0.850000  0.867347  \n",
      "Time_/365                  0.860465       0.850000  0.867347  \n",
      "Clinic_outlier             0.867470       0.858586  0.867347  \n",
      "Clinic_0-4(2steps)         0.876404       0.858586  0.867347  \n",
      "Clinic_0-1(resizing)       0.852273       0.858586  0.867347  \n",
      "SMOTE                      0.846154       0.867347  0.864583  \n",
      "ADASYN                     0.878378       0.855670  0.865979  \n",
      "SMOTETomek                 0.870130       0.846939  0.865979  \n",
      "SMOTEENN                   0.875000       0.870370  0.914894  \n",
      "\n",
      "\n",
      "\n",
      "*** test rec ***\n",
      "\n",
      "                      LogisticRegression  Support Vector Machines  \\\n",
      "Basic                           0.894118                 1.000000   \n",
      "Time_outlier                    0.882353                 1.000000   \n",
      "Time_/365                       0.894118                 1.000000   \n",
      "Clinic_outlier                  0.882353                 1.000000   \n",
      "Clinic_0-4(2steps)              0.870588                 1.000000   \n",
      "Clinic_0-1(resizing)            0.870588                 1.000000   \n",
      "SMOTE                           0.882353                 0.858824   \n",
      "ADASYN                          0.870588                 0.823529   \n",
      "SMOTETomek                      0.870588                 0.870588   \n",
      "SMOTEENN                        0.564706                 0.000000   \n",
      "\n",
      "                      KNN or k-Nearest Neighbors  Gaussian Naive Bayes  \\\n",
      "Basic                                   0.988235                   0.8   \n",
      "Time_outlier                            1.000000                   0.8   \n",
      "Time_/365                               0.976471                   0.8   \n",
      "Clinic_outlier                          1.000000                   0.8   \n",
      "Clinic_0-4(2steps)                      0.976471                   0.8   \n",
      "Clinic_0-1(resizing)                    0.964706                   0.8   \n",
      "SMOTE                                   0.047059                   1.0   \n",
      "ADASYN                                  0.058824                   1.0   \n",
      "SMOTETomek                              0.070588                   1.0   \n",
      "SMOTEENN                                0.023529                   1.0   \n",
      "\n",
      "                      Perceptron  Linear SVC  Stochastic Gradient Descent  \\\n",
      "Basic                   0.635294    0.811765                     0.752941   \n",
      "Time_outlier            0.600000    0.847059                     0.376471   \n",
      "Time_/365               0.929412    0.811765                     0.847059   \n",
      "Clinic_outlier          0.000000    0.847059                     1.000000   \n",
      "Clinic_0-4(2steps)      0.952941    0.835294                     0.964706   \n",
      "Clinic_0-1(resizing)    0.223529    0.835294                     1.000000   \n",
      "SMOTE                   0.635294    0.835294                     0.976471   \n",
      "ADASYN                  1.000000    0.800000                     0.223529   \n",
      "SMOTETomek              1.000000    0.800000                     0.929412   \n",
      "SMOTEENN                0.141176    0.588235                     0.729412   \n",
      "\n",
      "                      Decision Tree  Random Forest  Ensemble  \n",
      "Basic                      0.776471       1.000000  1.000000  \n",
      "Time_outlier               0.858824       1.000000  1.000000  \n",
      "Time_/365                  0.870588       1.000000  1.000000  \n",
      "Clinic_outlier             0.847059       1.000000  1.000000  \n",
      "Clinic_0-4(2steps)         0.917647       1.000000  1.000000  \n",
      "Clinic_0-1(resizing)       0.882353       1.000000  1.000000  \n",
      "SMOTE                      0.776471       1.000000  0.976471  \n",
      "ADASYN                     0.764706       0.976471  0.988235  \n",
      "SMOTETomek                 0.788235       0.976471  0.988235  \n",
      "SMOTEENN                   0.576471       0.552941  0.505882  \n",
      "\n",
      "\n",
      "\n",
      "*** test f1 ***\n",
      "\n",
      "                      LogisticRegression  Support Vector Machines  \\\n",
      "Basic                           0.868571                 0.918919   \n",
      "Time_outlier                    0.877193                 0.918919   \n",
      "Time_/365                       0.868571                 0.918919   \n",
      "Clinic_outlier                  0.877193                 0.918919   \n",
      "Clinic_0-4(2steps)              0.870588                 0.918919   \n",
      "Clinic_0-1(resizing)            0.875740                 0.918919   \n",
      "SMOTE                           0.786993                 0.809355   \n",
      "ADASYN                          0.780000                 0.775610   \n",
      "SMOTETomek                      0.780000                 0.816930   \n",
      "SMOTEENN                        0.614317                 0.039130   \n",
      "\n",
      "                      KNN or k-Nearest Neighbors  Gaussian Naive Bayes  \\\n",
      "Basic                                   0.913043              0.829268   \n",
      "Time_outlier                            0.928962              0.829268   \n",
      "Time_/365                               0.907104              0.829268   \n",
      "Clinic_outlier                          0.928962              0.829268   \n",
      "Clinic_0-4(2steps)                      0.927374              0.829268   \n",
      "Clinic_0-1(resizing)                    0.911111              0.829268   \n",
      "SMOTE                                   0.116945              0.781081   \n",
      "ADASYN                                  0.135354              0.781081   \n",
      "SMOTETomek                              0.153372              0.781081   \n",
      "SMOTEENN                                0.078903              0.781081   \n",
      "\n",
      "                      Perceptron  Linear SVC  Stochastic Gradient Descent  \\\n",
      "Basic                   0.739726    0.836364                     0.810127   \n",
      "Time_outlier            0.718310    0.862275                     0.528926   \n",
      "Time_/365               0.892655    0.836364                     0.857143   \n",
      "Clinic_outlier          0.000000    0.862275                     0.928962   \n",
      "Clinic_0-4(2steps)      0.920455    0.855422                     0.916201   \n",
      "Clinic_0-1(resizing)    0.358491    0.855422                     0.923913   \n",
      "SMOTE                   0.654886    0.771226                     0.791941   \n",
      "ADASYN                  0.781081    0.738211                     0.329297   \n",
      "SMOTETomek              0.781081    0.749743                     0.784844   \n",
      "SMOTEENN                0.235314    0.631248                     0.716550   \n",
      "\n",
      "                      Decision Tree  Random Forest  Ensemble  \n",
      "Basic                      0.804878       0.918919  0.918919  \n",
      "Time_outlier               0.853801       0.918919  0.928962  \n",
      "Time_/365                  0.865497       0.918919  0.928962  \n",
      "Clinic_outlier             0.857143       0.923913  0.928962  \n",
      "Clinic_0-4(2steps)         0.896552       0.923913  0.928962  \n",
      "Clinic_0-1(resizing)       0.867052       0.923913  0.928962  \n",
      "SMOTE                      0.712668       0.824912  0.811137  \n",
      "ADASYN                     0.738871       0.791941  0.817949  \n",
      "SMOTETomek                 0.742560       0.771038  0.817949  \n",
      "SMOTEENN                   0.631458       0.614164  0.602317  \n",
      "\n",
      "\n",
      "\n",
      "*** train acc describe ***\n",
      "\n",
      "LogisticRegression              99.90\n",
      "Support Vector Machines         89.56\n",
      "KNN or k-Nearest Neighbors      91.89\n",
      "Gaussian Naive Bayes            94.18\n",
      "Perceptron                      94.17\n",
      "Linear SVC                     100.00\n",
      "Stochastic Gradient Descent     95.78\n",
      "Decision Tree                  100.00\n",
      "Random Forest                  100.00\n",
      "Ensemble                       100.00\n",
      "Name: max, dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "*** test acc describe ***\n",
      "\n",
      "LogisticRegression             0.79\n",
      "Support Vector Machines        0.85\n",
      "KNN or k-Nearest Neighbors     0.87\n",
      "Gaussian Naive Bayes           0.85\n",
      "Perceptron                     0.86\n",
      "Linear SVC                     0.77\n",
      "Stochastic Gradient Descent    0.87\n",
      "Decision Tree                  0.82\n",
      "Random Forest                  0.87\n",
      "Ensemble                       0.87\n",
      "Name: max, dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "*** test pre describe ***\n",
      "\n",
      "LogisticRegression             0.880952\n",
      "Support Vector Machines        0.902439\n",
      "KNN or k-Nearest Neighbors     1.000000\n",
      "Gaussian Naive Bayes           0.860759\n",
      "Perceptron                     0.904762\n",
      "Linear SVC                     0.878049\n",
      "Stochastic Gradient Descent    0.888889\n",
      "Decision Tree                  0.878378\n",
      "Random Forest                  0.870370\n",
      "Ensemble                       0.914894\n",
      "Name: max, dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "*** test rec describe ***\n",
      "\n",
      "LogisticRegression             0.894118\n",
      "Support Vector Machines        1.000000\n",
      "KNN or k-Nearest Neighbors     1.000000\n",
      "Gaussian Naive Bayes           1.000000\n",
      "Perceptron                     1.000000\n",
      "Linear SVC                     0.847059\n",
      "Stochastic Gradient Descent    1.000000\n",
      "Decision Tree                  0.917647\n",
      "Random Forest                  1.000000\n",
      "Ensemble                       1.000000\n",
      "Name: max, dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "*** test f1 describe ***\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression             0.877193\n",
      "Support Vector Machines        0.918919\n",
      "KNN or k-Nearest Neighbors     0.928962\n",
      "Gaussian Naive Bayes           0.829268\n",
      "Perceptron                     0.920455\n",
      "Linear SVC                     0.862275\n",
      "Stochastic Gradient Descent    0.928962\n",
      "Decision Tree                  0.896552\n",
      "Random Forest                  0.923913\n",
      "Ensemble                       0.928962\n",
      "Name: max, dtype: float64\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = ['Basic','Time_outlier','Time_/365','Clinic_outlier','Clinic_0-4(2steps)','Clinic_0-1(resizing)',\n",
    "        'SMOTE', 'ADASYN', 'SMOTETomek', 'SMOTEENN']\n",
    "\n",
    "print('*** train result ***', end='\\n\\n')\n",
    "result_train_df.index = index\n",
    "print(result_train_df)\n",
    "print(end='\\n\\n\\n')\n",
    "\n",
    "# print('*** test result ***', end='\\n\\n')\n",
    "# result_test_df.index = index\n",
    "# print(result_test_df)\n",
    "# print(end='\\n\\n\\n')\n",
    "\n",
    "print('*** test acc ***', end='\\n\\n')\n",
    "result_acc_test_df.index = index\n",
    "print(result_acc_test_df)\n",
    "print(end='\\n\\n\\n')\n",
    "\n",
    "print('*** test pre ***', end='\\n\\n')\n",
    "result_pre_test_df.index = index\n",
    "print(result_pre_test_df)\n",
    "print(end='\\n\\n\\n')\n",
    "\n",
    "print('*** test rec ***', end='\\n\\n')\n",
    "result_rec_test_df.index = index\n",
    "print(result_rec_test_df)\n",
    "print(end='\\n\\n\\n')\n",
    "\n",
    "print('*** test f1 ***', end='\\n\\n')\n",
    "result_f1score_test_df.index = index\n",
    "print(result_f1score_test_df)\n",
    "print(end='\\n\\n\\n')\n",
    "\n",
    "print('*** train acc describe ***', end='\\n\\n')\n",
    "print(result_train_df.describe().loc['max'])\n",
    "print(end='\\n\\n\\n')\n",
    "\n",
    "print('*** test acc describe ***', end='\\n\\n')\n",
    "print(result_acc_test_df.describe().loc['max'])\n",
    "print(end='\\n\\n\\n')\n",
    "\n",
    "print('*** test pre describe ***', end='\\n\\n')\n",
    "print(result_pre_test_df.describe().loc['max'])\n",
    "print(end='\\n\\n\\n')\n",
    "\n",
    "print('*** test rec describe ***', end='\\n\\n')\n",
    "print(result_rec_test_df.describe().loc['max'])\n",
    "print(end='\\n\\n\\n')\n",
    "\n",
    "print('*** test f1 describe ***', end='\\n\\n')\n",
    "print(result_f1score_test_df.describe().loc['max'])\n",
    "print(end='\\n\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
