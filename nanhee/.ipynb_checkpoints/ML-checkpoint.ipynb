{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "exclusive-religious",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "analyzed-entity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('Survival_time_event.csv', index_col=0)\n",
    "df2=pd.read_csv('Treatment.csv', index_col=0)\n",
    "df3=pd.read_csv('Clinical_Variables.csv', index_col=0)\n",
    "df4=pd.read_csv('Genetic_alterations.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aware-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1,df2,df3,df4], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "municipal-percentage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['time' 'event' 'Treatment' 'Var1' 'Var2' 'Var3' 'Var4' 'Var5' 'Var6'\n",
      " 'Var7' 'Var8' 'Var9' 'Var10' 'G1' 'G2' 'G3' 'G4' 'G5' 'G6' 'G7' 'G8' 'G9'\n",
      " 'G10' 'G11' 'G12' 'G13' 'G14' 'G15' 'G16' 'G17' 'G18' 'G19' 'G20' 'G21'\n",
      " 'G22' 'G23' 'G24' 'G25' 'G26' 'G27' 'G28' 'G29' 'G30' 'G31' 'G32' 'G33'\n",
      " 'G34' 'G35' 'G36' 'G37' 'G38' 'G39' 'G40' 'G41' 'G42' 'G43' 'G44' 'G45'\n",
      " 'G46' 'G47' 'G48' 'G49' 'G50' 'G51' 'G52' 'G53' 'G54' 'G55' 'G56' 'G57'\n",
      " 'G58' 'G59' 'G60' 'G61' 'G62' 'G63' 'G64' 'G65' 'G66' 'G67' 'G68' 'G69'\n",
      " 'G70' 'G71' 'G72' 'G73' 'G74' 'G75' 'G76' 'G77' 'G78' 'G79' 'G80' 'G81'\n",
      " 'G82' 'G83' 'G84' 'G85' 'G86' 'G87' 'G88' 'G89' 'G90' 'G91' 'G92' 'G93'\n",
      " 'G94' 'G95' 'G96' 'G97' 'G98' 'G99' 'G100' 'G101' 'G102' 'G103' 'G104'\n",
      " 'G105' 'G106' 'G107' 'G108' 'G109' 'G110' 'G111' 'G112' 'G113' 'G114'\n",
      " 'G115' 'G116' 'G117' 'G118' 'G119' 'G120' 'G121' 'G122' 'G123' 'G124'\n",
      " 'G125' 'G126' 'G127' 'G128' 'G129' 'G130' 'G131' 'G132' 'G133' 'G134'\n",
      " 'G135' 'G136' 'G137' 'G138' 'G139' 'G140' 'G141' 'G142' 'G143' 'G144'\n",
      " 'G145' 'G146' 'G147' 'G148' 'G149' 'G150' 'G151' 'G152' 'G153' 'G154'\n",
      " 'G155' 'G156' 'G157' 'G158' 'G159' 'G160' 'G161' 'G162' 'G163' 'G164'\n",
      " 'G165' 'G166' 'G167' 'G168' 'G169' 'G170' 'G171' 'G172' 'G173' 'G174'\n",
      " 'G175' 'G176' 'G177' 'G178' 'G179' 'G180' 'G181' 'G182' 'G183' 'G184'\n",
      " 'G185' 'G186' 'G187' 'G188' 'G189' 'G190' 'G191' 'G192' 'G193' 'G194'\n",
      " 'G195' 'G196' 'G197' 'G198' 'G199' 'G200' 'G201' 'G202' 'G203' 'G204'\n",
      " 'G205' 'G206' 'G207' 'G208' 'G209' 'G210' 'G211' 'G212' 'G213' 'G214'\n",
      " 'G215' 'G216' 'G217' 'G218' 'G219' 'G220' 'G221' 'G222' 'G223' 'G224'\n",
      " 'G225' 'G226' 'G227' 'G228' 'G229' 'G230' 'G231' 'G232' 'G233' 'G234'\n",
      " 'G235' 'G236' 'G237' 'G238' 'G239' 'G240' 'G241' 'G242' 'G243' 'G244'\n",
      " 'G245' 'G246' 'G247' 'G248' 'G249' 'G250' 'G251' 'G252' 'G253' 'G254'\n",
      " 'G255' 'G256' 'G257' 'G258' 'G259' 'G260' 'G261' 'G262' 'G263' 'G264'\n",
      " 'G265' 'G266' 'G267' 'G268' 'G269' 'G270' 'G271' 'G272' 'G273' 'G274'\n",
      " 'G275' 'G276' 'G277' 'G278' 'G279' 'G280' 'G281' 'G282' 'G283' 'G284'\n",
      " 'G285' 'G286' 'G287' 'G288' 'G289' 'G290' 'G291' 'G292' 'G293' 'G294'\n",
      " 'G295' 'G296' 'G297' 'G298' 'G299' 'G300']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Analyze by describing data\n",
    "'''\n",
    "\n",
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baking-nevada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        time  event  Treatment  Var1  Var2  Var3  Var4  Var5  Var6  Var7  ...  \\\n",
      "0  57.448331      1          0     5     1     1     4     6     5     2  ...   \n",
      "1  27.004439      1          0     3     1     3     9     1     1     2  ...   \n",
      "2  43.770511      1          1     2     5     3     4     3     3     3  ...   \n",
      "3  32.281018      1          1     2     7     2     3     5     0     1  ...   \n",
      "4  44.559284      0          0     1     3     0     0     2     2     6  ...   \n",
      "\n",
      "   G291  G292  G293  G294  G295  G296  G297  G298  G299  G300  \n",
      "0     0     0     0     0     0     0     0     0     0     0  \n",
      "1     0     0     0     0     0     0     0     0     0     0  \n",
      "2     0     0     0     0     0     0     0     0     0     0  \n",
      "3     0     1     0     1     0     0     0     0     0     0  \n",
      "4     0     0     0     0     0     0     0     0     0     1  \n",
      "\n",
      "[5 rows x 313 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "specified-bonus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          time  event  Treatment  Var1  Var2  Var3  Var4  Var5  Var6  Var7  \\\n",
      "995  19.289036      0          0     3     5     3     7     0     2     1   \n",
      "996  66.591235      1          1     4     2     1     2     2     2     2   \n",
      "997  62.986021      0          1     4     3     4     9     3     6     6   \n",
      "998  32.736220      1          0     4     1     4     5     6     3     1   \n",
      "999  36.714493      1          0     3     2     1     2     4     3     1   \n",
      "\n",
      "     ...  G291  G292  G293  G294  G295  G296  G297  G298  G299  G300  \n",
      "995  ...     0     0     0     0     0     0     1     0     0     0  \n",
      "996  ...     0     0     1     0     1     0     0     0     1     0  \n",
      "997  ...     0     0     0     0     1     0     0     0     0     0  \n",
      "998  ...     0     0     0     0     0     0     0     1     1     0  \n",
      "999  ...     0     0     0     0     0     0     0     0     0     0  \n",
      "\n",
      "[5 rows x 313 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "regular-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "vocal-theme",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Train & Test Split\n",
    "'''\n",
    "random_index = np.arange(1000)\n",
    "np.random.shuffle(random_index)\n",
    "\n",
    "train_df, test_df = df.iloc[random_index[:900],:], df.iloc[random_index[900:1000],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "effective-recall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 313)\n",
      "          time  event  Treatment      Var1      Var2      Var3      Var4  \\\n",
      "743  53.044561      1          1  0.000000  0.333333  0.222222  0.333333   \n",
      "815  51.142264      1          1  0.222222  0.222222  0.222222  0.111111   \n",
      "190  41.796940      1          0  0.333333  0.222222  0.555556  0.111111   \n",
      "213  26.039087      1          1  0.222222  0.666667  0.444444  1.000000   \n",
      "669  76.825402      1          1  0.555556  0.777778  0.000000  0.333333   \n",
      "42   31.203717      1          0  0.000000  0.111111  0.444444  0.111111   \n",
      "824  51.347352      1          0  0.222222  0.333333  0.222222  0.333333   \n",
      "265  29.463054      0          0  0.000000  0.222222  0.444444  0.333333   \n",
      "326  48.244555      1          1  0.333333  0.333333  0.444444  0.666667   \n",
      "928  59.018633      1          1  0.111111  0.222222  0.111111  0.333333   \n",
      "\n",
      "         Var5      Var6      Var7  ...  G291  G292  G293  G294  G295  G296  \\\n",
      "743  0.666667  0.666667  0.333333  ...     0     0     0     0     0     0   \n",
      "815  0.444444  0.333333  0.111111  ...     0     0     0     0     1     0   \n",
      "190  0.222222  0.222222  0.000000  ...     0     0     0     0     0     0   \n",
      "213  0.111111  0.555556  0.111111  ...     0     0     0     0     0     0   \n",
      "669  0.444444  0.333333  0.111111  ...     0     0     0     0     0     0   \n",
      "42   0.555556  0.111111  0.111111  ...     0     0     1     1     1     1   \n",
      "824  0.222222  0.333333  0.444444  ...     0     0     0     0     0     0   \n",
      "265  0.666667  0.111111  0.111111  ...     0     0     0     0     0     0   \n",
      "326  0.444444  0.555556  0.333333  ...     0     0     0     0     0     0   \n",
      "928  0.333333  0.222222  0.666667  ...     0     0     0     0     0     0   \n",
      "\n",
      "     G297  G298  G299  G300  \n",
      "743     0     0     0     1  \n",
      "815     0     0     0     0  \n",
      "190     0     0     0     0  \n",
      "213     0     0     0     1  \n",
      "669     0     0     0     0  \n",
      "42      0     0     0     0  \n",
      "824     0     0     0     0  \n",
      "265     0     0     0     0  \n",
      "326     0     0     0     0  \n",
      "928     0     0     0     0  \n",
      "\n",
      "[10 rows x 313 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "lonely-inquiry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             time       event   Treatment        Var1        Var2        Var3  \\\n",
      "count  900.000000  900.000000  900.000000  900.000000  900.000000  900.000000   \n",
      "mean    51.348455    0.894444    0.486667    0.323580    0.365926    0.331235   \n",
      "std     21.705269    0.307439    0.500100    0.205330    0.214760    0.211608   \n",
      "min      7.070708    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%     37.350560    1.000000    0.000000    0.222222    0.222222    0.222222   \n",
      "50%     46.786793    1.000000    0.000000    0.333333    0.333333    0.333333   \n",
      "75%     60.100614    1.000000    1.000000    0.444444    0.444444    0.444444   \n",
      "max    217.078908    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
      "\n",
      "             Var4        Var5        Var6        Var7  ...        G291  \\\n",
      "count  900.000000  900.000000  900.000000  900.000000  ...  900.000000   \n",
      "mean     0.357531    0.388889    0.360741    0.261852  ...    0.108889   \n",
      "std      0.218399    0.210512    0.222384    0.200129  ...    0.311673   \n",
      "min      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
      "25%      0.222222    0.222222    0.222222    0.111111  ...    0.000000   \n",
      "50%      0.333333    0.333333    0.333333    0.222222  ...    0.000000   \n",
      "75%      0.444444    0.555556    0.444444    0.444444  ...    0.000000   \n",
      "max      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
      "\n",
      "             G292        G293        G294        G295        G296        G297  \\\n",
      "count  900.000000  900.000000  900.000000  900.000000  900.000000  900.000000   \n",
      "mean     0.088889    0.101111    0.104444    0.128889    0.103333    0.108889   \n",
      "std      0.284742    0.301643    0.306006    0.335263    0.304563    0.311673   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
      "\n",
      "             G298        G299        G300  \n",
      "count  900.000000  900.000000  900.000000  \n",
      "mean     0.088889    0.100000    0.095556  \n",
      "std      0.284742    0.300167    0.294144  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      0.000000    0.000000    0.000000  \n",
      "50%      0.000000    0.000000    0.000000  \n",
      "75%      0.000000    0.000000    0.000000  \n",
      "max      1.000000    1.000000    1.000000  \n",
      "\n",
      "[8 rows x 313 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "naked-ethernet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             time      event   Treatment        Var1       Var2        Var3  \\\n",
      "count  100.000000  100.00000  100.000000  100.000000  100.00000  100.000000   \n",
      "mean    51.621439    0.92000    0.490000    3.070000    3.32000    2.950000   \n",
      "std     20.281128    0.27266    0.502418    1.776701    1.98418    1.799972   \n",
      "min     20.303883    0.00000    0.000000    0.000000    0.00000    0.000000   \n",
      "25%     39.361435    1.00000    0.000000    2.000000    2.00000    2.000000   \n",
      "50%     48.322230    1.00000    0.000000    3.000000    3.00000    3.000000   \n",
      "75%     61.168396    1.00000    1.000000    4.000000    4.00000    4.000000   \n",
      "max    171.994623    1.00000    1.000000    9.000000   10.00000    9.000000   \n",
      "\n",
      "             Var4        Var5        Var6        Var7  ...        G291  \\\n",
      "count  100.000000  100.000000  100.000000  100.000000  ...  100.000000   \n",
      "mean     3.470000    3.670000    3.300000    2.100000  ...    0.130000   \n",
      "std      2.231342    1.943936    1.972027    1.598611  ...    0.337998   \n",
      "min      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
      "25%      2.000000    2.000000    2.000000    1.000000  ...    0.000000   \n",
      "50%      3.000000    3.000000    3.000000    2.000000  ...    0.000000   \n",
      "75%      5.000000    5.000000    4.000000    3.000000  ...    0.000000   \n",
      "max      9.000000   10.000000   10.000000    7.000000  ...    1.000000   \n",
      "\n",
      "             G292        G293        G294        G295        G296        G297  \\\n",
      "count  100.000000  100.000000  100.000000  100.000000  100.000000  100.000000   \n",
      "mean     0.100000    0.130000    0.110000    0.110000    0.060000    0.140000   \n",
      "std      0.301511    0.337998    0.314466    0.314466    0.238683    0.348735   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
      "\n",
      "             G298        G299        G300  \n",
      "count  100.000000  100.000000  100.000000  \n",
      "mean     0.050000    0.130000    0.120000  \n",
      "std      0.219043    0.337998    0.326599  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      0.000000    0.000000    0.000000  \n",
      "50%      0.000000    0.000000    0.000000  \n",
      "75%      0.000000    0.000000    0.000000  \n",
      "max      1.000000    1.000000    1.000000  \n",
      "\n",
      "[8 rows x 313 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "proud-bronze",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 311) (900,) (100, 311) (900,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Data & Ground Truth Split\n",
    "'''\n",
    "\n",
    "'''\n",
    "Time data drop\n",
    "'''\n",
    "\n",
    "X_train = train_df.drop(['time', 'event'], axis=1)\n",
    "Y_train = train_df['event']\n",
    "\n",
    "X_test = test_df.drop(['time', 'event'], axis=1)\n",
    "Y_test = test_df['event']\n",
    "\n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Save train & test results\n",
    "\n",
    "When doing train, Shuffle and split the data\n",
    "\n",
    "'''\n",
    "test_method_list = ['LogisticRegression', 'Support Vector Machines', 'KNN or k-Nearest Neighbors',\n",
    "                    'Gaussian Naive Bayes', 'Perceptron', 'Linear SVC', \n",
    "                    'Stochastic Gradient Descent', 'Decision Tree', 'Random Forest']\n",
    "\n",
    "index = ['Basic_train', 'Basic_test',\n",
    "         'Time_outlier_train', 'Time_outlier_test',\n",
    "         'Time_/365_train', 'Time_/365_test',\n",
    "         'Clinic_outlier_train', 'Clinic_outlier_test',\n",
    "         'Clinic_0-4(2steps)_train', 'Clinic_0-4(2steps)_test',\n",
    "         'Clinic_0-1(resizing)_train', 'Clinic_0-1(resizing)_test']\n",
    "\n",
    "# result_train_df = pd.DataFrame(index = index, columns=test_method_list)\n",
    "# result_test_df = pd.DataFrame(index = index, columns=test_method_list)\n",
    "# result_df[index] = [train-ulre, , ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "first-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model, predict and solve\n",
    "\n",
    "\n",
    "- Methods\n",
    "Logistic Regression\n",
    "KNN or k-Nearest Neighbors\n",
    "Support Vector Machines\n",
    "Naive Bayes classifier\n",
    "Decision Tree\n",
    "Random Forrest\n",
    "Perceptron\n",
    "Artificial neural network\n",
    "RVM or Relevance Vector Machine\n",
    "'''\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def training(call_model_name):\n",
    "    print('*** Method: ', call_model_name)\n",
    "    \n",
    "    if call_model_name == 'LogisticRegression':\n",
    "        model = LogisticRegression()\n",
    "        \n",
    "    elif call_model_name == 'Support Vector Machines':\n",
    "        model = SVC()\n",
    "        \n",
    "    elif call_model_name == 'KNN or k-Nearest Neighbors':\n",
    "        model = KNeighborsClassifier(n_neighbors = 3)\n",
    "        \n",
    "    elif call_model_name == 'Gaussian Naive Bayes':\n",
    "        model = GaussianNB()\n",
    "        \n",
    "    elif call_model_name == 'Perceptron':\n",
    "        model = Perceptron()\n",
    "        \n",
    "    elif call_model_name == 'Linear SVC':\n",
    "        model = LinearSVC()\n",
    "        \n",
    "    elif call_model_name == 'Stochastic Gradient Descent':\n",
    "        model = SGDClassifier()\n",
    "        \n",
    "    elif call_model_name == 'Decision Tree':\n",
    "        model = DecisionTreeClassifier()\n",
    "    \n",
    "    elif call_model_name == 'Random Forest':\n",
    "        model = RandomForestClassifier(n_estimators=100)\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train, Y_train)\n",
    "    acc_log = round(model.score(X_train, Y_train) * 100, 2)\n",
    "    print('trained-acc: ', acc_log)\n",
    "\n",
    "    # Test\n",
    "    acc_log = round(model.score(X_test, Y_test) * 100, 2)\n",
    "    print('test-acc: ', acc_log)\n",
    "    print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "centered-month",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method:  LogisticRegression\n",
      "trained-acc:  94.78\n",
      "test-acc:  82.0\n",
      "\n",
      "\n",
      "Method:  Support Vector Machines\n",
      "trained-acc:  88.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-acc:  92.0\n",
      "\n",
      "\n",
      "Method:  KNN or k-Nearest Neighbors\n",
      "trained-acc:  89.89\n",
      "test-acc:  92.0\n",
      "\n",
      "\n",
      "Method:  Gaussian Naive Bayes\n",
      "trained-acc:  85.11\n",
      "test-acc:  77.0\n",
      "\n",
      "\n",
      "Method:  Perceptron\n",
      "trained-acc:  92.89\n",
      "test-acc:  85.0\n",
      "\n",
      "\n",
      "Method:  Linear SVC\n",
      "trained-acc:  99.56\n",
      "test-acc:  73.0\n",
      "\n",
      "\n",
      "Method:  Stochastic Gradient Descent\n",
      "trained-acc:  94.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-acc:  82.0\n",
      "\n",
      "\n",
      "Method:  Decision Tree\n",
      "trained-acc:  100.0\n",
      "test-acc:  79.0\n",
      "\n",
      "\n",
      "Method:  Random Forest\n",
      "trained-acc:  100.0\n",
      "test-acc:  92.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Basic Training & Test\n",
    "\n",
    "'''\n",
    "for input_method in test_method_list:\n",
    "    training(input_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "strange-norfolk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlier of time: \n",
      "905   -7.945621\n",
      "Name: time, dtype: float64\n",
      "\n",
      "              time        event\n",
      "count  1000.000000  1000.000000\n",
      "mean     51.876125     0.891000\n",
      "std      22.122689     0.311795\n",
      "min       7.070708     0.000000\n",
      "25%      37.401307     1.000000\n",
      "50%      47.064712     1.000000\n",
      "75%      60.966476     1.000000\n",
      "max     217.078908     1.000000\n",
      "\n",
      "Method:  LogisticRegression\n",
      "trained-acc:  95.0\n",
      "test-acc:  83.0\n",
      "\n",
      "\n",
      "Method:  Support Vector Machines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained-acc:  88.78\n",
      "test-acc:  92.0\n",
      "\n",
      "\n",
      "Method:  KNN or k-Nearest Neighbors\n",
      "trained-acc:  91.44\n",
      "test-acc:  92.0\n",
      "\n",
      "\n",
      "Method:  Gaussian Naive Bayes\n",
      "trained-acc:  85.44\n",
      "test-acc:  78.0\n",
      "\n",
      "\n",
      "Method:  Perceptron\n",
      "trained-acc:  89.44\n",
      "test-acc:  92.0\n",
      "\n",
      "\n",
      "Method:  Linear SVC\n",
      "trained-acc:  95.89\n",
      "test-acc:  82.0\n",
      "\n",
      "\n",
      "Method:  Stochastic Gradient Descent\n",
      "trained-acc:  93.0\n",
      "test-acc:  85.0\n",
      "\n",
      "\n",
      "Method:  Decision Tree\n",
      "trained-acc:  100.0\n",
      "test-acc:  80.0\n",
      "\n",
      "\n",
      "Method:  Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained-acc:  100.0\n",
      "test-acc:  92.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Add Time data\n",
    "\n",
    "1) outlier value drop\n",
    "2) clustering from step 0-N days to step 0-N/365 days\n",
    "'''\n",
    "\n",
    "'''\n",
    "1)\n",
    "'''\n",
    "print('outlier of time: ')\n",
    "print(df1.loc[df1['time'] < 0, 'time'], end='\\n\\n')\n",
    "\n",
    "df1_outlier = df1.copy()\n",
    "df1_outlier.loc[df1_outlier['time'] < 0, 'time'] = abs(df1_outlier.loc[df1_outlier['time'] < 0, 'time'])\n",
    "print(df1_outlier.describe(), end='\\n\\n')\n",
    "\n",
    "df = pd.concat([df1_outlier,df2,df3,df4], axis=1)\n",
    "train_df, test_df = df.iloc[random_index[:900],:], df.iloc[random_index[900:1000],:]\n",
    "\n",
    "X_train = train_df.drop(['event'], axis=1)\n",
    "Y_train = train_df['event']\n",
    "\n",
    "X_test = test_df.drop(['event'], axis=1)\n",
    "Y_test = test_df['event']\n",
    "\n",
    "\n",
    "'''\n",
    "Add Time data(1) Training & Test\n",
    "\n",
    "'''\n",
    "\n",
    "for input_method in test_method_list:\n",
    "    training(input_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "technical-might",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              time        event\n",
      "count  1000.000000  1000.000000\n",
      "mean      0.142126     0.891000\n",
      "std       0.060610     0.311795\n",
      "min       0.019372     0.000000\n",
      "25%       0.102469     1.000000\n",
      "50%       0.128944     1.000000\n",
      "75%       0.167031     1.000000\n",
      "max       0.594737     1.000000\n",
      "\n",
      "Method:  LogisticRegression\n",
      "trained-acc:  94.78\n",
      "test-acc:  82.0\n",
      "\n",
      "\n",
      "Method:  Support Vector Machines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained-acc:  88.78\n",
      "test-acc:  92.0\n",
      "\n",
      "\n",
      "Method:  KNN or k-Nearest Neighbors\n",
      "trained-acc:  89.56\n",
      "test-acc:  92.0\n",
      "\n",
      "\n",
      "Method:  Gaussian Naive Bayes\n",
      "trained-acc:  85.44\n",
      "test-acc:  78.0\n",
      "\n",
      "\n",
      "Method:  Perceptron\n",
      "trained-acc:  90.56\n",
      "test-acc:  71.0\n",
      "\n",
      "\n",
      "Method:  Linear SVC\n",
      "trained-acc:  99.56\n",
      "test-acc:  72.0\n",
      "\n",
      "\n",
      "Method:  Stochastic Gradient Descent\n",
      "trained-acc:  92.78\n",
      "test-acc:  72.0\n",
      "\n",
      "\n",
      "Method:  Decision Tree\n",
      "trained-acc:  100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-acc:  84.0\n",
      "\n",
      "\n",
      "Method:  Random Forest\n",
      "trained-acc:  100.0\n",
      "test-acc:  92.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2)\n",
    "'''\n",
    "df1_normalize = df1_outlier.copy()\n",
    "df1_normalize['time'] = df1_normalize['time']/365.0\n",
    "print(df1_normalize.describe(), end='\\n\\n')\n",
    "\n",
    "df = pd.concat([df1_normalize,df2,df3,df4], axis=1)\n",
    "train_df, test_df = df.iloc[random_index[:900],:], df.iloc[random_index[900:1000],:]\n",
    "\n",
    "X_train = train_df.drop(['event'], axis=1)\n",
    "Y_train = train_df['event']\n",
    "\n",
    "X_test = test_df.drop(['event'], axis=1)\n",
    "Y_test = test_df['event']\n",
    "\n",
    "\n",
    "'''\n",
    "Add Time data(1) Training & Test\n",
    "\n",
    "'''\n",
    "\n",
    "for input_method in test_method_list:\n",
    "    training(input_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "usual-church",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Var1\n",
      "2    235\n",
      "3    204\n",
      "1    171\n",
      "4    139\n",
      "5     95\n",
      "0     57\n",
      "6     50\n",
      "7     27\n",
      "8     13\n",
      "9      9\n",
      "Name: Var1, dtype: int64\n",
      "--------------------\n",
      "# Var2\n",
      "3    221\n",
      "2    218\n",
      "4    163\n",
      "1    113\n",
      "5    109\n",
      "6     65\n",
      "0     48\n",
      "7     30\n",
      "9     20\n",
      "8     13\n",
      "Name: Var2, dtype: int64\n",
      "--------------------\n",
      "# Var3\n",
      "2    260\n",
      "3    196\n",
      "1    156\n",
      "4    130\n",
      "5     97\n",
      "0     55\n",
      "6     55\n",
      "7     23\n",
      "8     16\n",
      "9     12\n",
      "Name: Var3, dtype: int64\n",
      "--------------------\n",
      "# Var4\n",
      "2    242\n",
      "3    195\n",
      "1    150\n",
      "4    140\n",
      "5    106\n",
      "6     67\n",
      "0     36\n",
      "7     32\n",
      "8     16\n",
      "9     16\n",
      "Name: Var4, dtype: int64\n",
      "--------------------\n",
      "# Var5\n",
      "2    247\n",
      "3    223\n",
      "4    161\n",
      "5    124\n",
      "1     76\n",
      "6     63\n",
      "7     41\n",
      "0     28\n",
      "9     19\n",
      "8     18\n",
      "Name: Var5, dtype: int64\n",
      "--------------------\n",
      "# Var6\n",
      "2    240\n",
      "3    212\n",
      "4    128\n",
      "1    127\n",
      "5     99\n",
      "6     64\n",
      "0     53\n",
      "7     40\n",
      "8     20\n",
      "9     17\n",
      "Name: Var6, dtype: int64\n",
      "--------------------\n",
      "# Var7\n",
      "1    269\n",
      "2    208\n",
      "3    144\n",
      "0    128\n",
      "4    118\n",
      "5     62\n",
      "6     47\n",
      "7     16\n",
      "8      6\n",
      "9      2\n",
      "Name: Var7, dtype: int64\n",
      "--------------------\n",
      "# Var8\n",
      "1    241\n",
      "2    227\n",
      "3    171\n",
      "0    127\n",
      "4    101\n",
      "5     69\n",
      "6     30\n",
      "7     20\n",
      "8     10\n",
      "9      4\n",
      "Name: Var8, dtype: int64\n",
      "--------------------\n",
      "# Var9\n",
      "2    250\n",
      "1    235\n",
      "3    157\n",
      "0    135\n",
      "4    100\n",
      "5     57\n",
      "6     33\n",
      "7     22\n",
      "9      6\n",
      "8      5\n",
      "Name: Var9, dtype: int64\n",
      "--------------------\n",
      "# Var10\n",
      "1    287\n",
      "2    205\n",
      "3    156\n",
      "0    114\n",
      "4    108\n",
      "5     62\n",
      "6     40\n",
      "7     18\n",
      "8      5\n",
      "9      5\n",
      "Name: Var10, dtype: int64\n",
      "--------------------\n",
      "\n",
      "Method:  LogisticRegression\n",
      "trained-acc:  95.33\n",
      "test-acc:  84.0\n",
      "\n",
      "\n",
      "Method:  Support Vector Machines\n",
      "trained-acc:  88.78\n",
      "test-acc:  92.0\n",
      "\n",
      "\n",
      "Method:  KNN or k-Nearest Neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained-acc:  91.44\n",
      "test-acc:  92.0\n",
      "\n",
      "\n",
      "Method:  Gaussian Naive Bayes\n",
      "trained-acc:  85.33\n",
      "test-acc:  78.0\n",
      "\n",
      "\n",
      "Method:  Perceptron\n",
      "trained-acc:  89.22\n",
      "test-acc:  92.0\n",
      "\n",
      "\n",
      "Method:  Linear SVC\n",
      "trained-acc:  96.89\n",
      "test-acc:  79.0\n",
      "\n",
      "\n",
      "Method:  Stochastic Gradient Descent\n",
      "trained-acc:  94.33\n",
      "test-acc:  84.0\n",
      "\n",
      "\n",
      "Method:  Decision Tree\n",
      "trained-acc:  100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-acc:  80.0\n",
      "\n",
      "\n",
      "Method:  Random Forest\n",
      "trained-acc:  100.0\n",
      "test-acc:  92.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Correlating numerical features of Clinic data\n",
    "\n",
    "- outlier value drop\n",
    "- clustering from step 0-9 to step 0-4(clustering 2 steps)/0-1(just resizing)\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "1)\n",
    "'''\n",
    "df3_outlier = df3.copy()\n",
    "\n",
    "\n",
    "# drop outlier\n",
    "for col in df3_outlier.columns:\n",
    "    for outlier in range(10,13):\n",
    "        df3_outlier = df3_outlier.replace(outlier, 9)\n",
    "\n",
    "# visualize\n",
    "for col in df3_outlier.columns:\n",
    "    print('#', col)\n",
    "    print(df3_outlier[col].value_counts())\n",
    "    print('-'*20)\n",
    "\n",
    "\n",
    "df = pd.concat([df1_outlier,df2,df3_outlier,df4], axis=1)\n",
    "train_df, test_df = df.iloc[random_index[:900],:], df.iloc[random_index[900:1000],:]\n",
    "\n",
    "X_train = train_df.drop(['event'], axis=1)\n",
    "Y_train = train_df['event']\n",
    "\n",
    "X_test = test_df.drop(['event'], axis=1)\n",
    "Y_test = test_df['event']\n",
    "\n",
    "\n",
    "'''\n",
    "Add Time data(1) +  Correlating Clinic data(1) \n",
    "Training & Test\n",
    "'''\n",
    "\n",
    "print()\n",
    "for input_method in test_method_list:\n",
    "    training(input_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "conscious-large",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Var1         Var2         Var3         Var4         Var5  \\\n",
      "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
      "mean      1.226000     1.400000     1.256000     1.354000     1.500000   \n",
      "std       0.958041     0.975167     0.968195     0.995829     0.942809   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "50%       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "75%       2.000000     2.000000     2.000000     2.000000     2.000000   \n",
      "max       4.000000     4.000000     4.000000     4.000000     4.000000   \n",
      "\n",
      "              Var6         Var7         Var8         Var9        Var10  \n",
      "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  \n",
      "mean      1.366000     0.933000     0.944000     0.930000     0.915000  \n",
      "std       1.011468     0.947316     0.928292     0.917574     0.941627  \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "25%       1.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "50%       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
      "75%       2.000000     2.000000     1.000000     1.000000     1.000000  \n",
      "max       4.000000     4.000000     4.000000     4.000000     4.000000  \n",
      "\n",
      "Method:  LogisticRegression\n",
      "trained-acc:  95.11\n",
      "test-acc:  83.0\n",
      "\n",
      "\n",
      "Method:  Support Vector Machines\n",
      "trained-acc:  88.78\n",
      "test-acc:  92.0\n",
      "\n",
      "\n",
      "Method:  KNN or k-Nearest Neighbors\n",
      "trained-acc:  91.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-acc:  92.0\n",
      "\n",
      "\n",
      "Method:  Gaussian Naive Bayes\n",
      "trained-acc:  85.44\n",
      "test-acc:  77.0\n",
      "\n",
      "\n",
      "Method:  Perceptron\n",
      "trained-acc:  91.67\n",
      "test-acc:  92.0\n",
      "\n",
      "\n",
      "Method:  Linear SVC\n",
      "trained-acc:  96.89\n",
      "test-acc:  76.0\n",
      "\n",
      "\n",
      "Method:  Stochastic Gradient Descent\n",
      "trained-acc:  90.56\n",
      "test-acc:  92.0\n",
      "\n",
      "\n",
      "Method:  Decision Tree\n",
      "trained-acc:  100.0\n",
      "test-acc:  83.0\n",
      "\n",
      "\n",
      "Method:  Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained-acc:  100.0\n",
      "test-acc:  92.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2-1) 2 steps clustering(0-4)\n",
    "'''\n",
    "df3_2c = df3_outlier.copy()\n",
    "\n",
    "for col in df3_2c.columns:\n",
    "    df3_2c.loc[df3_2c[col] <= 1, col] = 0\n",
    "    df3_2c.loc[(df3_2c[col] > 1) & (df3_2c[col] <= 3), col] = 1\n",
    "    df3_2c.loc[(df3_2c[col] > 3) & (df3_2c[col] <= 5), col] = 2\n",
    "    df3_2c.loc[(df3_2c[col] > 5) & (df3_2c[col] <= 7), col] = 3\n",
    "    df3_2c.loc[(df3_2c[col] > 7) & (df3_2c[col] <= 9), col] = 4\n",
    "\n",
    "print(df3_2c.describe(), end='\\n\\n')\n",
    "\n",
    "df = pd.concat([df1_outlier,df2,df3_2c,df4], axis=1)\n",
    "train_df, test_df = df.iloc[random_index[:900],:], df.iloc[random_index[900:1000],:]\n",
    "\n",
    "X_train = train_df.drop(['event'], axis=1)\n",
    "Y_train = train_df['event']\n",
    "\n",
    "X_test = test_df.drop(['event'], axis=1)\n",
    "Y_test = test_df['event']\n",
    "\n",
    "\n",
    "'''\n",
    "Add Time data(1) +  Correlating Clinic data(2-1) \n",
    "Training & Test\n",
    "'''\n",
    "\n",
    "for input_method in test_method_list:\n",
    "    training(input_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "colonial-maryland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Var1         Var2         Var3         Var4         Var5  \\\n",
      "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
      "mean      0.328667     0.365889     0.332889     0.356333     0.387000   \n",
      "std       0.207386     0.214559     0.210689     0.216080     0.210446   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.222222     0.222222     0.222222     0.222222     0.222222   \n",
      "50%       0.333333     0.333333     0.333333     0.333333     0.333333   \n",
      "75%       0.444444     0.444444     0.444444     0.444444     0.555556   \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "              Var6         Var7         Var8         Var9        Var10  \n",
      "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  \n",
      "mean      0.358556     0.262111     0.265889     0.259667     0.262000  \n",
      "std       0.223040     0.201703     0.202755     0.201437     0.201204  \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "25%       0.222222     0.111111     0.111111     0.111111     0.111111  \n",
      "50%       0.333333     0.222222     0.222222     0.222222     0.222222  \n",
      "75%       0.444444     0.444444     0.333333     0.333333     0.333333  \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
      "\n",
      "Method:  LogisticRegression\n",
      "trained-acc:  94.89\n",
      "test-acc:  83.0\n",
      "\n",
      "\n",
      "Method:  Support Vector Machines\n",
      "trained-acc:  88.78\n",
      "test-acc:  92.0\n",
      "\n",
      "\n",
      "Method:  KNN or k-Nearest Neighbors\n",
      "trained-acc:  91.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-acc:  90.0\n",
      "\n",
      "\n",
      "Method:  Gaussian Naive Bayes\n",
      "trained-acc:  85.33\n",
      "test-acc:  78.0\n",
      "\n",
      "\n",
      "Method:  Perceptron\n",
      "trained-acc:  90.33\n",
      "test-acc:  92.0\n",
      "\n",
      "\n",
      "Method:  Linear SVC\n",
      "trained-acc:  81.0\n",
      "test-acc:  58.0\n",
      "\n",
      "\n",
      "Method:  Stochastic Gradient Descent\n",
      "trained-acc:  60.67\n",
      "test-acc:  40.0\n",
      "\n",
      "\n",
      "Method:  Decision Tree\n",
      "trained-acc:  100.0\n",
      "test-acc:  82.0\n",
      "\n",
      "\n",
      "Method:  Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained-acc:  100.0\n",
      "test-acc:  92.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2-2) just resizing(0-1)\n",
    "'''\n",
    "df3_rs = df3_outlier.copy()\n",
    "\n",
    "for col in df3_rs.columns:\n",
    "    df3_rs[col] = df3_rs[col]/9\n",
    "\n",
    "print(df3_rs.describe(), end='\\n\\n')\n",
    "\n",
    "df = pd.concat([df1_outlier,df2,df3_rs,df4], axis=1)\n",
    "train_df, test_df = df.iloc[random_index[:900],:], df.iloc[random_index[900:1000],:]\n",
    "\n",
    "X_train = train_df.drop(['event'], axis=1)\n",
    "Y_train = train_df['event']\n",
    "\n",
    "X_test = test_df.drop(['event'], axis=1)\n",
    "Y_test = test_df['event']\n",
    "\n",
    "\n",
    "'''\n",
    "Add Time data(1) +  Correlating Clinic data(2-2) \n",
    "Training & Test\n",
    "'''\n",
    "\n",
    "for input_method in test_method_list:\n",
    "    training(input_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "delayed-journalist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel parameters\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model parameters\n",
    "\n",
    "result collection\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
